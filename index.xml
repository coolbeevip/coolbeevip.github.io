<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title/><link>https://coolbeevip.github.io/</link><description>Recent content on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 19 Jun 2021 13:24:14 +0800</lastBuildDate><atom:link href="https://coolbeevip.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Ratis</title><link>https://coolbeevip.github.io/posts/ratis/ratis-study/</link><pubDate>Sat, 19 Jun 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ratis/ratis-study/</guid><description/></item><item><title>GraphQL Tools Schema Parser</title><link>https://coolbeevip.github.io/posts/graphql-tools-schema-paarser-slow/</link><pubDate>Sat, 29 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/graphql-tools-schema-paarser-slow/</guid><description>SYSTEM
MacBook Pro 16G
JVM
-Xmx4g -Xms4g -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -Xnoclassgc -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:ParallelGCThreads=12 -XX:MaxTenuringThreshold=15 -XX:+ExplicitGCInvokesConcurrent -XX:+CMSParallelRemarkEnabled -XX:SurvivorRatio=8 -XX:CMSInitiatingOccupancyFraction=65 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCMSCompactAtFullCollection -XX:+CMSClassUnloadingEnabled -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 CPU Flame Graph
GrpaphQL Schema Parser
Slow Method</description></item><item><title>APISIX Study Notes (1) Build &amp; QuickStart</title><link>https://coolbeevip.github.io/posts/study-notes-for-apisix-1-quickstart/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/study-notes-for-apisix-1-quickstart/</guid><description>安装 在 macOS 基于源代码自己编译发布版本
安装 Etcd 启动 apisix-etcd.yml
version: &amp;#39;3.2&amp;#39; services: etcd-1: image: docker.io/bitnami/etcd:3.4.16 hostname: etcd container_name: apisix-etcd ports: - &amp;#39;2380:2380&amp;#39; - &amp;#39;2379:2379&amp;#39; environment: - ALLOW_NONE_AUTHENTICATION=yes - ETCD_NAME=etcd-1 - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380 - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 - ETCD_ADVERTISE_CLIENT_URLS=http://0.0.0.0:2379 volumes: - ./volume/apisix/etcd/data:/bitnami/etcd/data - ./volume/apisix/etcd/conf:/opt/bitnami/etcd/conf docker-compose -f docker-compose-apisix-etcd.yml up -d 验证 $ curl -L http://127.0.0.1:2379/health {&amp;#34;health&amp;#34;:&amp;#34;true&amp;#34;} 安装编译环境 安装 Node 10.23.0+ $ node -v v12.18.3 安装 Yarn $ npm install -g yarn $ yarn -v 1.</description></item><item><title>APISIX Study Notes (2) Plugins Traffic Split</title><link>https://coolbeevip.github.io/posts/study-notes-for-apisix-2-plugins-traffic-split/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/study-notes-for-apisix-2-plugins-traffic-split/</guid><description>场景描述 我有两个 UPSTREAM 服务:
UPSTREAM 1 $ curl -i -X GET http://192.168.51.234:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:09:29 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} UPSTREAM 2 $ curl -i -X GET http://10.19.88.60:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:08:12 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} 我希望通过 APISIX 将请求流量路由到两个不同的 UPSTREAM 服务上，参考插件 traffic-split 的样例，可以实现此功能
配置路由 &amp;amp; traffic-split 本例中并没有单独定义 UPSTREAM，而是在 traffic-split 中直接定义了 UPSTREAM 的地址</description></item><item><title>APISIX Study Notes (3) Install with Docker</title><link>https://coolbeevip.github.io/posts/study-notes-for-apisix-3-install-with-docker/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/study-notes-for-apisix-3-install-with-docker/</guid><description>使用 Docker 启动
定义卷目录 APISIX 目前好像还不支持通过环境变量配置参数，所以需要在宿主机上创建配置文件，并在启动 Docker 时通过 Volume 映射进容器
规划外部卷目录
mkdir apisix_home mkdir -p apisix_home/apisix_volume/apisix/apisix_conf mkdir -p apisix_home/apisix_volume/apisix/dashboard_conf 定义 APISIX Dashboard 配置文件 apisix_home/apisix_volume/apisix/dashboard_conf/conf.yaml
conf: listen: # 绑定 IP 地址 host: 0.0.0.0 # 监听端口 port: 9000 etcd: # etcd 用户名 # username: &amp;#34;root&amp;#34; # etcd 密码 # password: &amp;#34;123456&amp;#34; # etcd 地址，支持集群多节点定义 endpoints: - apisix-etcd:2379 log: error_log: # 日志级别 debug, info, warn, error, panic, fatal level: warn # 日志输出路径 file_path: logs/error.</description></item><item><title>APISIX Study Notes (4) Plugins Proxy Rewrite</title><link>https://coolbeevip.github.io/posts/study-notes-for-apisix-4-plugins-proxy-rewrite/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/study-notes-for-apisix-4-plugins-proxy-rewrite/</guid><description>在 APISIX STUDY NOTES (2) PLUGINS TRAFFIC SPLIT 提到，我们可以通过这个插件实现上游服务的导流，但是这个插件只能通过自定义 URL参数 或者 REQUEST HEADER 的方式传递导流变量。如果我们想通过 URL PATH 的方式实现上游业务的到导流，可以使用 Proxy Rewrite 插件
场景描述 我有两个 UPSTREAM 服务:
UPSTREAM 1 $ curl -i -X GET http://192.168.51.234:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:09:29 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} UPSTREAM 2 $ curl -i -X GET http://10.19.88.60:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:08:12 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{.</description></item><item><title>Bash script automates the Maven project Git release process</title><link>https://coolbeevip.github.io/posts/git-automate-tag-release-process-with-bash/</link><pubDate>Sun, 16 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-automate-tag-release-process-with-bash/</guid><description>开源项目中我们大多采用主干开发模式管理我们的项目，他基本遵循以下规则
所有的 PR 都默认向主干合并 主干上项目的版本号是 -SNAPSHOT 当主干要发布时，我们会建立与之对应的 X 分支（此分支的目的是为了基于此分支发布补丁版本） 基于当前主干去除版本号中的 -SNAPSHOT 后建立与版本对应的 TAG 将主干上的版本号中的 minor 累加一，并在后边增加 -SNAPSHOT 后缀 此过程繁琐，切容易出错。我制作了一个脚本 maven-project-git-release.sh 用来实现这个过程的规范化和自动化
当然，这并不意味着你不需要掌握正手动发布的过程。
由于某种原因导致自动过程中断后，你依然需要手动去处理，所以在使用这个脚本前，请确保你了解这个脚本帮你做了什么工作，以及如何做的。
如何使用 maven-project-git-release.sh 脚本会帮你自动化以下工作
创建一个编译用的目录
目录会创建在你系统的临时目录下，在我的 Mac 系统系统中看起来像 /var/folders/fd/gqdh88px2fj66tmtcy6ffr580000gn/T
在编译用的目录中 git clone 你的仓库代码
你的仓库地址在使用脚本时通过参数指定，像这样 sh maven-project-git-release.sh git@github.com:coolbeevip/license-maven-plugin.git
编译你的代码确保正确
默认在当前仓库根目录下执行 mvn clean package，如果你需要特殊的方式，可以修改脚本中的 check_source_before_release 函数
计算版本号分支名
根据 pom 中的版本定义，自动计算下一版本号，默认采 maven 的3段式版号方式 major.minor.patch，并以此为基准滚动 minor 版本号，如果你需要特殊的方式，可以修改脚本中的 next_version 函数
输出发布计划</description></item><item><title>JProfiler with Docker Sonatype Nexus3</title><link>https://coolbeevip.github.io/posts/jprofiler-with-docker/</link><pubDate>Fri, 14 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/jprofiler-with-docker/</guid><description>使用 JProfiler 监控 Docker Sonatype Nexus3
下载 JProfiler 从 https://www.ej-technologies.com/下载 JProfiler 和 Agent（注意版本必须一致）
JProfiler GUI
https://download-gcdn.ej-technologies.com/jprofiler/jprofiler_macos_12_0_2.dmg
JProfiler Agent
https://download-gcdn.ej-technologies.com/jprofiler/jprofiler_linux_12_0_2.sh
在服务器上安装 JProfiler Agent 将下载后的 jprofiler_linux_12_0_2.sh 传到服务器上，通过 sh jprofiler_linux_12_0_2.sh 命令按提示安装即可
默认安装路径为 /opt/jprofiler12/，这个路径在启动 Docker 的时候要映射到容器内部
启动 Docker Sonatype Nexus3 在官方 sonatype/nexus3 容器启动参数的基础上做如下修改
使用 -v /opt/jprofiler12:/opt/jprofiler12 将 jprofiler 路径映射到容器内部
增加 -agentpath:/opt/jprofiler12/bin/linux-x64/libjprofilerti.so=port=9899 JVM 参数，设置监听端口为 9899
增加 -p 9899:9899 容器端口映射
docker run -d \ -e NEXUS_CONTEXT=nexus \ -e INSTALL4J_ADD_VM_PARAMS=&amp;#34;-Xms10g -Xmx10g \ -agentpath:/opt/jprofiler12/bin/linux-x64/libjprofilerti.</description></item><item><title>Securing Docker ports with firewalld</title><link>https://coolbeevip.github.io/posts/securing-docker-ports-with-firewalld/</link><pubDate>Tue, 11 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/securing-docker-ports-with-firewalld/</guid><description>概述 为了保护 Docker 暴露的端口不受外部访问的影响，可以使用 firewalld 配置防火墙规则，只允许特定的 IP 访问。 通过让 firewalld 创建 DOCKER-USER 链，我们可以实现由 firewalld 维护的安全 Docker 端口, Docker 处理 iptables 规则以提供网络隔离，更多详细
本文基于环境
Docker-CE 19.03.12 CentOS Linux release 7.8.2003 Firewall 0.6.3 本文例子:
我们使用 Docker 安装一个 Nginx，并将 80(HTTP) 端口对外映射为 8080，443(HTTPS) 端口对外映射为 8443，并通过 Firewalld 仅允许特定的 IP 访问；提示：后续的防火墙规则中配置的端口是容器内部端口，例如 80，443
192.168.51.246 安装 Nginx Docker
配置 192.168.51.245 可以访问 Nginx Docker
其他机器无法访问 Nginx Docker
重要的事情说三遍
如果你在 Docker 运行时重启 firewalld，那么 firewalld 将删除 DOCKER-USER</description></item><item><title>Use Maven plugin to export license info in source files and its optional dependencies</title><link>https://coolbeevip.github.io/posts/maven-export-dependencies-analyse-license/</link><pubDate>Sun, 09 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven-export-dependencies-analyse-license/</guid><description>有的时候我们那需要分析多模块 Maven 项目的依赖使用情况，并希望能够分析出这些依赖的 LICENSE 信息。使用 io.github.coolbeevip:license-maven-plugin 插件 可以生成 TXT 或者 CSV 格式的分析报告
youtube
bilibili
CSV 格式的报告 NOTICE.CSV NOTICE-LICENSE.CSV TXT 格式的报告 NOTICE.TXT NOTICE-LICENSE.TXT 插件 LICENSE-MAVEN-PLUGIN format 导出格式，支持 csv、txt； license 是否分析 LICENSE 信息，默认 false； ignoreGroupIds 忽略 groupId 列表, 多个用逗号分割; timeout 分析 LICENSE 的超时时间，默认 5 秒; 导出报告 在 Maven 项目的根目录执行如下命令
导出 CSV
mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=csv 导出 TXT
mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=txt 提示： 导出的报告位置在 ./target/distribute 目录下
导出报告(忽略部分依赖) mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=csv -DignoreGroupIds=org.</description></item><item><title>Synchronize between image repositories with Bash</title><link>https://coolbeevip.github.io/posts/docker-pulling-pushing/</link><pubDate>Mon, 19 Apr 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker-pulling-pushing/</guid><description>从源镜像仓库批量拉取镜像，并将这些镜像推送到目标镜像仓库的批量脚本
#!/bin/bash ################################################# # 使用方式 # 从源仓库拉取镜像到本机 # sh docker-images-pulling-pushing.sh pull # # 将本机镜像推送到目的仓库 # sh docker-images-pulling-pushing.sh push # # 清理本机的镜像 # sh docker-images-pulling-pushing.sh clean ################################################# # 源仓库地址 DOCKER_REPO_FROM= # 目标仓库地址 DOCKER_REPO_TO=192.168.2.2:8888/ DOCKER_REPO_TO_USER=test DOCKER_REPO_TO_PASS=Test123456 # 镜像定义 DOCKER_IMAGES=() DOCKER_IMAGES+=(postgres:9.6) DOCKER_IMAGES+=(elasticsearch:6.6.2) DOCKER_IMAGES+=(coolbeevip/servicecomb-pack) # 从源仓库地址拉取镜像到本机仓库 function pull(){ echo &amp;#34;Pull images from $DOCKER_REPO_FROM&amp;#34; for image in ${DOCKER_IMAGES[@]}; do docker pull $DOCKER_REPO_FROM$image done } # 本机镜像推送到目的仓库 function push(){ docker login http://$DOCKER_REPO_TO -u $DOCKER_REPO_TO_USER -p $DOCKER_REPO_TO_PASS echo &amp;#34;Push $DOCKER_REPO_FROMto $DOCKER_REPO_TO&amp;#34; for image in ${DOCKER_IMAGES[@]}; do docker image tag $DOCKER_REPO_FROM$image $DOCKER_REPO_TO$image docker push $DOCKER_REPO_TO$image done } # 清理本机拉取后的镜像 function clean(){ echo &amp;#34;Remove images&amp;#34; docker rmi -f $(docker images | grep $DOCKER_REPO_FROM | awk &amp;#39;{print $3}&amp;#39;) docker rmi -f $(docker images | grep $DOCKER_REPO_TO | awk &amp;#39;{print $3}&amp;#39;) } case &amp;#34;${@: -1}&amp;#34; in pull ) pull ;; clean ) clean ;; push ) push ;; esac</description></item><item><title>About</title><link>https://coolbeevip.github.io/about/</link><pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/about/</guid><description>Hi, I&amp;rsquo;m ZhangLei 👋
Software Enginner at asiainfo.com Beijing, China
Apache committer、Apache ServiceComb PMC</description></item><item><title>Bookmarks</title><link>https://coolbeevip.github.io/bookmarks/</link><pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/bookmarks/</guid><description>Some of my favorite websites/tools with excellent design and UX that I highly recommend
Color Adobe Color
terminal.sexy
Dev Rex Transform texts with RegExp like a Pro
Regex101
RegExper - Regex Visualizer
rhein Text editor with freedom of layouting
Rico’s cheatsheets
transform - Collection of code transformers
JMH Visualizer JMH json files Visualizer.
Resources Icônes Iconify Explorer with Instant searching
UI/UX Open UI - Comparison between different component frameworks
Diagram Isoflow</description></item><item><title>MacOS Switch JDK</title><link>https://coolbeevip.github.io/posts/macos-switch-jdk/</link><pubDate>Thu, 25 Mar 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/macos-switch-jdk/</guid><description>查看本机 JDK 版本 命令行输入 /usr/libexec/java_home -V 可以看到多个 JDK 版本
$ /usr/libexec/java_home -V Matching Java Virtual Machines (2): 11.0.10, x86_64: &amp;#34;OpenJDK 11.0.10&amp;#34; /Users/zhanglei/Library/Java/JavaVirtualMachines/adopt-openj9-11.0.10/Contents/Home 1.8.0_201, x86_64: &amp;#34;Java SE 8&amp;#34; /Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home /Users/zhanglei/Library/Java/JavaVirtualMachines/adopt-openj9-11.0.10/Contents/Home 查看当前使用的 JDK 版本 $ java -version java version &amp;#34;1.8.0_201&amp;#34; Java(TM) SE Runtime Environment (build 1.8.0_201-b09) Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) 切换 JDK 切换到 JDK 11.0.10 版本，并查看切换后的 JDK 版本
$ export JAVA_HOME=`/usr/libexec/java_home -v 11.0.10` $ java -version openjdk version &amp;#34;11.</description></item><item><title>Setting up Redis for Production</title><link>https://coolbeevip.github.io/posts/redis/setting-up-redis-for-production/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/setting-up-redis-for-production/</guid><description>安装 官方建议的安装方法是从源代码编译安装，您可以从 redis.io 下载最新稳定版的 TAR 包
wget https://download.redis.io/releases/redis-6.2.5.tar.gz tar xvzf redis-6.2.5.tar.gz cd redis-6.2.5 make 此时，您可以通过键入 make test 来测试您的构建是否正常工作。编译后 redis-6.2.5/src 目录填充了一部分可执行文件。 最好将编译后的 Redis 执行文件都复制到适当的位置，或者使用以下命令手动复制（假设我们的安装路径是 /usr/local/redis）：
# 可执行文件 sudo mkdir -p /usr/local/redis/bin sudo cp src/redis-server /usr/local/redis/bin sudo cp src/redis-cli /usr/local/redis/bin sudo cp src/redis-sentinel /usr/local/redis/bin sudo cp src/redis-benchmark /usr/local/redis/bin sudo cp src/redis-check-aof /usr/local/redis/bin sudo cp src/redis-check-rdb /usr/local/redis/bin # 配置文件 sudo mkdir -p /usr/local/redis/conf sudo cp redis.conf /usr/local/redis/conf sudo cp sentinel.conf /usr/local/redis/conf # 数据目录 sudo mkdir -p /usr/local/redis/data sudo mkdir -p /usr/local/redis/log # 创建链接 sudo ln -s /usr/local/redis/bin/redis-server /usr/bin/redis-server sudo ln -s /usr/local/redis/bin/redis-cli /usr/bin/redis-cli 提示： 复制完毕后，您可以删除 redis-6.</description></item><item><title>Using Redis as a Cache</title><link>https://coolbeevip.github.io/posts/redis/using-redis-as-a-cache/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/using-redis-as-a-cache/</guid><description>当 Redis 用作缓存时，通常可以方便地让它在您添加新数据时自动驱逐旧数据。Redis 支持 6 种驱逐策略，你可以使用 maxmemory-policy 修改驱逐策略。默认是不驱逐，也就是说如果使用的内存超过了 maxmemory 限制，将提示 OOM。
你可以在 redis.conf 通过 maxmemory 2gb 设置，也可以通过 config set maxmemory 2gb 方式动态设置，注意： 在64bit系统下，maxmemory设置为0表示不限制内存使用，在32bit系统下，maxmemory不能超过3GB
驱逐策略 noenviction: 禁止驱逐数据(默认淘汰策略) 当 redis 内存数据达到 maxmemory，在该策略下，直接返回OOM错误； volatile-lru: 驱逐已设置过期时间的内存数据集中最近最少使用的数据； volatile-ttl: 驱逐已设置过期时间的内存数据集中即将过期的数据； volatile-random: 驱逐已设置过期时间的内存数据集中任意挑选数据； allkeys-lru: 驱逐内存数据集中最近最少使用的数据； allkeys-random: 驱逐数据集中任意挑选数据； volatile-lfu 驱逐已设置过期时间的内存数据集中使用频率最少的数据；（since 4.0） allkeys-lfu 驱逐内存数据集中使用频率最少的数据；（since 4.0） 如果 KEY 未设置过期时间，那么 volatile-random、volatile-ttl 和 volatile-lru 等同于 noenviction。
驱逐程序如何运作 重要的是要了解驱逐过程的工作方式如下：
客户端运行新命令，导致添加更多数据。 Redis 检查内存使用情况，如果大于 maxmemory limit ，则根据策略驱逐键。 执行新命令，等等。 所以我们不断地越过内存限制的边界，越过它，然后通过驱逐键返回到限制之下。 如果某个命令导致使用大量内存一段时间，则内存限制可能会明显超出。</description></item><item><title>Kafka Commands</title><link>https://coolbeevip.github.io/posts/kafka-commands/</link><pubDate>Tue, 28 Jul 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kafka-commands/</guid><description>常用 Kafka 命令
Topics 查询 topic 列表
./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --list 查看 topic 描述
./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe --topic my-topic Consumer Groups 查询消费组列表
./bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list 查询指定的组各 topic 消息消费情况
./bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group my-group</description></item><item><title>MySQL Commands</title><link>https://coolbeevip.github.io/posts/mysql-commands/</link><pubDate>Mon, 11 May 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/mysql-commands/</guid><description>常用 MySQL 命令
连接数配置 查看允许的最大连接数 show variables like &amp;#39;%max_connection%&amp;#39;; 如果过去曾达到此限制，则可以使用以下方法检查 SHOW GLOBAL STATUS LIKE &amp;#39;max_use%&amp;#39;; 配置用户的最大并发连接数 GRANT USAGE ON *.* TO &amp;#39;repl&amp;#39;@&amp;#39;%&amp;#39; WITH MAX_CONNECTIONS_PER_HOUR 100 MAX_USER_CONNECTIONS 10; 查看用户的最大并发连接数 SELECT User, Host, max_connections, max_user_connections FROM mysql.user; 设置最大连接数 set global max_connections=1000; 查看当前连接数 show status like &amp;#39;Threads%&amp;#39;; Threads_cached 当前线程池中缓存有多少空闲线程 Threads_connected 当前的连接数 ( 也就是线程数 ) Threads_running 已经创建的线程总数 Threads_created 当前激活的线程数 ( Threads_connected 中的线程有些可能处于休眠状态 ) thread_cache_size 值过小会导致频繁创建线程，直接反映就是 show status 查看 Threads_created 值过大。 当 Threads_cached 越来越少 但 Threads_connected 始终不降 且 Threads_created 持续升高 这时可适当增加 thread_cache_size 的大小</description></item><item><title>Maven Projects Best Practices</title><link>https://coolbeevip.github.io/posts/best-practices-for-structuring-maven-projects-and-modules/</link><pubDate>Sat, 02 May 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/best-practices-for-structuring-maven-projects-and-modules/</guid><description>本文整理构建Maven项目和模块的最佳实践的关键事项，其中包含依赖、版本、属性、模块划分等关键因素，推荐使用 Maven 3.6.3 及以上版本。 为了便于理解，我们假设有一个 API 网关项目，这个网关项目包含服务端、客户端、通知服务端支持插件。
目标 通过多模块方式组织项目 管理项目版本、依赖，属性 规划模块依赖关系 主项目 POM 每个项目都应该在项目根目录下有一个主 POM 文件，并通过主 POM 文件管理下级子模块。在主 POM 中至少会使用一下标签
properties: 定义字符集编码、JDK 版本、插件版本; modules: 下级子模块; pluginRepositories: 插件仓库地址（非必须，主要解决国内访问慢的问题）; repositories: 定义 Maven 私服地址; distributionManagement: 定义发布用 Maven 私服地址 pluginManagement: 定义管理类插件版本 例如：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;build xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;com.coolbeevip.apigateway&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;apigateway-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;!-- project --&amp;gt; &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt; &amp;lt;project.reporting.outputEncoding&amp;gt;UTF-8&amp;lt;/project.reporting.outputEncoding&amp;gt; &amp;lt;maven.compiler.encoding&amp;gt;UTF-8&amp;lt;/maven.compiler.encoding&amp;gt; &amp;lt;maven.compiler.source&amp;gt;8&amp;lt;/maven.compiler.source&amp;gt; &amp;lt;maven.compiler.target&amp;gt;8&amp;lt;/maven.compiler.target&amp;gt; &amp;lt;!-- plugins version --&amp;gt; &amp;lt;maven-compiler-plugin.version&amp;gt;3.1&amp;lt;/maven-compiler-plugin.version&amp;gt; &amp;lt;jacoco-maven-plugin.version&amp;gt;0.8.6&amp;lt;/jacoco-maven-plugin.version&amp;gt; &amp;lt;docker-maven-plugin.</description></item><item><title>Git Squash Commits</title><link>https://coolbeevip.github.io/posts/git-command-commit-squash/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-command-commit-squash/</guid><description>压缩合并 Commits，将多个 commit 整理合并的方法，这样可以使提交记录更加清晰
查看提交记录，选择你要合并的范围 git log commit 6d757f70af289b5a90d00bd5e4b93d892d64a258 (HEAD -&amp;gt; SCB-1669) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Thu Dec 19 13:53:26 2019 +0800 SCB-1669 Fixed reverse compensation sort bug in FSM commit 37e0c5d99d0e6dae188cbd78f543ba69433b928f (origin/SCB-1669) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Thu Dec 19 02:00:20 2019 +0800 SCB-1669 Fixed Reverse compensation sort bug in FSM commit b4ea8717a86d1eba1956d21727d05c466ff6d8a2 (upstream/master, origin/master, origin/HEAD, master) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Tue Dec 10 16:25:48 2019 +0800 SCB-1658 Improve encapsulation on txEntityMap of SagaData 可以看到最后两次提交，都是为了修复 SCB-1669 这个问题，此时我想合并最后两次提交 6d757f70af289b5a90d00bd5e4b93d892d64a258 和 37e0c5d99d0e6dae188cbd78f543ba69433b928f</description></item><item><title>Git Stash</title><link>https://coolbeevip.github.io/posts/git-command-commit-stash/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-command-commit-stash/</guid><description>你在当前分支上开发代码，此时不想 commit，但是又想切换到其他分支完成其他的工作，此时可以用 stash
在当前分支执行 stash 将当前分支未提交的代码隐藏起来 $ git stash Saved working directory and index state WIP on SCB-1577: 2554be3d SCB-1593 Add notice for Boringssl support ciphers (base) bogon:servicecomb-pack zhanglei$ 此时你可以看到已经存储到一个id为 2554be3d 里了，这时你可以用 git status 查看已经没有要提交的内容了
git status On branch SCB-1577 nothing to commit, working tree clean (base) bogon:servicecomb-pack zhanglei$ 这时你就可以切换到其他分支开始新的工作 (base) bogon:servicecomb-pack zhanglei$ git checkout master Switched to branch &amp;#39;master&amp;#39; Your branch is up to date with &amp;#39;origin/master&amp;#39;.</description></item><item><title>Synchronizing Your Forked Git Project</title><link>https://coolbeevip.github.io/posts/git-command-rebase-upstream/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-command-rebase-upstream/</guid><description>当你 fork 一个仓库后，可以时用此方法使你 fork 后的仓库 master 分支保持和上游 master 分支的同步
使用 rebase 命令同步上游 master 分支到你本地的 master 分支，并推送到你 fork 后的仓库
git fetch upstream git checkout master git rebase upstream/master git push -f origin master 或者你确定放弃你本地所有的修改，则可以简单的重置为上游版本
git fetch upstream git checkout master git reset --hard upstream/master git push -f origin master 如果你也想同步 master 分支的修改到你的功能分支
git checkout &amp;lt;分支名&amp;gt; git rebase master git push -f origin &amp;lt;分支名&amp;gt;</description></item><item><title>Git Reset HEAD</title><link>https://coolbeevip.github.io/posts/git-reset-head/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-reset-head/</guid><description>Git 分支非常有用，您可以根据需要创建一个新分支，合并一个分支或删除一个分支。 您可以使用许多 git 命令来管理 git 中的分支。
当您使用 git checkout 分支时，HEAD会指出最后的提交。 简单来说，您可以说 Git HEAD 是当前分支。 每当您签出一个分支或创建一个新分支时，Git HEAD 都会转移它。
HEAD 是对当前检出分支中最后一次提交的引用。
在存储库中，HEAD 始终指向当前分支的起点。 换句话说，HEAD 是指向下一个提交的父对象或下一个提交将发生的地方的指针。
更具体地说，HEAD 是一个移动指针，它可以引用或可以不引用当前分支，但是它始终引用当前提交。
什么是 HEAD^ 插入符（^）是 Commit 的父级。
什么是 HEAD~ 代字号（〜）是一行几个字符（^）的简写字符。
HEAD〜2 与 HEAD ^^ 的作用相同。
如果写数字，则使用的默认值为1，因此 HEAD〜 等价于 HEAD ^。
如何检查HEAD的状态 您可以使用以下命令查看当前 Git HEAD 指向的位置：
$ cat .git/HEAD ref: refs/heads/master 并且，你可以使用以下命令查看指向 HEAD 的 commit 的 Hash ID：
$ git rev-parse --short HEAD 6f975a5 Detached HEAD HEAD 是您目前的工作分支。 当您尝试 git checkout 分支时，HEAD 指向该分支的顶部，这样您就可以继续工作而没有任何困难。</description></item><item><title>Git Revert</title><link>https://coolbeevip.github.io/posts/git-command-revert/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-command-revert/</guid><description>撤销上一次提交
$ git revert HEAD 撤销上两次提交
ISSUE-4 解决网关服务日志中无法正确显示经过代理访问的请求端 IP 问题 $ git revert [倒数第一个提交] [倒数第二个提交]</description></item><item><title>Important JVM Options</title><link>https://coolbeevip.github.io/posts/java-jvm-options/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java-jvm-options/</guid><description>Heap Memory -XX:MetaspaceSize Metaspace 空间初始大小，如果不设置的话，默认是20.79M。这个初始大小是触发首次 Metaspace Full GC 的阈值，例如 -XX:MetaspaceSize=128M
-XX:MaxMetaspaceSize Metaspace 最大值，默认不限制大小，但是线上环境建议设置，例如 -XX:MaxMetaspaceSize=512M
GC -Xnoclassgc 表示关闭JVM对类的垃圾回收，缺省情况下，当一个类没有任何活动实例时，JVM 就会从内存中卸装该类，但是这样会使性能下降。如果关闭类垃圾回收，就可以消除由于多次装入和卸装同一个类而造成的开销
-XX:+UseParNewGC 设置年轻代为并行收集
-XX:MaxTenuringThreshold 控制新生代需要经历多少次GC​晋升到老年代中的最大阈值，默认值 15
-XX:+CMSParallelRemarkEnabled CMS收集算法步骤如下：初始标记 -&amp;gt; 并发标记 -&amp;gt; 重新标记 -&amp;gt; 标记清除。 其中 初始标记和重新标记都需要STW，即暂停用户线程。 CMSParallelRemarkEnabled参数可以让重新标记阶段进行并行重新标记，减少暂停时间
-XX:SurvivorRatio 设置 Eden、S0、S1 分配比例，默认值是 8
-XX:SurvivorRatio=5 表示 Eden 占 50%，S0、S1 平分剩余空间
-XX:+UseCompressedOops In short, don&amp;rsquo;t turn it on, use a version which has it on by default.
https://stackoverflow.com/questions/11054548/what-does-the-usecompressedoops-jvm-flag-do-and-when-should-i-use-it
-XX:+DisableExplicitGC 禁止 System.gc() 触发 GC 操作，当没有开启 DisableExplicitGC 这个参数时,你会发现JVM每个小时会执行一次Full GC,这是因为JVM在做分布式GC,为RMI服务的, 可以通过 sun.</description></item><item><title>Linux Command - Disk</title><link>https://coolbeevip.github.io/posts/linux-commands-disk/</link><pubDate>Mon, 06 May 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux-commands-disk/</guid><description>Linux 磁盘相关命令
磁盘IO dd [root@localhost ~]# dd if=/dev/zero of=./a.dat bs=8K count=1M conv=fdatasync 记录了8192+0 的读入 记录了8192+0 的写出 8589934592字节(8.6 GB)已复制，14.8606 秒，578 MB/秒 [root@localhost ~]# dd if=./a.dat of=/dev/null bs=1M count=8k iflag=direct 记录了8192+0 的读入 记录了8192+0 的写出 8589934592字节(8.6 GB)已复制，14.2462 秒，603 MB/秒 磁盘空间 df 查看磁盘各个分区的空间大小、占用、可用等信息
$ df -h Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk1s5 466Gi 10Gi 128Gi 8% 488463 4881964417 0% / devfs 192Ki 192Ki 0Bi 100% 663 0 100% /dev /dev/disk1s1 466Gi 318Gi 128Gi 72% 4557528 4877895352 0% /System/Volumes/Data /dev/disk1s4 466Gi 8.</description></item><item><title>Git Commands</title><link>https://coolbeevip.github.io/posts/git-commands/</link><pubDate>Sat, 06 Apr 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-commands/</guid><description>常用 Git 命令
Init 在已有目录中初始化 GIT 仓库
$ git init $ git remote add origin &amp;lt;仓库地址&amp;gt; $ git add . $ git commit -m &amp;quot;Initial commit&amp;quot; $ git push -u origin master Branch 创建分支
git checkout -b &amp;lt;分支名&amp;gt; 推送分支
git push origin &amp;lt;分支名&amp;gt; 修改分支名
git branch -m &amp;lt;旧分支名&amp;gt; &amp;lt;新分支名&amp;gt; 删除本地分支
git branch -D &amp;lt;分支名&amp;gt; 删除远程分支
git push origin --delete &amp;lt;分支名&amp;gt; 拉取远程分支
git fetch origin &amp;lt;分支名&amp;gt; 拉取远程分支并切换
git checkout -b &amp;lt;分支名&amp;gt; origin/&amp;lt;分支名&amp;gt; 当前分支会退到指定版本</description></item><item><title>Docker Commands</title><link>https://coolbeevip.github.io/posts/docker-commands/</link><pubDate>Wed, 06 Feb 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker-commands/</guid><description>常用 Docker 命令记录
镜像 删除所有镜像 docker rmi -f $(docker images | awk &amp;#39;{print $3}&amp;#39;) 删除所有 dangling 镜像 docker rmi -f $(docker images -a | grep &amp;#34;&amp;lt;none&amp;gt;&amp;#34; | awk &amp;#39;{print $3}&amp;#39;) 导出镜像 docker save -o postgres_9.6.tar postgres:9.6 导入镜像 docker load -i postgres_9.6.tar 容器 删除所有 Exited 容器 docker rm $(docker ps -a | grep Exited | awk &amp;#39;{print $1}&amp;#39;) 停止并删除所有容器 docker stop $(docker ps | awk &amp;#39;{print $1}&amp;#39;) docker rm -f $(docker ps -a | awk &amp;#39;{print $1}&amp;#39;) 停止 dead 容器 删除实例时提示 device or resource busy</description></item><item><title>Flyway hung on the MySQL Router + MGR</title><link>https://coolbeevip.github.io/posts/flyway-hung-on-mysql-router-mgr/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/flyway-hung-on-mysql-router-mgr/</guid><description>Flyway 连接 MySQL Router 后启动卡在 GET_LOCK 语句
现象 MySQL MGR + Router 部署高可用集群 Flyway 客户端使用 jdbc:mysql:loadbalance 连接 初始化 Schema History 表、或者执行多个 SQL 脚本时 当满足以上条件时，Flyway 会卡在初始化阶段，经过分析发现停顿在执行 GET_LOCK 语句时
原因 Flyway 默认在执行 DDL 脚本时不启用事务，在初始化时 Flyway 会先执行 GET_LOCK 锁定数据库，然后再执行 DDL 脚本。当使用 jdbc:mysql:loadbalance 连接时，会随机选择一个数据源，如果执行 GET_LOCK 和 执行 DDL 不是一个数据源，就会导致执行等待锁释放
解决办法 在启动时设置 group=true 参数，这样 Flyway 在初始化时就会启用事务，确保一个事务内的 DDL 都在一个数据源执行
ISSUE-3154
public class FlywayTestManual { String url=&amp;#34;jdbc:mysql:loadbalance://192.168.51.206:3810,192.168.51.207:3810/nc_notifier?roundRobinLoadBalance=false&amp;amp;characterEncoding=utf8&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;useSSL=false&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=GMT%2B8&amp;amp;allowMultiQueries=true&amp;amp;allowPublicKeyRetrieval=true&amp;#34;; String user=&amp;#34;user&amp;#34;; String password=&amp;#34;pass&amp;#34;; @Test public void test(){ Flyway flyway = Flyway.</description></item><item><title>Flyway Support Oracle</title><link>https://coolbeevip.github.io/posts/java-flyway-support-oracle/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java-flyway-support-oracle/</guid><description>记录在使用 Flyway 管理 Oracle 数据库脚本时遇到的一些问题，Flyway 5.2.1 - 7.7.3 都存在此问题。
1. Flyway not support Oracle 11g 异常信息
Caused by: org.flywaydb.core.internal.license.FlywayEditionUpgradeRequiredException: Flyway Enterprise Edition or Oracle upgrade required: Oracle 11.2 is no longer supported by Flyway Community Edition, but still supported by Flyway Enterprise Edition. at org.flywaydb.core.internal.database.base.Database.ensureDatabaseNotOlderThanOtherwiseRecommendUpgradeToFlywayEdition(Database.java:173) at org.flywaydb.core.internal.database.oracle.OracleDatabase.ensureSupported(OracleDatabase.java:91) at org.flywaydb.core.Flyway.execute(Flyway.java:514) at org.flywaydb.core.Flyway.migrate(Flyway.java:159) at org.springframework.boot.autoconfigure.flyway.FlywayMigrationInitializer.afterPropertiesSet(FlywayMigrationInitializer.java:65) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1855) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1792) ... 19 common frames omitted 修改 Flyway 5.2.4 OracleDatabase.java 社区版本做了版本号限制 修改 Flyway 6.</description></item><item><title>To roll up Flyway incremental changes into 1 file</title><link>https://coolbeevip.github.io/posts/java-flyway-merge-script-step/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java-flyway-merge-script-step/</guid><description>Flyway 通过 SQL Patch 脚本的方式管理数据库脚本版本，开发一段时间后会积攒大量脚本。当一个版本稳定后我们希望合并成一个全量脚本
1.首先对齐程序与数据库中的脚本版本号 查看程序中脚本版本清单，例如：程序中有三个版本的脚本
V1.0.0.0__init.sql V1.0.0.1__add_user_table.sql V1.0.0.2__modify_user_table.sql 查看数据库中历史版本记录表 (默认是 flyway_schema_history) 中执行过的脚本版本，例如：
versions description script success 1.0.0.0 init.sql V1.0.0.0__init.sql 1 1.0.0.1 add_user_table.sql V1.0.0.1__add_user_table.sql 1 1.0.0.2 modify_user_table V1.0.0.2__modify_user_table.sql 1 这里只摘取了关键字段，你可以看到每个版本都已经执行，并且执行都是成功的 success=1
至此：你已经对齐了程序和数据库中脚本版本号，可以开始准备合并了
2.合并程序中的SQL脚本 合并多个脚本的内容到最大版本号的文件中，例如：将 V1.0.0.0__init.sql, V1.0.0.1__add_user_table.sql, V1.0.0.2__modify_user_table.sql 合并为 V1.0.0.2__init.sql
注意： 不是简单的文件合并，而是最终执行结果的合并
3.重新打包程序 只包含合 V1.0.0.2__init.sql 脚本的程序
4.停止所有老版本的程序 包含 V1.0.0.0__init.sql,V1.0.0.1__add_user_table.sql,V1.0.0.2__modify_user_table.sql 老脚本的程序
5.删除数据库中的版本历史表 默认是 flyway_schema_history
6.重启应用程序 在程序启动时设置基线版本参数为当前版本，设置这个参数的目的是告诉 Flyway 当前已经执行过 1.</description></item><item><title>Maven Commands</title><link>https://coolbeevip.github.io/posts/maven-commands/</link><pubDate>Fri, 23 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven-commands/</guid><description>常用 Maven 命令
Parameters -D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试； -P 指定 Profile 配置，可以用于区分环境； -e 显示maven运行出错的信息； -o 离线执行命令,即不去远程仓库更新包； -f 强制指定使用 POM 文件，或者包含 POM 文件的目录 -pl 选项后可跟随{groupId}:{artifactId}或者所选模块的相对路径(多个模块以逗号分隔) -am 表示同时处理选定模块所依赖的模块 -amd 表示同时处理依赖选定模块的模块 -rf 表示从指定模块开始继续处理 -N 表示不递归子模块 -X 显示maven允许的debug信息； -U 强制去远程更新 snapshot的插件或依赖，默认每天只更新一次。 &amp;ndash;no-snapshot-updates 禁止更新 snapshot Dependency 显示maven依赖数
mvn dependency:tree 显示maven依赖列表
mvn dependency:list 下载依赖包的源码
mvn dependency:sources Maven Wrapper 自动安装 maven 的包装器（适合不想手动安装Maven的用户），使用插件Maven Wrapper plugin将其自动化安装指定版本的 Maven
mvn -N io.takari:maven:wrapper -Dmaven=3.6.3 这个命令会在你的项目中生成如下文件，请将这些文件与源代码一起管理
mvnw: 这是 Linux Script 可执行文件，用来代替 mvn mvnw.</description></item><item><title>Estimate host capacity based on QPS</title><link>https://coolbeevip.github.io/posts/stress-testing-host-estimate-with-qps/</link><pubDate>Wed, 07 Mar 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/stress-testing-host-estimate-with-qps/</guid><description>通过单个服务器压测的 QPS 估算需要的服务器数量
已知 QPS 和期望每笔耗时，估算服务器数量 服务器数量 \( = QPS \div (1000 \div 每笔毫秒) \div 每服务器CPU个数 \)
例如：
QPS：每秒处理3200笔 每笔毫秒：50ms 每个服务器CPU个数：16 服务器数量 \( 3200_{qps} \div (1000_{ms} \div 50_{ms}) \div 16_{cpu} = 10_{台} \)
已知 QPS 以及服务器数量，估算每笔耗时 每笔耗时毫秒 \( = 1000 \div ( QPS \div ( 服务器数量 \times 每服务器CPU个数 ) ) \)
例如：
QPS：每秒处理3200笔 服务器数量：10 每服务器CPU个数：16 每笔耗时毫秒 \( 1000 \div ( 3200 \div ( 10 \times 16 ) ) = 50_{ms}\)</description></item></channel></rss>