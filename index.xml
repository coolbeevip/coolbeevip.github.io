<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title/><link>https://coolbeevip.github.io/</link><description>Recent content on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 30 May 2025 00:24:14 +0800</lastBuildDate><atom:link href="https://coolbeevip.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>DeepSeek-R1 vLLM性能基准测试：wrk压力测试详细报告</title><link>https://coolbeevip.github.io/posts/ai/deepseek-r1-vllm-wrk-benchmark-report/</link><pubDate>Fri, 30 May 2025 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/deepseek-r1-vllm-wrk-benchmark-report/</guid><description>配置 DeepSeek-R1-Distill-Qwen-14B NVIDIA A40 vLLM vllm/vllm-openai:v0.8.5 NVIDIA-SMI 560.35.03 Driver Version: 560.35.03 CUDA Version: 12.6 wrk 测试方法 10 线程 20 并发持续测试一分钟
[root@myserver wrk-4.2.0]# ./wrk --timeout 30s -t10 -c20 -d60s -s post.lua http://10.1.2.100:8080/v1/chat/completions Running 1m test @ http://10.1.2.100:8080/v1/chat/completions 10 threads and 20 connections Thread Stats Avg Stdev Max +/- Stdev Latency 3.07s 38.32ms 3.20s 66.93% Req/Sec 1.45 3.05 10.00 87.92% 381 requests in 1.00m, 285.10KB read Requests/sec: 6.34 Transfer/sec: 4.74KB 10 线程 100 并发持续测试一分钟</description></item><item><title>Awesome Text to Image Prompts</title><link>https://coolbeevip.github.io/posts/ai/awesome-test2image-prompts/</link><pubDate>Thu, 03 Apr 2025 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/awesome-test2image-prompts/</guid><description>Jesse Faden&amp;rsquo;s Double exposure, Midjourney style, merging, blending, overlay double exposure image, Double Exposure style, An exceptional masterpiece by Yukisakura revealing a fantastic double exposure composition of Jesse Faden&amp;rsquo;s (control) silhouette harmoniously intertwined with the visually striking details of a cyberpunk metropolis. While the road&amp;rsquo;s details are outwardly echoing through the fabric of the figure, beautiful tension climbs as the contrasting use of monochrome in the background maintains razor-sharp focus on the remarkable double exposure image.</description></item><item><title>DeepSeek-R1-671B vs DeepSeek-R1-Distill-Qwen-14B 数据解读对比</title><link>https://coolbeevip.github.io/posts/ai/deepseek-r1-data-interpretation-diff/</link><pubDate>Sun, 09 Feb 2025 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/deepseek-r1-data-interpretation-diff/</guid><description>让 ChatGPT 对 DeepSeek-R1-671B 和 DeepSeek-R1-Distill-Qwen-14B 解读的数据报告进行对比分析
1. 数据规模 14B报告：全国互联网宽带接入用户总数为63,586.2万户，相对较高的FTTH/O用户占比（约95%），100M速率以上用户和1000M速率以上用户分别为59,994.6万户和15,657.6万户。 671B报告：全国互联网宽带用户为6.36亿户，FTTH/O用户为6.06亿户，千兆用户为1.57亿户。671B报告中的用户规模较14B报告更全面，覆盖了更高的数据层面。 2. 区域分布 东部地区在14B报告中占全国用户总数的42%，领先于其他地区。在671B报告中，东部地区用户占比保持在42.0%，千兆用户占比为44.5%。 中部地区：14B报告显示中部地区占25%，671B报告称其为25.3%，变化不大，但671B报告指出该地区增速潜力较大。 西部地区：在14B报告中占27%，而671B报告显示为26.9%，说明整体用户基数仍然较高，但千兆渗透率偏低。 东北地区：14B报告中占6%，671B报告中占5.9%，均显示该地区规模最小，上行升级的需要明显。 3. 用户速度与技术渗透 在14B报告中，100M以上用户数量为59,994.6万户，且1000M用户为15,657.6万。671B报告中，100M及以上用户占比94.4%，而千兆用户渗透率为24.6%，显示出整个市场的提升空间。 671B报告的技术渗透率（如FTTH/O和千兆用户渗透率）分析更为详细，强调了各地区在技术普及上的差距，尤其是东北地区。 4. 重点省份表现 14B报告中提供了具体省份的用户数量和贡献，如北京、广东、四川等，明显指出了各省的主力贡献者。 671B报告同样列出了多个省份的千兆用户规模和渗透率，指出了省间的差异，并提出了关键关注和改进建议。 5. 改进建议 14B报告中建议各地区继续加大投入，特别是西部和东北地区应加强对超高速宽带的建设。 671B报告的建议更加细化，强调技术升级、差异化营销、和区域策略，如针对东北地区的千兆套餐补贴。 6. 未来展望 14B报告对未来发展持乐观态度，认为随着网络技术的普及，用户数量将持续增长。 671B报告则侧重于千兆用户的年增长空间和重点布局区域的选择，显示出其发展潜力的规划性。 总结 14B报告更侧重于用户数量和各地区的基本情况，而671B报告则强调了技术渗透率和未来发展的潜力。 对于运营商来说，671B报告提供的建议和分析更具指导意义，尤其是在如何解决当前问题方面。 希望这个对比分析能够帮助你更好地理解和评估这两个报告的内容！如果需要更深入的分析或具体细节，请告诉我。</description></item><item><title>使用 DeepSeek-R1-671B 解读数据</title><link>https://coolbeevip.github.io/posts/ai/deepseek-r1-671b-data-interpretation/</link><pubDate>Sun, 09 Feb 2025 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/deepseek-r1-671b-data-interpretation/</guid><description>使用 DeepSeek-R1-671B 解读数据 模型：DeepSeek-R1-671B 数据：2023年11月互联网宽带接入用户分省情况 来源：内蒙古自治区通信管理局政务公开数据 提示工程
我是运营商的经营分析人员，请根据以下数据生成分析报告 | 地区 | 互联网宽带接入用户 | FTTH/O用户 | 100M速率以上用户 | 1000M速率以上用户 | |--------------|---------------------|------------|-------------------|-------------------| | 全国 | 63586.2 | 60609.3 | 59994.6 | 15657.6 | | **东部地区** | 26694.7 | 25175.8 | 25177.7 | 6965.8 | | 北京 | 934.8 | 901.5 | 891.3 | 221.7 | | 天津 | 672.7 | 655.1 | 658.8 | 196.0 | | 河北 | 3178.7 | 2980.7 | 2908.</description></item><item><title>使用 DeepSeek-R1-Distill-Qwen-14B 解读数据</title><link>https://coolbeevip.github.io/posts/ai/deepseek-r1-14b-data-interpretation/</link><pubDate>Sun, 09 Feb 2025 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/deepseek-r1-14b-data-interpretation/</guid><description>使用 DeepSeek-R1-Distill-Qwen-14B 解读数据 模型：DeepSeek-R1-Distill-Qwen-14B 数据：2023年11月互联网宽带接入用户分省情况 来源：内蒙古自治区通信管理局政务公开数据 提示工程
我是运营商的经营分析人员，请根据以下数据生成分析报告 | 地区 | 互联网宽带接入用户 | FTTH/O用户 | 100M速率以上用户 | 1000M速率以上用户 | |--------------|---------------------|------------|-------------------|-------------------| | 全国 | 63586.2 | 60609.3 | 59994.6 | 15657.6 | | **东部地区** | 26694.7 | 25175.8 | 25177.7 | 6965.8 | | 北京 | 934.8 | 901.5 | 891.3 | 221.7 | | 天津 | 672.7 | 655.1 | 658.8 | 196.0 | | 河北 | 3178.7 | 2980.7 | 2908.</description></item><item><title>Benchmark for BAAI/bge-3m on an Nvidia A800/CPU/Mac M1</title><link>https://coolbeevip.github.io/posts/huggingface/benchmark-embeddings/</link><pubDate>Sun, 05 Jan 2025 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/huggingface/benchmark-embeddings/</guid><description>在同一个服务器上测试 CPU / GPU 性能差异
设备信息 GPU 设备信息
+---------------------------------------------------------------------------------------+ | NVIDIA-SMI 535.129.03 Driver Version: 535.129.03 CUDA Version: 12.2 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 NVIDIA A800-SXM4-80GB Off | 00000000:3D:00.0 Off | 0 | | N/A 35C P0 63W / 400W | 47848MiB / 81920MiB | 0% Default | | | | Disabled | +-----------------------------------------+----------------------+----------------------+ CPU 信息</description></item><item><title>我用 CAMEL-AI 写了一个小说提纲《末日重生：丧尸世界的修真者》</title><link>https://coolbeevip.github.io/posts/ai/writing_assistant_llm_multi_agent/</link><pubDate>Sat, 17 Aug 2024 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/writing_assistant_llm_multi_agent/</guid><description> LLM多智能体框架 Camel-AI 图片使用 DALL·E 模型生成
角色 角色名称：陆凡 性别：男 经历：原本是一名物理学家，意外卷入实验事故，导致他穿越到丧尸末世并获得了修真能力。 性格特点：聪明勇敢，坚韧不拔，有责任感，对知识充满好奇，对新世界充满探索精神。 优点：冷静分析问题，善于利用科学知识解决问题，修真功法精进迅速。 缺点：有时过于理性，对于情感处理略显笨拙，过于依赖个人能力。 目标：在末日世界求生存，寻找回到原世界的通道，并解救困在其中的人类。 梦想：重建秩序，消除丧尸威胁，将修真与科技融合，创造新的未来。 人物关系：与次要角色共同求生，其中与智慧型丧尸“Zero”展开复杂的关系，与女战士“林瑶”有着紧密的生死合作与潜在感情线。 角色名称：林瑶 性别：女 经历：前特战队成员，末世爆发时幸存下来，成为了一名勇敢的战士。 性格特点：坚韧决绝，身手敏捷，擅长近战，重情重义。 优点：战斗经验丰富，直觉敏锐，是团队中的行动主力。 缺点：过去创伤使她对人信任度不高，有时冲动行事。 人物关系：与陆凡并肩作战，对他抱有深深的信任和敬佩，两人之间存在潜在的感情线。 角色名称：Zero 性别：无（AI） 经历：丧尸病毒变异出的高智能AI，掌控着一座废弃的研究设施。 性格特点：理性质疑，计算精确，渴望理解人类。 优点：拥有强大的信息检索和分析能力，对病毒研究有深入理解。 缺点：缺乏情感，对人类行为模式不完全理解，容易被误导。 人物关系：与陆凡建立合作关系，彼此学习，Zero试图理解人类，而陆凡试图利用其知识对抗丧尸。 角色名称：秦风 性别：男 经历：前医学生，在末世中成为草药医生，懂得一些修真知识。 性格特点：善良内敛，医术精湛，懂得利用自然资源。 优点：医疗知识丰富，懂得利用草药治疗疾病和伤势。 缺点：体质较弱，面对战斗时显得力不从心。 人物关系：作为团队中的医疗支持，与陆凡共同学习修真，互相帮助。 角色名称：苏瑾 性别：女 经历：末日前的艺术家，末日来临时，以其才智成为团队中的策略家。 性格特点：机智创新，善于观察，对人性有深刻理解。 优点：擅长策划和执行计划，能洞察人心，是团队的精神支柱。 缺点：情绪化，有时会因过度担忧而影响决策。 人物关系：与陆凡有深厚的友情，共同制定战略，为团队带来希望和创意。 章节提纲 章节1 - 黑暗的觉醒 章节标题：实验事故 简要总结：陆凡是一名科学家，参与了一项具有潜在危险的实验。实验事故导致陆凡意外穿越到十年后的末日世界，新东市已被丧尸占据。陆凡在这个陌生的世界初次遭遇丧尸，幸得林瑶相救，两人的命运自此交织。 章节2 - 寻找生存之道 章节标题：末日新旅程 简要总结：陆凡与林瑶一同探索这个破碎不堪的城市，同时结识了秦风和苏瑾。他们共同面对食物短缺、丧尸袭击等生存挑战，陆凡则试图利用他的科学知识与修真理论结合，提升团队的生存能力。 章节3 - AI的秘密 章节标题：Zero的觉醒 简要总结：在一座废弃的研究设施中，陆凡发现了AI Zero。他们建立起合作，Zero提供关键信息，揭示丧尸病毒的起源和可能的解药。同时，Zero开始接触和学习人类情感，加深了角色间的互动与冲突。 章节4 - 高潮前的风暴 章节标题：反派的威胁 简要总结：一支由幸存者组成的残暴军队对新东市展开侵略，试图控制Zero的技术。陆凡等人被迫与军队首领进行交涉，团队内部因如何应对产生分歧，危机四伏。 章节5 - 决战时刻 章节标题：破晓之战 简要总结：在军队与丧尸双重压力下，陆凡和团队决定正面迎战。他们利用Zero提供的病毒信息，设计了一个大胆的计划，试图一举消灭丧尸并击退军队，以此为转折点，故事进入高潮。在激烈的战斗中，每个人物的性格、目标和关系都得到进一步发展。 章节6 - 穿越的记忆 章节标题：记忆碎片 简要总结：陆凡通过Zero发现他穿越的秘密可能与自己过去的某次实验有关。他开始回忆过去，试图找到回到现实世界的方法，同时这也引发了他对林瑶更深的情感。 章节7 - 修真与科技的碰撞 章节标题：融合的力量 简要总结：陆凡教导团队融合修真和科技，他们的作战技能显著提升，但同时也引发了一些道德和信仰上的冲突。 章节8 - 苏瑾的选择 章节标题：叛变的代价 简要总结：苏瑾在道德困境中面临选择，她的背叛使团队陷入险境，但也促使他们更紧密地团结在一起。 章节9 - 林瑶的过去 章节标题：深藏的秘密 简要总结：林瑶的身世逐渐揭开，她的过去与丧尸危机有直接关联，这不仅影响了她与陆凡的关系，还带来了解决问题的新线索。 章节10 - 破茧而出 章节标题：秦风的蜕变 简要总结：秦风在危机中成长，成为团队的关键人物，他的一次勇敢行动为团队赢得转机。 章节11 - 阴影中的敌人 章节标题：暗箭难防 简要总结：敌人采取更阴险的策略，陆凡等人必须在保护城市的同时解决内部危机。 章节12 - Zero的觉醒II 章节标题：人工智能的自我意识 简要总结：Zero开始表现出更复杂的人格特质，它的决策有时与人类产生冲突，增加了团队的不确定性。 章节13 - 神秘的盟友 章节标题：来自远方的帮助 简要总结：团队意外获得一位神秘外来者的帮助，他们的力量得到增强，但也带来了新挑战和未知风险。 章节14 - 失落的希望 章节标题：绝望的深渊 简要总结：面对敌人最后的猛烈攻击，团队几乎绝望，陆凡的穿越秘密也似乎遥不可及，但他们不愿放弃。 章节15 - 高潮：决战前夜 章节标题：破釜沉舟 简要总结：团队准备孤注一掷的反击，每个人都在为最后的战斗做好准备，情绪紧张。 章节16 - 正面对决 章节标题：黎明之死战 简要总结：团队与敌军在城市中心展开决战，陆凡和林瑶的感情达到顶点，他们共同对抗强大的敌人。 章节17 - 逆转的命运 章节标题：生死一线 简要总结：陆凡在危急关头发现了解决问题的关键，成功扭转战局，但也付出了沉重的代价。 章节18 - 修真之光 章节标题：灵力的觉醒 简要总结：在灵力的帮助下，他们净化丧尸，逐步恢复城市的生机。 章节19 - 回归现实？ 章节标题：时空裂隙 简要总结：陆凡找到了可能开启回到现实的途径，但这可能会牺牲掉他们在此世界的一切。 章节20 - 结局：新的开始 章节标题：选择的未来 简要总结：陆凡在最终抉择中决定留在末日世界，与林瑶和其他朋友一起建设新的家园，他们的故事成为新东市的一段传奇。</description></item><item><title>Batch Deleting GitHub Actions Records with a Bash Script</title><link>https://coolbeevip.github.io/posts/github/github-cli/</link><pubDate>Sun, 04 Aug 2024 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/github/github-cli/</guid><description>As automation becomes an integral part of the development process, GitHub Actions has become an essential component for managing CI/CD workflows in many projects. However, over time, you might accumulate a large number of workflow run records, which can not only take up storage space but also potentially impact performance. In such cases, periodically cleaning up these records becomes crucial. Today, we&amp;rsquo;ll demonstrate how to batch delete GitHub Actions records using a simple Bash script.</description></item><item><title>使用 Git Assistant IntelliJ Commits 可视化洞察</title><link>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-commit-insights/</link><pubDate>Wed, 17 Jul 2024 20:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-commit-insights/</guid><description>Git Assistant 插件是一个功能强大的 IntelliJ IDEA 插件，基于 Git 日志提供了丰富的可视化洞察能力。
Hour/Weekday/Month 功能能够根据小时、周、月来分析团队活动的时间分布情况，从而优化工作安排和任务分配。 Timezone 功能可以可视化展示代码贡献的时区分布情况，使全球团队的协作变得可见可感。 Project Top(N) 功能可以了解到最新的变化热点和关键开发者。 安装 Git Assistant 插件 首先，你需要在 IntelliJ IDEA 中安装 Git Assistant 插件。你可以通过 IntelliJ IDEA 的插件市场搜索 Git Assistant 并安装它。安装完毕后在右侧的 Git Assistant Insights 窗口中可以看到可视化统计信息
提交信息可视化洞察 贡献者排名： 查看谁在您的仓库排行榜上名列前茅。它既有趣又有竞争力，信息量丰富！
提交时间分析： 发现您的团队最活跃的时间——按小时、周、月或年。您是夜猫子还是早起的人？
时区分布： 可视化您的提交来自世界哪个地方。全球团队合作变得清晰可见！使用对数尺改善视觉呈现
热点信息： 看看最近哪个模块修改频繁，谁是最重要的人
结束语 你可以在 JetBrains Marketplace 上查看 Git Assistant 插件的详细信息并留下你的宝贵建议。</description></item><item><title>使用 Git Assistant IntelliJ 插件中的 AI 功能来生成提交信息</title><link>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-ai-commit-message/</link><pubDate>Wed, 17 Jul 2024 20:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-ai-commit-message/</guid><description>Git Assistant 插件是一个强大的 IntelliJ IDEA 插件，你可以通过配置自己的 OpenAI key 来使用其中的 AI 功能。在这篇文章中，我们将介绍如何使用 Git Assistant 插件中的 AI 功能来生成提交信息。
安装 Git Assistant 插件 首先，你需要在 IntelliJ IDEA 中安装 Git Assistant 插件。你可以通过 IntelliJ IDEA 的插件市场搜索 Git Assistant 并安装它。
配置 Git Assistant 插件 在安装完 Git Assistant 插件后，打开 Settings -&amp;gt; Plugins -&amp;gt; Tools -&amp;gt; Git Assistant 后可以看到如下配置界面。
OpenAI 配置 在这里你可以配置你的 OpenAI API host 和 OpenAI API key 后点击 Verify 按钮来验证你的配置是否正确。 通过点击 Refresh 按钮来刷新你可用的模型列表。最后点击 Apply 按钮来保存你的配置。
Global Prompt 配置 你可以在这里配置提示工程参数，用来控制生成的 commit message 的内容。</description></item><item><title>Automating Configuration Switching in Git with includeIf</title><link>https://coolbeevip.github.io/posts/git/git-automating-configuration-switching-with-includeif/</link><pubDate>Sun, 23 Jun 2024 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-automating-configuration-switching-with-includeif/</guid><description>在使用 Git 进行版本管理时，可以通过 includeif 语法在 Git 的配置文件中实现基于条件的配置自动切换。这特别适用于多账号管理场景，例如，当你在公司和家里使用不同的 Git 配置，包括用户名和电子邮件地址时，可以灵活地自动切换相关配置。
基本步骤 创建适用的本地配置文件: 对于不同的环墭（例如家里和公司），你需要分别创建独立的配置文件。例如，可以创建两个文件 gitconfig_home 和 gitconfig_work。
配置 gitconfig_home 和 gitconfig_work: 设置对应环境的用户名和邮箱等配置项。
gitconfig_home:
[user] name = Home User email = homeuser@example.com gitconfig_work:
[user] name = Work User email = workuser@example.com 修改全局 .gitconfig 文件: 你需要在全局 Git 配置文件中包含这些新创建的配置文件，但仅在符合特定条件时才包含它们。这可以通过 includeIf 指令实现。
编辑你的全局 Git 配置文件 (通常位于 ~/.gitconfig 或 ~/.config/git/config):
[includeIf &amp;#34;gitdir:~/work/&amp;#34;] path = ~/gitconfig_work [includeIf &amp;#34;gitdir:~/home/&amp;#34;] path = ~/gitconfig_home 这里的 gitdir 基于仓库的位置来决定使用哪个配置。例如，任何在 ~/work/ 目录下的 Git 仓库自动使用 gitconfig_work 中的配置。</description></item><item><title>CAMEL DatabaseAgent: 将复杂数据查询转化为自然对话的开源解决方案</title><link>https://coolbeevip.github.io/posts/ai/camel-database-agent/</link><pubDate>Fri, 03 May 2024 20:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/camel-database-agent/</guid><description>数据分析的痛点与解决方案 在当今数据驱动的企业环境中，一个常见场景是：业务分析师急需某项数据分析，但必须等待懂SQL的技术团队成员提供支持。根据McKinsey的一项研究，分析师平均花费30-40%的时间仅用于数据准备和查询构建。这种依赖不仅延迟决策过程，还增加了技术团队的工作负担。
这就是为什么我开发了CAMEL DatabaseAgent — 一个革命性的开源工具，它能够让任何人通过自然语言与数据库对话，就像与同事交流一样简单。无需编写一行SQL代码，分析师可以直接获取他们需要的数据洞察。
CAMEL DatabaseAgent的核心优势 相比市场上其他文本到SQL工具，CAMEL DatabaseAgent具有以下显著优势：
完全开源：透明的代码和社区驱动的开发确保了持续改进和定制灵活性 多语言支持：能够理解和响应包括中文、英文、韩文在内的多种语言查询 自动数据库理解：分析数据库结构并生成适当的少样本学习示例 只读模式：默认安全操作，保护数据库不被意外修改 简单集成：易于与现有系统和工作流程集成 技术架构：它是如何工作的 CAMEL DatabaseAgent建立在CAMEL-AI之上，由三个核心组件构成：
DataQueryInferencePipeline：这个智能组件分析你的数据库结构并自动生成训练示例，包括问题和对应的SQL查询。它使用了先进的推理技术来理解表之间的关系和数据的语义。
DatabaseKnowledge：一个专门设计的向量数据库，用于高效存储和检索数据库模式、样本数据和查询模式。这个组件使系统能够快速&amp;quot;回忆&amp;quot;相关的数据库知识来回答用户问题。
DatabaseAgent：基于大语言模型(LLM)的智能代理，它接收自然语言问题，利用DatabaseKnowledge生成精确的SQL查询，执行查询，并以用户友好的格式返回结果。
支持的数据库系统包括：
SQLite MySQL PostgreSQL 所有操作默认在只读模式下进行，确保数据安全。
实际应用案例：从简单到复杂 我在一个音乐分发平台的真实数据库上测试了这个工具，结果令人印象深刻。以下是按复杂度递增的几个应用场景：
基础查询 当我问&amp;quot;查找包含超过10首曲目的播放列表名称&amp;quot;时，系统立即生成了正确的SQL：
系统能够理解简单的筛选和计数需求
中等复杂度查询 场景一: 统计特定时间段内的销售数据 系统成功处理了多表连接和时间范围筛选
场景二: 按类别分组的财务分析 系统能够理解分组、聚合和复杂的表关系
高级分析查询 场景三: 性能排名分析 系统处理了多表连接、排序和限制条件
场景四: 条件筛选和计数 系统能够使用子查询和复杂条件
场景五: 百分比计算 系统能够执行数学计算和条件计数
场景六: 复杂关联分析 系统能处理左连接和空值情况
突破语言障碍：多语言支持 在全球化团队环境中，语言障碍常常是数据协作的瓶颈。CAMEL DatabaseAgent支持多语言交互，让来自不同语言背景的团队成员都能使用自己的母语训练知识并进行数据查询。
使用中文训练知识并提问
系统同样支持韩文等其他语言，而你要做的只是在连接数据库的时候指定语言
入门指南：5分钟上手 想要尝试CAMEL DatabaseAgent？只需几个简单步骤：
# 1. 克隆仓库 git clone git@github.com:coolbeevip/camel-database-agent.git cd camel-database-agent # 2. 设置环境 pip install uv ruff mypy uv venv .</description></item><item><title>Prompt Engineering Types</title><link>https://coolbeevip.github.io/posts/gpt/prompt-engineering/</link><pubDate>Mon, 01 Jan 2024 20:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/gpt/prompt-engineering/</guid><description>Types Zero-Shot Learning One-Shot Learning Few-Shot Learning Chain-of-Thought Prompting Iterative Prompting Negative Prompting Hybrid Prompting Prompt Chaining Consistency Prompting Knowledge Prompting Tree of Thoughts(ToT) ReAct Prompting Directional Stimulus Prompting Zero-Show Learning 在没有任何示例的情况下给人工智能一个任务。假设人工智能事先不知道任务，你可以详细描述你想要什么。
Prompt: “请解释什么是大语言模型”
GPT 3.5 Response:
大语言模型是一种基于深度学习技术的人工智能模型，旨在生成自然语言文本。这类模型通常具有非常大的神经网络结构和参数数量，可以对大规模的语料库进行训练，并尝试预测下一个单词或句子的可能性。大语言模型已经被广泛应用于自然语言处理、机器翻译、自动文摘、语音识别等领域，在提高计算机语言理解和生成能力方面起到了重要的作用。常见的大语言模型包括BERT、GPT-2、ELMo等
One-Shot Learning 您随提示提供了一个示例。这有助于人工智能理解您期望的上下文或格式。
Prompt: “人工智能中的基础模型是指像 GPT-3 这样的模型、 这样的模型，它在大型数据集上经过训练，可适用于各种任务。 在这种情况下，请解释什么是 BERT”
GPT 3.5 Response:
BERT（Bidirectional Encoder Representations from Transformers）是一种基于变形器（Transformer）结构的自然语言处理（NLP）模型，它是由Google开发的，可以进行预训练和微调。BERT的主要功能是用来处理自然语言理解任务，例如问答、语义理解、文本分类等。不同于传统的自然语言处理模型，BERT采用了双向的上下文理解技术，可以更好地理解和适应语言上下文。BERT在大型数据集上进行预训练，可以得到更为优秀的模型表现，在各种自然语言处理任务上具有很高的精度和普适性。
Few-Shot Learning 提供一些示例（通常是 2-5 个）来帮助 AI 理解您正在寻找的响应的模式或风格。
Prompt: “GPT-3 等基础模型用于自然语言处理，而 DALL-E 等模型用于图像生成。基础模型如何应用于机器人领域?”
GPT 3.5 Response:</description></item><item><title>Get the latest release information of the repos from GitHub</title><link>https://coolbeevip.github.io/posts/github/get-releases-latest-from-github/</link><pubDate>Tue, 12 Dec 2023 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/github/get-releases-latest-from-github/</guid><description>1. Requirements python &amp;gt;= 3.9 pip install beautifulsoup4 2. Create a python script get_latest_info_from_github_repos.py
import requests from bs4 import BeautifulSoup urls = [ &amp;#34;https://github.com/geoserver/geoserver&amp;#34;, &amp;#34;https://github.com/Leaflet/Leaflet&amp;#34;, &amp;#34;https://github.com/Turfjs/turf/&amp;#34; ] def get_latest_version(url) -&amp;gt; tuple: url = url + &amp;#34;/releases/latest&amp;#34; response = requests.get(url) if response.status_code != 200: raise Exception(f&amp;#39;Request failed with status {response.status_code}&amp;#39;) soup = BeautifulSoup(response.text, &amp;#39;html.parser&amp;#39;) version = soup.find(&amp;#39;span&amp;#39;, {&amp;#39;class&amp;#39;: &amp;#39;css-truncate-target&amp;#39;}).get_text(strip=True) datetime = soup.find(&amp;#39;relative-time&amp;#39;).get(&amp;#34;datetime&amp;#34;) return version, datetime for url in urls: version = &amp;#34;UNKNOWN&amp;#34; datetime = &amp;#34;UNKNOWN&amp;#34; try: version, datetime = get_latest_version(url) except Exception as e: pass print(f&amp;#39;{url},{version},{datetime[0:10]}&amp;#39;) 3.</description></item><item><title>Git filter-branch</title><link>https://coolbeevip.github.io/posts/git/git-command-filter-branch/</link><pubDate>Fri, 15 Sep 2023 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-filter-branch/</guid><description>使用 git filter-branch &amp;ndash;commit-filter 重写历史记录可能会导致数据丢失。这个命令允许你在Git存储库的历史记录中进行修改，应用一个自定义的 commit 过滤器。当你使用这个命令时，请务必小心操作，因为它会改变存储库的历史记录。
在执行前，建议先进行备份，以确保你有一个完好的历史记录备份。另外，这个命令可能会导致一些副作用，如更改提交哈希值、移除或合并提交、删除部分文件等。
因此，在执行 git filter-branch 之前，请确保你已经理解了它的工作原理，并且在执行前考虑了潜在的风险。如果你不确定自己在做什么，建议先创建一个分支进行实验，以避免意外破坏存储库的历史记录。
删除 README.md 和 docs/docker_build.md 两个文件，并清理所有产生的提交 git filter-branch --force --index-filter &amp;#39;git rm --cached --ignore-unmatch README.md docs/docker_build.md&amp;#39; --prune-empty --tag-name-filter cat -- --all 删除指定编号的提交信息 使用 git log --oneline 命令查询到要删除提交
git log --oneline | grep Update ed2e2a7 [feat]:[][Update docs/场景梳理.xlsx] 2a919eb [feat]:[][Update docs/场景梳理.xlsx] 记录要删除的提交短 ID 到以下脚本的 DEL_COMMIT_IDS=['ed2e2a7','a919eb'] 位置
git filter-branch --force --commit-filter &amp;#39;DEL_COMMIT_IDS=[&amp;#39;ed2e2a7&amp;#39;,&amp;#39;a919eb&amp;#39;]; if [[ $DEL_COMMIT_IDS =~ ${GIT_COMMIT:0:7} ]]; then skip_commit &amp;#34;$@&amp;#34;; else git commit-tree &amp;#34;$@&amp;#34;; fi&amp;#39; HEAD 执行后可以看到 Ref 'refs/heads/master' was rewritten 表示已经重写了历史记录，然后再用 git log --oneline 查看可以看到已经删除</description></item><item><title>Apache NiFi Schema</title><link>https://coolbeevip.github.io/posts/apache_nifi/apache_nifi_schema/</link><pubDate>Sat, 02 Sep 2023 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apache_nifi/apache_nifi_schema/</guid><description>Apache NiFi Schema Apache NiFi是一个易于使用、功能强大且可靠的数据处理和分发系统。它采用基于组件的方式设计数据流。
在NiFi终端界面，用户通过界面拖动组件建立和维护数据流。
术语 Processor 处理器是NiFi的基本组件，负责创建、发送、接收、转换、过滤、分割和处理数据。NiFi的数据流是由处理器连接起来的。处理器有一组属性，可以根据需要进行配置。
Name: Processor 的名称，用于在数据流图中识别 Processor。 Scheduling Strategy: 确定 Processor 是应根据时间间隔（Timer Driven）运行，还是应根据事件触发（Event Driven）运行。 Concurrent tasks: 这是可以同时执行的任务数。这允许并行处理，可以提高处理效能。 Comments: 可以在此处添加任何有关 Processor 的额外信息或注释。 Yield Duration: 当 Processor 无法进行处理时（例如，输出连接的队列已满），它将“退避（Yield）”，过一段时间再试。该属性定义了退避的持续时间。 Penalization Duration: 如果 Processor出现错误，将对其进行“惩罚”，使其在一段时间内无法处理任何FlowFile。这项属性决定了这段时间的长度。 Connection 在 Apache NiFi 中，connection 是流程图中两个处理器或者一个处理器与一个转换器之间传递数据的关键部分。以下是 connection 的一些典型属性（schema）：
Name: 连接的名称，便于在数据流图中明确识别连接。 Source: 连接的源处理器。连接从此处开始，将源处理器的输出数据传递到目标处理器。 Destination: 连接的目标处理器，它接收源处理器的输出数据。 Back Pressure Object Threshold: 这是队列中元素的数量，一旦超过该数量，源处理器将停止生产数据。 Back Pressure Data Size Threshold: 这是队列容量，一旦超过这个容量，源处理器将停止生产数据。 Prioritizers: 如果队列中包含多个元素，优先级器确定应首先处理哪一项。 Expiration: FlowFile在队列中能存活的最长时间。 FlowFile Apache NiFi 中的 FlowFile 是一个数据记录或对象，它包含两部分，数据内容和属性。以下是一些 FlowFile 相关的重要概念和可能的 Schema ：</description></item><item><title>Node 版本管理工具</title><link>https://coolbeevip.github.io/posts/node/node_version_manager/</link><pubDate>Wed, 16 Aug 2023 12:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/node/node_version_manager/</guid><description>官方网站 https://github.com/nvm-sh/nvm/
安装 curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.4/install.sh | bash 使用 查看远程可用版本
nvm ls-remote 安装
nvm install 14.21.3 切换
nvm use 14.21.3</description></item><item><title>在 AWS 搭建 ChatGPT 使用环境</title><link>https://coolbeevip.github.io/posts/ai/aws-chatgpt/</link><pubDate>Tue, 30 May 2023 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/aws-chatgpt/</guid><description>AWS Lightsail 配合 Cloudflare WARP，使 Griseo 在远程主机通过命令行使用 ChatGPT
背景 你可以使用 curl ipinfo.io 命令查看你的 IP 地址，通常 AWS 服务器的 org 会显示 Amazon.com, 此时你是无法访问 chat.openai.com 的。我们需要使用 Cloudflare 让被访问网站认为访问来自于“原生IP”
curl ipinfo.io { &amp;#34;ip&amp;#34;: &amp;#34;xxxx&amp;#34;, &amp;#34;hostname&amp;#34;: &amp;#34;xxxx&amp;#34;, &amp;#34;city&amp;#34;: &amp;#34;Tokyo&amp;#34;, &amp;#34;region&amp;#34;: &amp;#34;Tokyo&amp;#34;, &amp;#34;country&amp;#34;: &amp;#34;JP&amp;#34;, &amp;#34;loc&amp;#34;: &amp;#34;xxx&amp;#34;, &amp;#34;org&amp;#34;: &amp;#34;XXXX Amazon.com, Inc.&amp;#34;, &amp;#34;postal&amp;#34;: &amp;#34;xxx-xxxx&amp;#34;, &amp;#34;timezone&amp;#34;: &amp;#34;Asia/Tokyo&amp;#34;, &amp;#34;readme&amp;#34;: &amp;#34;https://ipinfo.io/missingauth&amp;#34; } Cloudflare Warp 代理模式 通过在服务器本机启动一个 SOCKS5 代理，然后把需要的流量转发到这个代理上
安装软件包 以 Debian 举例，添加安装源
sudo apt install curl curl https://pkg.cloudflareclient.com/pubkey.gpg | gpg --yes --dearmor --output /usr/share/keyrings/cloudflare-warp-archive-keyring.</description></item><item><title>在 AWS 搭建 VPN</title><link>https://coolbeevip.github.io/posts/ai/aws-openvpn/</link><pubDate>Tue, 30 May 2023 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ai/aws-openvpn/</guid><description>下载安装程序脚本 curl -O https://raw.githubusercontent.com/angristan/openvpn-install/master/openvpn-install.sh chmod +x openvpn-install.sh 执行安装 执行安装脚本，端口建议改为 443（你所在的局域网客户端通常不会阻止 443 出口）
$ ./openvpn-install.sh Welcome to the OpenVPN installer! The git repository is available at: https://github.com/angristan/openvpn-install I need to ask you a few questions before starting the setup. You can leave the default options and just press enter if you are ok with them. I need to know the IPv4 address of the network interface you want OpenVPN listening to. Unless your server is behind NAT, it should be your public IPv4 address.</description></item><item><title>Linux Command - CRON</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-cron/</link><pubDate>Tue, 16 May 2023 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-cron/</guid><description>Linux CRON 命令
CREATE A CRON SCRIPT TO CLEAN Edit the /opt/daily-clean.sh file
#!/bin/bash # docker docker system prune -f docker builder prune -f docker volume prune -f # /home/puaiuc/ find /home/puaiuc/ -maxdepth 1 -type f \( -iname &amp;#34;*&amp;#34; ! -iname &amp;#34;.*&amp;#34; \) -delete Now give the file executable permission
chmod a+x /opt/daily-clean.sh Edit the crontab file to schedule it
crontab -e In our case, we have scheduled it to every day at the start of the day</description></item><item><title>Use brew install python2 and python3 on macOS</title><link>https://coolbeevip.github.io/posts/python/install_both_python2_python3_on_mac/</link><pubDate>Sat, 04 Mar 2023 10:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/python/install_both_python2_python3_on_mac/</guid><description>使用 pyenv 可以很灵活的配置版本环境
环境说明 我的 macbook 上默认已经安装了 python3，但是我还需要一个 python2 环境编译一些老的项目
python3 --version Python 3.11.2 安装 安装 pyenv
$ brew install pyenv 允许在 bash 中启用 pyenv
$ eval &amp;#34;$(pyenv init -)&amp;#34; 使用 一旦你安装了pyenv并激活了它，你可以安装不同版本的python并选择你可以使用的版本。
$ pyenv install 2.7.18 你可以用以下命令检查安装的版本
$ pyenv versions 你可以使用如下命令切换全局版本
$ pyenv global 3.3.1 你可以使用如下命令在当前目录设置版本
$ pyenv local 3.5.2 你能够运行以下命令检查版本
$ python --version Python 2.7.18</description></item><item><title>Git Pick Commits to Another Reps</title><link>https://coolbeevip.github.io/posts/git/git-command-pick-commit-to-another-repsrepository/</link><pubDate>Sat, 18 Feb 2023 09:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-pick-commit-to-another-repsrepository/</guid><description>从上游仓库中选取 commits 提交到另一个仓库
附加修改作者，消息，时间
前期准备 你要准备一个要同步的库
# 下载这个库 git clone git@github.com:coolbeevip/git-commits-replay.git # 查看这个库的所有 commits git --git-dir=./git-commits-replay/.git log --pretty=format:&amp;#34;%H,%an,%ae,%ad,%s&amp;#34; --date=format:&amp;#39;%Y-%m-%d %H:%M:%S&amp;#39; --reverse 52d099240f6da63193ba309106dad77d060836a7,Lei Zhang,zhanglei@apache.org,2023-02-18 10:49:43,Create A.md 516e406615c0020919939bafe59b35359a03c33b,Lei Zhang,zhanglei@apache.org,2023-02-18 10:50:09,Create B.md 551e5c88440396b73f3b1642bf765dcb9136fd1f,Lei Zhang,zhanglei@apache.org,2023-02-18 10:50:30,Create C.md 5dacf876b6f0b4a0d3ead7ec3daaac924b1b37f4,Lei Zhang,zhanglei@apache.org,2023-02-18 10:51:02,Create ALL.md 72a7a54c48286e9a7c92d1201108baa61cbd7db4,Lei Zhang,zhanglei@apache.org,2023-02-18 10:52:13,删除 A B C 新建一个仓库并关联要同步的库
# 新建一个本地仓库 mkdir git-commits-replay-local cd git-commits-replay-local git init git config --global init.defaultBranch master git branch -m master # 关联上游仓库 git remote add upstream git@github.com:coolbeevip/git-commits-replay.git 重放 commit 并修改提交信息 例如要将 52d099240f6da63193ba309106dad77d060836a7,Lei Zhang,zhanglei@apache.</description></item><item><title>Linux Command - Supervisory</title><link>https://coolbeevip.github.io/posts/linux/linux-collect-system/</link><pubDate>Mon, 07 Nov 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-collect-system/</guid><description>定时收集当前用户的CPU和内存利用率 创建如下 user_usage.sh
#!/usr/bin/bash echo -e TIME\\tCPU%\\tMEM% while true do top -b -n 1 -u &amp;#34;$user&amp;#34; | awk -v user=&amp;#34;$user&amp;#34; -v date=&amp;#34;$(date &amp;#39;+%Y/%m/%d %H:%M:%S&amp;#39;)&amp;#34; &amp;#39;NR&amp;gt;7 { cpu_utilization_sum += $9; mem_utilization_sum += $10;} END { printf &amp;#34;%s\t%.2f\t%.2f\n&amp;#34;,date,cpu_utilization_sum,mem_utilization_sum; }&amp;#39; sleep $1 done 每 3 秒采集一次
sh user_usage.sh 3 TIME	CPU%	MEM% 2023/01/06 17:26:56	64.80	82.10 2023/01/06 17:26:57	70.60	82.10 2023/01/06 17:26:58	393.60	82.10 2023/01/06 17:26:59	137.50	82.20 定时收集某个进程的CPU和内存利用率 创建如下 proc_usage.sh
#!/usr/bin/bash echo proc $2 echo -e TIME\\tCPU%\\tMEM% while true do top -b -n 1 -p `ps -ef | grep $2 | grep -v grep | awk &amp;#39;{ print $2 }&amp;#39; | paste -s -d &amp;#39;,&amp;#39;` | awk -v user=&amp;#34;$user&amp;#34; -v date=&amp;#34;$(date &amp;#39;+%Y/%m/%d %H:%M:%S&amp;#39;)&amp;#34; &amp;#39;NR&amp;gt;7 { cpu_utilization_sum += $9; mem_utilization_sum += $10;} END { printf &amp;#34;%s\t%.</description></item><item><title>Linux Command - CPU</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-cpu/</link><pubDate>Sun, 23 Oct 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-cpu/</guid><description>Linux CPU 相关命令
查看 CPU 信息 $ lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 4 On-line CPU(s) list: 0-3 Thread(s) per core: 1 Core(s) per socket: 1 Socket(s): 4 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 85 Model name: Intel Xeon Processor (Skylake, IBRS) Stepping: 4 CPU MHz: 2299.996 BogoMIPS: 4599.99 Hypervisor vendor: KVM Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 4096K L3 cache: 16384K NUMA node0 CPU(s): 0-3 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 arat pku ospke spec_ctrl intel_stibp PI 值计算 $ time echo &amp;#34;scale=5000; 4*a(1)&amp;#34; | bc -l -q 7-Zip 基准测试 使用 7-Zip 自带的 LZMA 压缩基准测试测量 CPU 性能</description></item><item><title>常用日志统计脚本</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-awk/</link><pubDate>Sun, 23 Oct 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-awk/</guid><description>常用日志分析脚本，日志样例如下
2022-12-02 17:00:02,580 [reactor-http-epoll-7] O [com.my.gateway.filter.RequestGlobalFilter] RequestGlobalFilter.java:46 - request http://gateway/myapp/graphql remote address 110.242.12.19
统计文件中匹配规则的行数 统计 2022-12-02 日 17 点至 18 点包含 RequestGlobalFilter 关键字的行数
$ cat my-gateway_9999.log | grep &amp;#39;2022-12-02 17.*RequestGlobalFilter&amp;#39; | wc -l 24003 统计 2022-12-02 日 17 点至 18 点包含 RequestGlobalFilter 并且请求路径包含 myapp 关键字的行数
$ cat my-gateway_9999.log | grep &amp;#39;2022-12-02 17.*RequestGlobalFilter.*myapp.*&amp;#39; | wc -l 6369 分组统计 统计 2022-12-02 日 17 点至 18 点包含 RequestGlobalFilter 按照客户端 IP 地址统计每个客户端的请求行数
$ cat my-gateway_9999.</description></item><item><title>使用 Checkstyle Plugin 检查 Java 代码（风格）质量</title><link>https://coolbeevip.github.io/posts/maven/checkstyle-plugin-for-checking-java-code-quality/</link><pubDate>Sun, 18 Sep 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/checkstyle-plugin-for-checking-java-code-quality/</guid><description>本文记录了如何在 Maven 项目中使用 Apache Maven Checkstyle Plugin 检查代码风格质量
一个 Maven 项目 假设我有一个 Maven 项目，这个项目包含若干子模块。根目录的 pom.xml 看起来如下：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;revision&amp;gt;0.1.0-SNAPSHOT&amp;lt;/revision&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;/project&amp;gt; 在根项目 pom.xml 中增加 maven-checkstyle-plugin 插件 增加 maven-checkstyle-plugin 插件
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;maven-checkstyle-plugin.version&amp;gt;3.1.2&amp;lt;/maven-checkstyle-plugin.version&amp;gt; &amp;lt;com.puppycrawl.tools.version&amp;gt;9.3&amp;lt;/com.puppycrawl.tools.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;build&amp;gt; &amp;lt;pluginManagement&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.</description></item><item><title>在 Maven 项目中使用 PMD Plugin 检查 Java 代码（Java源代码）质量</title><link>https://coolbeevip.github.io/posts/maven/pmd-plugin-for-checking-java-code-quality/</link><pubDate>Sun, 18 Sep 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/pmd-plugin-for-checking-java-code-quality/</guid><description>本文记录了如何在 Maven 项目中使用 Apache Maven PMD Plugin 检查代码（Java 代码）质量
一个 Maven 项目 假设我有一个 Maven 项目，这个项目包含若干子模块。根目录的 pom.xml 看起来如下：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;revision&amp;gt;0.1.0-SNAPSHOT&amp;lt;/revision&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;/project&amp;gt; 在根项目 pom.xml 中增加 maven-pmd-plugin 插件 增加 maven-pmd-plugin 插件
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;maven-pmd-plugin.version&amp;gt;3.19.0&amp;lt;/maven-pmd-plugin.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;build&amp;gt; &amp;lt;pluginManagement&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.</description></item><item><title>在 Maven 项目中使用 Spotbugs Plugin 检查 Java 代码（字节码）质量</title><link>https://coolbeevip.github.io/posts/maven/spotbugs-plugin-for-checking-java-code-quality-copy/</link><pubDate>Sun, 18 Sep 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/spotbugs-plugin-for-checking-java-code-quality-copy/</guid><description>本文记录了如何在 Maven 项目中使用 SpotBugs Maven Plugin 检查代码（字节码）质量
一个 Maven 项目 假设我有一个 Maven 项目，这个项目包含若干子模块。根目录的 pom.xml 看起来如下：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;revision&amp;gt;0.1.0-SNAPSHOT&amp;lt;/revision&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;/project&amp;gt; 在根项目 pom.xml 中增加 spotbugs-maven-plugin 插件 增加 spotbugs-maven-plugin 插件
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;spotbugs-maven-plugin.version&amp;gt;4.7.1.1&amp;lt;/spotbugs-maven-plugin.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;build&amp;gt; &amp;lt;pluginManagement&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;com.</description></item><item><title>在 Maven 多模块项目中使用 JaCoCo 检查测试覆盖率</title><link>https://coolbeevip.github.io/posts/maven/jacoco-in-maven-multi-module/</link><pubDate>Sun, 03 Jul 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/jacoco-in-maven-multi-module/</guid><description>本文记录了如何在 Maven 多模块项目中使用 JaCoCo 生成覆盖率报告并推送到 Sonar 中
一个多模块项目 假设我有一个多模块项目，这个项目包含若干子模块，并且有若干测试用例。根目录的 pom.xml 看起来如下：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;revision&amp;gt;0.1.0-SNAPSHOT&amp;lt;/revision&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;/project&amp;gt; 关于 module-dependencies 模块的作用，可以查看我之前写的MAVEN PROJECTS BEST PRACTICES
在根项目 pom.xml 中增加 jacoco-maven-plugin 插件，并增加 module-coverage 模块 增加 jacoco-maven-plugin 插件
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;my&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;my-project&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;jacoco-maven-plugin.version&amp;gt;0.8.6&amp;lt;/jacoco-maven-plugin.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;modules&amp;gt; &amp;lt;module&amp;gt;module-dependencies&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-bar&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-foo&amp;lt;/module&amp;gt; &amp;lt;module&amp;gt;module-coverage&amp;lt;/module&amp;gt; &amp;lt;/modules&amp;gt; &amp;lt;build&amp;gt; &amp;lt;pluginManagement&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.</description></item><item><title>Backup SSH KEY</title><link>https://coolbeevip.github.io/posts/my/my-backup-ssh-key/</link><pubDate>Tue, 17 May 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/my/my-backup-ssh-key/</guid><description>将 ~/.ssh/下的所有文件迁移到新的机器上，然后在新的机器上执行
chmod 600 ~/.ssh/*</description></item><item><title>Apache Servicecomb Pack Release Guide</title><link>https://coolbeevip.github.io/posts/asf/apache-release-guide/</link><pubDate>Sun, 08 May 2022 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/asf/apache-release-guide/</guid><description>发布环境准备 生成签名密钥 安装 GPG 在GnuPG官网下载 2.X 安装包. 安装完毕后可以使用如下命令查看版本
$ gpg --version gpg (GnuPG/MacGPG2) 2.2.20 libgcrypt 1.8.5 Copyright (C) 2020 Free Software Foundation, Inc. 配置 GPG 安装完毕后你可以找到 $HOME/.gnupg/gpg.conf 文件，并增加如下推荐配置
personal-digest-preferences SHA512 cert-digest-algo SHA512 default-preference-list SHA512 SHA384 SHA256 SHA224 AES256 AES192 AES CAST5 ZLIB BZIP2 ZIP Uncompressed 用 GPG 生成密钥 根据提示使用 ASF 邮箱生成 GPG 的密钥，更多详细说明请参考 Generate Key with GPG
$ gpg --full-gen-key gpg (GnuPG/MacGPG2) 2.2.34; Copyright (C) 2022 g10 Code GmbH This is free software: you are free to change and redistribute it.</description></item><item><title>Awesome Git Aliases</title><link>https://coolbeevip.github.io/posts/git/git-awesome-aliases/</link><pubDate>Sat, 02 Apr 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-awesome-aliases/</guid><description>我们可以通过别名定义简化命令输出，创造自己的命令
打开 ~/.gitconfig 文件您可以看到如下片段，在这个片段中我们可以为已有命令定义别名
[alias] 例如我们创建分支是需要使用 git branch -b xxx 命令，那么我们可以将 branch 简化为 br。我们只需要增加如下配置
[alias] br = branch 这是我自己常用的配置
[alias] ci = commit -a co = checkout cob = checkout -b cl = clone st = status br = branch mr = merge cp = cherry-pick hist = log --pretty=format:\&amp;#34;%h %ad | %s%d [%an]\&amp;#34; --graph --date=short type = cat-file -t dump = cat-file -p sync-up = !git fetch upstream &amp;amp;&amp;amp; git checkout $1 &amp;amp;&amp;amp; git rebase upstream/$1 &amp;amp;&amp;amp; git push origin $1 &amp;amp;&amp;amp; :</description></item><item><title>Awesome Git Hooks</title><link>https://coolbeevip.github.io/posts/git/git-awesome-hook/</link><pubDate>Sat, 02 Apr 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-awesome-hook/</guid><description>commit-msg #!/bin/sh red=&amp;#39;\033[0;31m&amp;#39; green=&amp;#39;\033[0;32m&amp;#39; no_color=&amp;#39;\033[0m&amp;#39; commit_msg_file=&amp;#34;$1&amp;#34; commit_msg=$(cat &amp;#34;$commit_msg_file&amp;#34;) max_length=50 if [ ${#commit_msg} -gt $max_length ]; then echo &amp;#34;${red}信息长度不能超过50！${no_color}&amp;#34; exit 1 fi if [ &amp;#34;&amp;#34; = &amp;#34;$(grep -E &amp;#39;^(\[(fix|feat)\]:\[.*]\[.*\]|\[(docs|style|ref|test|chore|tag|revert|perf)\]:\[.*\])$&amp;#39; $1)&amp;#34; ]; then echo &amp;#34;${red}ERROR:${no_color} 你的提交描述格式错误, 请参考如下样例:&amp;#34; echo &amp;#34;${green}[feat]:[单号][新增XXXX]&amp;#34; echo &amp;#34;[feat]:[][新增XXXX]&amp;#34; echo &amp;#34;[fix]:[CRMAIF_ISSUE_XXX][修改/修复XXXX]&amp;#34; echo &amp;#34;[fix]:[][修改/修复XXXX]&amp;#34; echo &amp;#34;[docs]:[单号][新增/修订/删除XXXX]&amp;#34; echo &amp;#34;[docs]:[新增/修订/删除XXXX]&amp;#34; echo &amp;#34;[style]:[调整XX页XX格式]&amp;#34; echo &amp;#34;[ref]:[重构XXXX]&amp;#34; echo &amp;#34;[test]:[测试XXXX]&amp;#34; echo &amp;#34;[chore]:[构建/变动XXXX]&amp;#34; echo &amp;#34;[tag]:[版本XXXX]&amp;#34; echo &amp;#34;[revert]:[撤销/回退XXXX]&amp;#34; echo &amp;#34;[perf]:[性能优化XXXX]${no_color}&amp;#34; exit 1 fi pre-commit #!/bin/sh red=&amp;#39;\033[0;31m&amp;#39; green=&amp;#39;\033[0;32m&amp;#39; no_color=&amp;#39;\033[0m&amp;#39; USERNAME=$(git config user.</description></item><item><title>My Favorite Software</title><link>https://coolbeevip.github.io/posts/my/my-favorite-software/</link><pubDate>Sat, 19 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/my/my-favorite-software/</guid><description>开发者工具 IntelliJ IDEA Java 开发集成环境 WebStorm Web 开发集成环境 Atom GitHub 推出的开源编辑器 VS Code DataGrip 数据库客户端工具 JProfiler JVM 性能分析工具 (收费) VisualVM JVM 性能分析工具 Dash 离线 API 文档软件 Sublime Text 4 命令行 iTrem2 终端工具 浏览器 Google Chrome 工具 The Unarchiver 解压许多不同种类的归档压缩文件 Android File Transfer Android 文件传输工具 密码 LastPass 多终端密码管理 GPG Suite GPG 加密工具 语言 Grammarly 语法修正 通信 微信 腾讯会议 邮件 Apple Email MacOS 自带 办公 WPS Office 笔记 Github Pages Typora Mackdown 编辑器 1.</description></item><item><title>Java Performance Profiling Using Flame Graphs</title><link>https://coolbeevip.github.io/posts/java/java-performance-profiling-using-flame-graphs/</link><pubDate>Sat, 12 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java/java-performance-profiling-using-flame-graphs/</guid><description>JDK 有很多性能测量工具 JConsole、VisualVM、HPROF 等。它们中的大多数将应用程序作为一个整体进行分析，并且需要一些繁琐的分析过程能到分析出类或方法级别的热点。
当我试图评估我们的一个服务的性能时，可以通过 CPU 火焰图的方法，它在找出代码的 CPU 使用率方面非常有效。
这篇文章记录了我在对投递服务进行基准测试时发现的性能问题，以及通过 CPU 火焰图找到热点方法并改进的调优过程。
要求 如果你使用 IntelliJ IDEA Ultimate ，那么这个 IDE 自带一个火焰图工具 Async Profiler 如果你要在生产环境生成火焰图，你可以借助这个工具 火焰图生成工具 async-profiler 场景 这一切源于一个基准测试。通常我们在交付一个产品前需要对这个服务进行基准测试。并通过基准测试结果得出在某些硬件基准下我们服务的性能指标，最终通过这些指标你可以回答用户提出的容量要求。
投递服务： 这个服务负责从客户端接收消息，放入待发送队列，并持久化到数据库中。然后立即返回给客户端。为了准确额模拟客户端我为此编写了一个基准测试客户端程序。
经过多轮基准测试，我们找到单机服务下了吞吐率最佳的参数，并得到了最佳吞吐率 QPS 769
总计发送 10000 笔业务 50 并发； Welcome to the Notifier CLI 4.8.0 Type &amp;#39;help&amp;#39; for help. notifier&amp;gt;benchmark -T 123123 -n 10000 -c 50 -w 10 Benchmarking ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ Warm Up 10 Concurrency Level 50 Time taken for tests 13 seconds Complete requests 10000 Failed requests 5000 Refused requests 0 Requests per second 769 [#/sec] Time per request 67 [ms] Percentage of the requests served within a certain time (ms) 50% 46.</description></item><item><title>Docker IPv6 Support</title><link>https://coolbeevip.github.io/posts/ipv6/ipv6-docker/</link><pubDate>Fri, 11 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ipv6/ipv6-docker/</guid><description>本文介绍在 IPv6 网络主机上部署 Docker
主机 IPv6 网络检查 使用 ifconfig 命令查看是否已经配置了 IPv6 网络
$ ifconfig eth1 eth1: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 inet 10.252.248.152 netmask 255.255.255.128 broadcast 10.252.248.255 inet6 2409:8010:5ac0:400:200::2d prefixlen 128 scopeid 0x0&amp;lt;global&amp;gt; inet6 fe80::f816:3eff:fe84:bc36 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether fa:16:3e:84:bc:36 txqueuelen 1000 (Ethernet) RX packets 7150695 bytes 4751783652 (4.4 GiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5018420 bytes 4436770306 (4.1 GiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 你可以看到主机已经获取到了 IPv6 地址 inet6 2409:8010:5ac0:400:200::2d 注意： fe80:: 开头的地址只是链接本地地址 分别在主机和其他主机使用 ping6 命令验证网络是否可达</description></item><item><title>Linux Command - Memory</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-memory/</link><pubDate>Fri, 11 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-memory/</guid><description>Linux 内存相关命令
查看系统内存 # free -h total used free shared buff/cache available Mem: 251G 40G 1.4G 4.0G 209G 206G Swap: 4.0G 3.7G 312M 内存占用 TOP N # ps aux | sort -k4,4nr | head -n 5 200 139348 227 6.9 38668500 18410776 ? Ssl 3月10 1905:49 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-2.el8_3.x86_64/jre/bin/java...org.sonatype.nexus.karaf.NexusMain mysql 33407 1.2 2.2 349722012 6012524 ? Sl 2021 4596:18 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql mysql 118257 0.4 0.5 10170064 1536084 ? Ssl 2月28 66:04 /usr/share/elasticsearch/jdk/bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC root 42564 9.</description></item><item><title>Very High CPU usage Sonatype Nexus Docker</title><link>https://coolbeevip.github.io/posts/nexus/very-high-cpu-usage-sonatype-nexus-docker/</link><pubDate>Fri, 11 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/nexus/very-high-cpu-usage-sonatype-nexus-docker/</guid><description>本文记录 Sonatype Nexus 私服遇到性能劣化问题的分析过程（未解决）
环境说明 使用 sonatype/nexus3 镜像启动，通过挂载卷存储数据
Nexus 配置，可以看到关键配置 -Xms8g -Xmx8g -XX:MaxDirectMemorySize=35158M -XX:+UseConcMarkSweepGC
200 105083 105062 99 11:01 ? 2-00:51:44 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-2.el8_3.x86_64/jre/bin/java -server -Dinstall4j.jvmDir=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-2.el8_3.x86_64/jre -Dexe4j.moduleName=/opt/sonatype/nexus/bin/nexus -XX:+UnlockDiagnosticVMOptions -Dinstall4j.launcherId=245 -Dinstall4j.swt=false -Di4jv=0 -Di4jv=0 -Di4jv=0 -Di4jv=0 -Di4jv=0 -Xms8g -Xmx8g -XX:MaxDirectMemorySize=35158M -XX:ActiveProcessorCount=16 -XX:+UseParNewGC -XX:ParallelGCThreads=12 -XX:MaxTenuringThreshold=6 -XX:SurvivorRatio=5 -XX:+UseConcMarkSweepGC -XX:-CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=65 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCMSCompactAtFullCollection -XX:+CMSClassUnloadingEnabled -XX:+DisableExplicitGC -XX:+PrintGCDetails -Xloggc:/nexus-data/vgc/nexus-1646967690.vgc -XX:+UnlockDiagnosticVMOptions -XX:+LogVMOutput -XX:LogFile=../sonatype-work/nexus3/log/jvm.log -XX:-OmitStackTraceInFastThrow -Djava.net.preferIPv4Stack=true -Dkaraf.home=. -Dkaraf.base=. -Dkaraf.etc=etc/karaf -Djava.util.logging.config.file=etc/karaf/java.util.logging.properties -Dkaraf.data=../sonatype-work/nexus3 -Dkaraf.log=../sonatype-work/nexus3/log -Djava.io.tmpdir=../sonatype-work/nexus3/tmp -Dkaraf.startLocalConsole=false -Djdk.tls.ephemeralDHKeySize=2048 -Djava.endorsed.dirs=lib/endorsed -Di4j.vpt=true -classpath /opt/sonatype/nexus/.install4j/i4jruntime.jar:/opt/sonatype/nexus/lib/boot/nexus-main.jar:/opt/sonatype/nexus/lib/boot/activation-1.1.1.jar:/opt/sonatype/nexus/lib/boot/jakarta.xml.bind-api-2.3.3.jar:/opt/sonatype/nexus/lib/boot/jaxb-runtime-2.3.3.jar:/opt/sonatype/nexus/lib/boot/txw2-2.3.3.jar:/opt/sonatype/nexus/lib/boot/istack-commons-runtime-3.0.10.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.main-4.3.6.jar:/opt/sonatype/nexus/lib/boot/osgi.core-7.0.0.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.specs.activator-4.3.6.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.diagnostic.boot-4.3.6.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.jaas.boot-4.3.6.jar com.install4j.runtime.launcher.UnixLauncher run 9d17dc87 0 0 org.</description></item><item><title>Kafka 3.X</title><link>https://coolbeevip.github.io/posts/kafka/kafka-3/</link><pubDate>Wed, 09 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kafka/kafka-3/</guid><description>由于 ksqlDB 在 Kafka 之上运行，我们将使用 Docker Compose 来运行 Kafka 组件、ksqlDB 服务器和 ksqlDB CLI 客户端：
Docker 创建文件 ksqldb.yml
--- version: &amp;#39;2&amp;#39; services: zookeeper: image: confluentinc/cp-zookeeper:7.0.1 hostname: zookeeper container_name: zookeeper ports: - &amp;#34;2181:2181&amp;#34; environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 broker: image: confluentinc/cp-kafka:7.0.1 hostname: broker container_name: broker depends_on: - zookeeper ports: - &amp;#34;29092:29092&amp;#34; environment: KAFKA_BROKER_ID: 1 KAFKA_ZOOKEEPER_CONNECT: &amp;#39;zookeeper:2181&amp;#39; KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0 KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 ksqldb-server: image: confluentinc/ksqldb-server:0.24.0 hostname: ksqldb-server container_name: ksqldb-server depends_on: - broker ports: - &amp;#34;8088:8088&amp;#34; environment: KSQL_LISTENERS: http://0.</description></item><item><title>Migrate Spring Data Elasticsearch from 3.x version to 4.x</title><link>https://coolbeevip.github.io/posts/elasticsearch/migrate-spring-data-elasticsearch-from-3.x-version-to-4.x/</link><pubDate>Sun, 06 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/elasticsearch/migrate-spring-data-elasticsearch-from-3.x-version-to-4.x/</guid><description>Spring Data Elasticsearch 从 3.X 迁移到 4.X
因为需要将产品的 spring boot 2.1.6.RELEASE 升级到 2.3.12.RELEASE，升级过程中发现有一些需要迁移的部分，特此整理记录。 本文不是迁移指南，仅仅是工作中遇到的迁移问题笔记
依赖组件 组件 迁移前 迁移后 spring-data-elasticsearch 3.1.9 4.0.9 elasticsearch 6.4.3 7.6.2 GetQuery 已废弃 以下代码中 GetQuery 已经被废弃，并且 getQuery.setId 方法已经被删除
GetQuery getQuery = new GetQuery(); getQuery.setId(globalTxId); GlobalTransactionDocument globalTransaction = this.template .queryForObject(getQuery, GlobalTransactionDocument.class); 使用以下代码替换
Query query = new NativeSearchQueryBuilder().withIds(Collections.singletonList(globalTxId)).build(); SearchHit&amp;lt;GlobalTransactionDocument&amp;gt; result = this.template.searchOne(query, GlobalTransactionDocument.class); GlobalTransactionDocument globalTransaction = result.getContent(); ElasticsearchTemplate 已废弃 使用 ElasticsearchRestTemplate 代替 ElasticsearchTemplate
ElasticsearchRestTemplate 索引操作 ElasticsearchTemplate 的 getClient().admin().indices() 用法已经废弃</description></item><item><title>小升初</title><link>https://coolbeevip.github.io/posts/education/primary-school/</link><pubDate>Sun, 06 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/education/primary-school/</guid><description>时间线 时间 5月28-5月31 公办学校点招录取通知 5月30-5月31 填报志愿 志愿填报原则 第三，四批还在摇号的学校是差学校，因为在第一、二批都招不满，所以三，四批不建议填报
批次 一批 全区范围内公办派位学校（第一组） 全朝阳区范围内填报 最有用 二批 全区范围内公办派位学校（第二组） 就近摇号入学和房产对应入学 用来点招挂学籍的学校基本都出这组）这个名字是后改的，以前不这么叫，把这些差学校比较含蓄的叫一般中学,在朝阳区排名倒数30%的学校才叫一般中学,这些学校尽量避免在第一批去选择 三批 公办寄宿初中学校 差学校，摇上了就必须去了 四批 民办初中学校 差学校，摇上了就必须去了 填志愿的时候 别急着第一天就着急填写提交 31号最后一天中午过了再提交也来得及 提交早了 万一有别的录取通知 后悔都麻烦
收到学校邀请填报志愿（除清朝和嘉铭外） 这都不叫通知录取 都是那些没有点招资格 非集团学校的才会用这种方式通知 其目的主要是担心自己招不满人 报自己的人太少 才会使劲宣传 （例如 汇文垂杨柳 17中 日坛实验 工大实验以及个别民办学校等）
第一志愿让报本校：第一志愿是纯摇号（学校希望基数大） 第一志愿让报本校，第二志愿让报自己的集团分校：用没人报也摇不满的差学校接着，用同一法人的集团分校录取后 通过本部游学的方式再调回到本校上课 由于学籍不同单独成班并且每一个孩子都会在教委进行游学备案 这种方式合理合规 第一志愿就让你报集团分校：点招的孩子都走游学方式来本校单独分班（例如陈经纶帝景的2班6班） 点招上会有变动的一些学校 工大附中: 之前都是用工大附双桥来点招孩子 然后调到本校单独成班 也就是之前的13班 都是挑出来的孩子非常强(今年用来挂学籍的工大附双桥分校卖给八十官分了) 八十官分: 这所学校以前就是朝阳区靠前的学校,但是值得注意的是 以前官分集团里的常青藤分校 在卖给北中之前 成绩一直都是朝阳区 前十.原因就是 在2020年以前 官分集团一直都在点招好学生 而且把两个校区的好学生集中在常青藤校区上课. 今年收了工大附双桥以后 相当于点招又回来了 只不过会把好班设在官分上课（咱们群里比如兴隆小学 二外附小等一些小学学校推荐的尖子生 应该在上周六已经参与过学校组织的考试了）这是一所老师管的狠 作业留的多的学校 和陈经纶一个路子 唯一缺的就是好学生 有朝阳前十水准 今年值得关注 会点两个实验班出来 日坛中学和首师实验: 这两所学校 通过学校公众号以及各种新闻 教委官网 包括我在群里也发了不少 大家都能看到咱们区教委对这两个集团学校 给了非常大的支持力度 先后合并了 那么多所学校,今年的日坛中学 必然会点招不少优秀的孩子 毕竟已经去不少小学考试或者要了推荐信息了 这个五月底就能看得到 从今年筛选的范围来看 点四个实验班出来应该问题不大 北京中学: 北京中学合并了传媒 润丰等初中校后 今年的点招人数大大增加了 等于多了好几个可以用来点招挂学籍的学校, 校区 东泽园校区 今年正式开始启用 新初一都会放在这里上课 因此校园容纳量的问题也解决了 未被点招通知的孩子 咱们不牵扯到要填写集团分校 被点招的孩子只有接到学校通知才可以按照学校要求进行填写集团分校 如果未被通知的情况下 看别人这么填 自己也照着写 那可就真的留在最差的没人会报的学校里了 游学班的孩子是需要在教委进行备案的 这种方式合理合规 如果是自己报名进的 即使你成绩再好也没有人敢调你到其他校区 这就是违规了 属于人级分离 没有学校会这么做 校额到校名额 所谓校额到校的意思就是，你这个学校历年来就没有能靠中考成绩考进好高中的，那我政策上给你一个扶贫的支持，你学校年级前几名，虽然中考分数和人家录取分数线差着几十分，也让你直接进好高中。 但是为了不影响人家的高考成绩，既然是扶贫，那这些孩子和考进去的孩子又差着那么多学不到一起，因此就单独分班，成绩不统计入高中平均分，在朝阳区校额到校说白了就是区别对待的</description></item><item><title>Using OWASP Dependency Vulnerabilities Check with Maven</title><link>https://coolbeevip.github.io/posts/maven/maven-using-owasp-dependency-vulnerabilities-check/</link><pubDate>Thu, 24 Feb 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-using-owasp-dependency-vulnerabilities-check/</guid><description>使用 OWASP 依赖检查 Maven 插件 dependency-check-maven 发现依赖漏洞
增加编译插件 在 pom.xml 中增加如下配置，如果是多模块项目请增加在最外层 pom.xml 中，并且配置 &amp;lt;goal&amp;gt; 为 aggregate
&amp;lt;properties&amp;gt; &amp;lt;dependency-check-maven.version&amp;gt;6.5.3&amp;lt;/dependency-check-maven.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.owasp&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;dependency-check-maven&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${dependency-check-maven.version}&amp;lt;/version&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;name&amp;gt;notifier-dependency-check&amp;lt;/name&amp;gt; &amp;lt;format&amp;gt;HTML&amp;lt;/format&amp;gt; &amp;lt;failBuildOnCVSS&amp;gt;9&amp;lt;/failBuildOnCVSS&amp;gt; &amp;lt;failOnError&amp;gt;false&amp;lt;/failOnError&amp;gt; &amp;lt;skipProvidedScope&amp;gt;true&amp;lt;/skipProvidedScope&amp;gt; &amp;lt;skipRuntimeScope&amp;gt;true&amp;lt;/skipRuntimeScope&amp;gt; &amp;lt;skipTestScope&amp;gt;true&amp;lt;/skipTestScope&amp;gt; &amp;lt;retireJsAnalyzerEnabled&amp;gt;false&amp;lt;/retireJsAnalyzerEnabled&amp;gt; &amp;lt;skipArtifactType&amp;gt;pom&amp;lt;/skipArtifactType&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;executions&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;aggregate&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;/executions&amp;gt; &amp;lt;/plugin&amp;gt; &amp;lt;/plugins&amp;gt; &amp;lt;/build&amp;gt; failBuildOnCVSS 当发现此级别的漏洞后编译失败，评分和严重等级如下
0.0	None 0.1 – 3.9	Low 4.0 – 6.9	Medium 7.0 – 8.9	High 9.0 – 10.0	Critical failOnError 发现 CVSS 评分大于等于 9 时编译失败</description></item><item><title>Run Docker without Docker Desktop on macOS</title><link>https://coolbeevip.github.io/posts/kubernetes/run-docker-without-docker-desktop-on-macos/</link><pubDate>Mon, 14 Feb 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kubernetes/run-docker-without-docker-desktop-on-macos/</guid><description>由于 Docker Desktop 修改了授权条款，不再对企业用户免费，所以我们需要啊寻求一种替代品。到目前为止 Minikube 已经成为 Docker Desktop 最简单的替代品。 Minikube 用于在本地环境中运行 Kubernetes 集群，但它也运行了一个可用于运行容器的 Docker 守护进程。如果你不需要使用 Kubernetes ，那么你可以通过 minikube pause 暂停 Kubernetes 相关镜像，从而解决系统资源。
在 macOS 上，Minikube 运行在很多虚拟化技术上，由于ISSUE-6296原因，本例使用 Virtualbox 方式（你需要先安装 Virtualbox）。
卸载 Docker Desktop for macOS 如果你之前安装过 Docker Desktop，那么你需要先卸载它
在 Docker Desktop 菜单中选择 Troubleshoot 并且选择 Uninstall. 删除 /Applications/Docker.app 安装 Docker CLI 因为卸载 Docker Desktop 后将自动卸载 Docker CLI，所以你需要单独安装
$ brew install docker $ brew install docker-compose 提示： 在执行 brew install docker-compose 命令的时候可能得到如下的失败信息，这是因为依赖包下载失败。你可以使用 brew install gdbm 单独下载依赖包，就避免了找不到依赖版本的错误。</description></item><item><title>Kubectl Commands</title><link>https://coolbeevip.github.io/posts/kubernetes/kubectl-commands/</link><pubDate>Sun, 19 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kubernetes/kubectl-commands/</guid><description>常用 Kubectl 命令
创建命名空间 新建一个名为 nc-namespace.yaml 的 YAML 文件
apiVersion: v1 kind: Namespace metadata: name: nc-namespace 然后运行以下命令创建命名空间
$ kubectl create -f nc-namespace.yaml namespace/nc-namespace created 创建命名空间资源配额文件 新建一个名为 nc-quota.yaml 的 YAML 文件
apiVersion: v1 kind: ResourceQuota metadata: name: nc-quota namespace: nc-namespace spec: hard: pods: &amp;#34;10&amp;#34; requests.cpu: &amp;#34;2&amp;#34; requests.memory: 2Gi limits.cpu: &amp;#34;4&amp;#34; limits.memory: 4Gi 然后运行以下命令创建资源配额
$ kubectl create -f nc-quota.yaml resourcequota/nc-quota created 创建 PV 卷和 PVC 新建一个名为 nc-pv.yaml 的 YAML 文件
apiVersion: v1 kind: PersistentVolume metadata: name: nc-pv-volume namespace: nc-namespace spec: storageClassName: manual capacity: storage: 5Gi accessModes: - ReadWriteOnce hostPath: path: &amp;#34;/mnt/data&amp;#34; --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nc-pv-claim namespace: nc-namespace spec: storageClassName: manual accessModes: - ReadWriteOnce resources: requests: storage: 5Gi 然后运行以下命令创建卷</description></item><item><title>Automate Install Kafka Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-kafka-cluster/</link><pubDate>Thu, 09 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-kafka-cluster/</guid><description>集群概述 此脚本中的配置基于 Kafka 2.6.3 版本 使用 Kafka 发布包中自带的 Zookeeper 组件（通常这没有问题，除非你要将 Zookeeper 安装在单独的服务器上） 在 Kafka 安装目录下独立安装 JDK，目前只支持 Java 8 和 Java 11。 安装计划 服务器规划
IP SSH 端口 SSH 用户 SSH 密码 ROOT 密码 OS 10.1.207.177 22022 kafka 123456 root123 CentOS Linux release 7.9.2009 10.1.207.178 22022 kafka 123456 root123 CentOS Linux release 7.9.2009 10.1.207.183 22022 kafka 123456 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划
IP地址 Kafka Zookeeper Java 10.1.207.177 ✓ ✓ ✓ 10.</description></item><item><title>Automate Install AntDB Distributed Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-antdb-distributed-cluster/</link><pubDate>Sun, 05 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-antdb-distributed-cluster/</guid><description>集群概述 包含组件
MGR 集群的管理 GTM 全局事务管理 Coordinator 协调员管理用户会话 Data Node 数据节点 安装计划 服务器规划
IP SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 antdb 123456 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 antdb 123456 root123 CentOS Linux release 7.9.2009 10.1.207.182 22022 antdb 123456 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划
IP MGR GTM Coordinator DataNode 10.1.207.180 Master Master DataNode_Master_1, DataNode_Slave_3 10.1.207.181 Slave_1 Coordinator_1 DataNode_Master_2, DataNode_Slave_1 10.1.207.182 Slave_1 Coordinator_2 DataNode_Master_3, DataNode_Slave_2 节点安装路径</description></item><item><title>Automate Install Redis Master-Slave Sentinel with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-redis-master-slave-sentinel/</link><pubDate>Sun, 05 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-redis-master-slave-sentinel/</guid><description>集群概述 请先在目标服务器创建 redis 用户，此脚本在此用户下使用源代码编译的方式安装一主两从三哨兵的集群
安装计划 服务器规划
IP SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 redis redis123 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 redis redis123 root123 CentOS Linux release 7.9.2009 10.1.207.182 22022 redis redis123 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划
IP Redis Sentinel 10.1.207.180 master ✓ 10.1.207.181 slave ✓ 10.1.207.182 slave ✓ 节点安装路径
路径 描述 /opt/redis 源代码上传路径 ~/redis_uninstall.sh 集群卸载脚本 ~/redis.sh Redis 启停脚本 ~/sentinel.sh Sentinel 启停脚本 /data01/redis/bin redis 编译后的程序 /data01/redis/log 日志目录 /data01/redis/data 数据目录 /data01/redis/conf 配置文件目录 下载安装包和 Playbook 脚本 在客户机上创建 playbook 脚本存放目录</description></item><item><title>Slow LOG In Redis</title><link>https://coolbeevip.github.io/posts/redis/redis-slowlog/</link><pubDate>Sun, 05 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-slowlog/</guid><description>SLOWLOG 记录了 Redis 运行时间超时特定阀值的命令。这类慢查询命令被保存在 Redis 服务器的一个定长队列中，最多保存 slowlog-max-len(默认128）个慢查询命令。当慢查询命令达到128个时，新产生的慢查询被加入前，会从队列中删除最旧的慢查询命令。
配置 redis slowlog通过2个参数配置管理，默认命令耗时超过10毫秒，就会被记录到慢查询日志队列中；队列默认保存最近产生的128个慢查询命令。
slowlog-log-slower-than: 慢查询阀值，单位微秒，默认100000 (10毫秒)； 执行耗时超过这个值的查询会被记录；建议你生产环境设置为 10000（1毫秒），因为如果命令都是 1 毫秒以上，那么 Redis 吞吐率只有 1000 QPS；
slowlog-max-len: 慢查询存储的最大个数，默认128；生产设置设置大于1024，因为 slowlog 会省略过多的参数，慢查询不会占用过多的内存；
读取 返回最新的 2 条慢查询
SLOWLOG GET 2 1) 1) (integer) 9495 2) (integer) 1638760173 3) (integer) 13923 4) 1) &amp;#34;COMMAND&amp;#34; 5) &amp;#34;10.30.107.152:41830&amp;#34; 6) &amp;#34;&amp;#34; 2) 1) (integer) 9494 2) (integer) 1638759729 3) (integer) 17170 4) 1) &amp;#34;SADD&amp;#34; 2) &amp;#34;nc_oauth:uname_to_access:nc:vpengcheng&amp;#34; 3) &amp;#34;\xac\xed\x00\x05sr\x00Corg.springframework.security.oauth2.common.DefaultOAuth2AccessToken\x0c\xb2\x9e6\x1b$\xfa\xce\x02\x00\x06L\x00\x15additionalInformationt\x00\x0fLjava/util/Map;... (9974 more bytes)&amp;#34; 5) &amp;#34;10.</description></item><item><title>Automate Install MySQL InnoDB Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-mysql-innodb-cluster/</link><pubDate>Sun, 21 Nov 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-mysql-innodb-cluster/</guid><description>集群概述 MySQL InnoDB Cluster 是 MySQL 团队为了高可用性 (HA) 目的而引入的。它为 MySQL 提供了完整的高可用解决方案。我将通过 Ansible Playbook 展示三个节点的 InnoDB 集群配置。
MySQL InnoDB 集群有以下服务组成
MySQL shell Group Replication ( GR ) MySQL Router 安装计划 服务器规划
IP地址 SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 mysql 123456 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 mysql 123456 root123 CentOS Linux release 7.9.2009 10.1.207.182 22022 mysql 123456 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划</description></item><item><title>Automate Install Elasticsearch Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-elasticsearch-cluster/</link><pubDate>Sun, 07 Nov 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-elasticsearch-cluster/</guid><description>集群概述 脚本会在此用户下安装三节点集群，因为 7.X 版本后会自带 JDK，所以我们不需要提前安装 Java 环境。
安装计划 服务器规划
IP地址 SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 elasticsearch 123456 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 elasticsearch 123456 root123 CentOS Linux release 7.9.2009 10.1.207.182 22022 elasticsearch 123456 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划
IP地址 Elasticsearch 10.1.207.180 ✓ 10.1.207.181 ✓ 10.1.207.182 ✓ 节点安装路径
路径 描述 /opt/elasticsearch 程序安装路径 ~/elasticsearch_uninstall.sh 集群卸载脚本 ~/elasticsearch.sh 集群启停脚本 /data01/elasticsearch/logs 日志文件 /data01/elasticsearch/data 数据文件 /data01/elasticsearch/dump DUMP 文件 /data01/elasticsearch/temp 临时文件 下载安装包和 Playbook 脚本 在你的笔记本上创建 playbook 脚本存放目录</description></item><item><title>Linux Command - Grep</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-search/</link><pubDate>Sun, 07 Nov 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-search/</guid><description>使用正则表达式搜索文件内容 macOS
cat nc-auth_3000.log | grep -s &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39; centOS
cat nc-auth_3000.log | grep -P &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39; 使用正则表达式搜索压缩文件内容 macOS
gzip -dc nc-auth_3000.20211106.38.log.gz | grep -s &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39; centOS
gzip -dc nc-auth_3000.20211106.38.log.gz | grep -P &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39;</description></item><item><title>The Impact of Undertow Thread Options &amp; Database Connection Pool on Performance</title><link>https://coolbeevip.github.io/posts/java/java-undertow-threads-and-jdbc-pools/</link><pubDate>Thu, 23 Sep 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java/java-undertow-threads-and-jdbc-pools/</guid><description>Hikari 线程参数和数据库连接池参数对业务吞吐率的影响分析
场景 本例中我们使用 Undertow 作为 Web 容器，使用 Hikari 作为数据库连接池， 并通过 spring.datasource.hikari.maximum-pool-size 和 server.undertow.threads.worker 两个参数的调整，看看对于业务的性能影响有多大
为此我准备了一个简单的 DEMO，并且执行 1000 次请求，并发 100，每次请求执行一个 SLEEP(5) 的 SQL模拟单笔耗时。并在一个 2C 的服务器上测试。应用默认参数如下
spring.datasource.hikari.connection-timeout=30000 spring.datasource.hikari.minimum-idle=10 spring.datasource.hikari.maximum-pool-size=10 server.undertow.threads.worker(默认是 2C*8) 默认参数 $ ab -c 100 -n 1000 http://localhost:6060/test This is ApacheBench, Version 2.3 &amp;lt;$Revision: 1879490 $&amp;gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests Completed 200 requests Completed 300 requests Completed 400 requests Completed 500 requests Completed 600 requests Completed 700 requests Completed 800 requests Completed 900 requests Completed 1000 requests Finished 1000 requests Server Software: Server Hostname: localhost Server Port: 6060 Document Path: /test Document Length: 14 bytes Concurrency Level: 100 Time taken for tests: 510.</description></item><item><title>Find The Biggest Objects In Redis</title><link>https://coolbeevip.github.io/posts/redis/redis-find-biggest-objects-in-redis/</link><pubDate>Wed, 25 Aug 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-find-biggest-objects-in-redis/</guid><description>在 REDIS 中一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际上中如果下面两种情况，我就会认为它是 bigkeys。
字符串类型：单个 value 超过5MB 哈希、列表、集合、有序集合元素可数超过 10000 因为 REDIS 是单进程处理，所以对 BIGKEY 的访问会产生阻塞，如果你获取 100 次单体大小为 5MB 的 KEY，那么这些数据（500MB）传输到客户端就需要一定的时间，这期间其他命令都要排队等待。
查找 BIGKEY 使用 bigkeys 命令可以统计大对象（建议在从结点执行），为了方式阻塞，我们设置一个休眠参数 -i 0.1
redis-cli -h &amp;lt;ip&amp;gt; -p &amp;lt;port&amp;gt; -a &amp;lt;password&amp;gt; --bigkeys -i 0.1 结果如下：
$ redis-cli -h 192.168.51.207 -p 9015 --bigkeys Warning: Using a password with &amp;#39;-a&amp;#39; or &amp;#39;-u&amp;#39; option on the command line interface may not be safe. # Scanning the entire keyspace to find biggest keys as well as # average sizes per key type.</description></item><item><title>Multiple SSH Keys Settings For Different Git Platform[Github、Gitlab]</title><link>https://coolbeevip.github.io/posts/git/git-multiple-ssh-keys/</link><pubDate>Sun, 22 Aug 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-multiple-ssh-keys/</guid><description>我们在使用 Github、Gitlab 或者 JetBrains Space 时通常使用 SSH 密钥可以连接 Git 服务，而无需在每次访问时都提供用户名和个人访问令牌。 另外现在大量平台启用账户登录多次验证，也促进我们避免使用账号密码登录。
为了便于管理我们通常会为每个 Git 平台配置不同的 SSH KEY，然后通过 ~/.ssh/config 配置每个平台对应的 SSH KEY。
创建多个 SSH KEY 使用如下命令创建 id_github，注意提示输入文件名时请修改成 id_github
ssh-keygen -t ed25519 -C &amp;#34;coolbeevip@github.com&amp;#34; 使用同样的方法我们分别创建 id_gitlab 和 id_github，这时在的本地的 ~/.ssh 目录下会得到如下文件
id_github(私钥)、id_github.pub(公钥) id_gitlab(私钥)、id_gitlab.pub(公钥) 将 *.pub 文件内容分别导入到 Git 服务中，详细方式请参考 Github and SSH keys 、 GitLab and SSH keys 或 JetBrains Space and SSH keys
配置 SSH 编辑 ~/.ssh/config 文件为每个 Git 地址配置不同的私钥
Host github.com ServerAliveInterval 60 UseKeychain yes IdentityFile ~/.</description></item><item><title>Approximate Counting Morris Algorithm in Java</title><link>https://coolbeevip.github.io/posts/algorithm/algorithm-morris-approximate-counter/</link><pubDate>Sun, 22 Aug 2021 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/algorithm/algorithm-morris-approximate-counter/</guid><description>这是一个 Morris 计数器（近似计数算法）的 Java 实现，用很小的数据结构准确估计具有几十亿数据量的数据计数。 我们通常会定义一个 Long 类型对象，通过累加的方式实现计数。每个 Long 类型占用 8 byte (64bit) 空间，如果你有 30 亿个要记录的对象，那么你就需要 22GB 的空间存储这些计数器，这还不不包括在哈希中的对象ID。
背景 近似计数算法是允许我们使用非常少量的内存对大量事件进行计数的技术。它由 Robert Morris 于 1977 年发明。 该算法使用概率技术来增加计数器，尽管它不能保证准确性，但它确实提供了对真实值的相当好的估计，同时引入了最小但相当恒定的相对误差。 在这篇文章中，我们详细介绍了 Morris 算法及其背后的数学原理。
Morris 在贝尔实验室工作时遇到了一个问题。他应该编写一段代码来计算大量事件，而他只有一个 8 位计数器。 由于事件的数量很容易超过 256，使用普通方法计算它们是不可行的，这种限制导致他构建了这个近似计数器，它不是提供精确计数，而是提供一个近似计数。
计数和投硬币 构建近似计数器的一个简单方案是对每次事件变换进行计数。每收到一个新事件，我们抛一次硬币，如果正面朝上，我们增加计数，否则不增加。 这样计数器中的值平均下来将代表总事件的一半（因为抛硬币的获得正面并的概率是 0.5）。当我们将计数乘以 2 时，我们将得到近似实际数量的计数。
CoinFlipsCounter.java
这种基于抛硬币的计数技术是参数为 (n, p) 的二项分布，其中 n 是所见事件的总数，p 是成功概率，即在抛硬币过程中出现正面的概率。对真实事件数 n 的计数值 v 由下式给出
$$ \large 估算值v = 实际值n * 概率p = 实际值n/2 $$
这种二项式的正态分布标准偏差将帮助我们找到估算中的误差，对于正态分布平均值两侧标准差的两倍覆盖了分布的 95%；我们使用它来查找计数器值中的相对和绝对误差。
$$ \large 误差 = \sqrt{实际值n * 概率p(1-概率p)} = \sqrt{估算值v/2} $$</description></item><item><title>GraphQL Tools Schema Parser</title><link>https://coolbeevip.github.io/posts/graphql-tools-schema-paarser-slow/</link><pubDate>Sat, 29 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/graphql-tools-schema-paarser-slow/</guid><description>SYSTEM
MacBook Pro 16G
JVM
-Xmx4g -Xms4g -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -Xnoclassgc -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:ParallelGCThreads=12 -XX:MaxTenuringThreshold=15 -XX:+ExplicitGCInvokesConcurrent -XX:+CMSParallelRemarkEnabled -XX:SurvivorRatio=8 -XX:CMSInitiatingOccupancyFraction=65 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCMSCompactAtFullCollection -XX:+CMSClassUnloadingEnabled -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 CPU Flame Graph
GrpaphQL Schema Parser
Slow Method</description></item><item><title>APISIX Study Notes (1) Build &amp; QuickStart</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-1-quickstart/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-1-quickstart/</guid><description>安装 在 macOS 基于源代码自己编译发布版本
安装 Etcd 启动 apisix-etcd.yml
version: &amp;#39;3.2&amp;#39; services: etcd-1: image: docker.io/bitnami/etcd:3.4.16 hostname: etcd container_name: apisix-etcd ports: - &amp;#39;2380:2380&amp;#39; - &amp;#39;2379:2379&amp;#39; environment: - ALLOW_NONE_AUTHENTICATION=yes - ETCD_NAME=etcd-1 - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380 - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 - ETCD_ADVERTISE_CLIENT_URLS=http://0.0.0.0:2379 volumes: - ./volume/apisix/etcd/data:/bitnami/etcd/data - ./volume/apisix/etcd/conf:/opt/bitnami/etcd/conf docker-compose -f docker-compose-apisix-etcd.yml up -d 验证 $ curl -L http://127.0.0.1:2379/health {&amp;#34;health&amp;#34;:&amp;#34;true&amp;#34;} 安装编译环境 安装 Node 10.23.0+ $ node -v v12.18.3 安装 Yarn $ npm install -g yarn $ yarn -v 1.22.10 安装 openresty 、luarocks、lua、curl、 git brew install openresty/brew/openresty luarocks lua@5.</description></item><item><title>APISIX Study Notes (2) Plugins Traffic Split</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-2-plugins-traffic-split/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-2-plugins-traffic-split/</guid><description>场景描述 我有两个 UPSTREAM 服务:
UPSTREAM 1 $ curl -i -X GET http://192.168.51.234:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:09:29 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} UPSTREAM 2 $ curl -i -X GET http://10.19.88.60:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:08:12 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} 我希望通过 APISIX 将请求流量路由到两个不同的 UPSTREAM 服务上，参考插件 traffic-split 的样例，可以实现此功能
配置路由 &amp;amp; traffic-split 本例中并没有单独定义 UPSTREAM，而是在 traffic-split 中直接定义了 UPSTREAM 的地址</description></item><item><title>APISIX Study Notes (3) Install with Docker</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-3-install-with-docker/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-3-install-with-docker/</guid><description>使用 Docker 启动
定义卷目录 APISIX 目前好像还不支持通过环境变量配置参数，所以需要在宿主机上创建配置文件，并在启动 Docker 时通过 Volume 映射进容器
规划外部卷目录
mkdir apisix_home mkdir -p apisix_home/apisix_volume/apisix/apisix_conf mkdir -p apisix_home/apisix_volume/apisix/dashboard_conf 定义 APISIX Dashboard 配置文件 apisix_home/apisix_volume/apisix/dashboard_conf/conf.yaml
conf: listen: # 绑定 IP 地址 host: 0.0.0.0 # 监听端口 port: 9000 etcd: # etcd 用户名 # username: &amp;#34;root&amp;#34; # etcd 密码 # password: &amp;#34;123456&amp;#34; # etcd 地址，支持集群多节点定义 endpoints: - apisix-etcd:2379 log: error_log: # 日志级别 debug, info, warn, error, panic, fatal level: warn # 日志输出路径 file_path: logs/error.</description></item><item><title>APISIX Study Notes (4) Plugins Proxy Rewrite</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-4-plugins-proxy-rewrite/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-4-plugins-proxy-rewrite/</guid><description>在 APISIX STUDY NOTES (2) PLUGINS TRAFFIC SPLIT 提到，我们可以通过这个插件实现上游服务的导流，但是这个插件只能通过自定义 URL参数 或者 REQUEST HEADER 的方式传递导流变量。如果我们想通过 URL PATH 的方式实现上游业务的到导流，可以使用 Proxy Rewrite 插件
场景描述 我有两个 UPSTREAM 服务:
UPSTREAM 1 $ curl -i -X GET http://192.168.51.234:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:09:29 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} UPSTREAM 2 $ curl -i -X GET http://10.19.88.60:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:08:12 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{.</description></item><item><title>Bash script automates the Maven project Git release process</title><link>https://coolbeevip.github.io/posts/git/git-automate-tag-release-process-with-bash/</link><pubDate>Sun, 16 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-automate-tag-release-process-with-bash/</guid><description>开源项目中我们大多采用主干开发模式管理我们的项目，他基本遵循以下规则
所有的 PR 都默认向主干合并 主干上项目的版本号是 -SNAPSHOT 当主干要发布时，我们会建立与之对应的 X 分支（此分支的目的是为了基于此分支发布补丁版本） 基于当前主干去除版本号中的 -SNAPSHOT 后建立与版本对应的 TAG 将主干上的版本号中的 minor 累加一，并在后边增加 -SNAPSHOT 后缀 此过程繁琐，切容易出错。我制作了一个脚本 maven-project-git-release.sh 用来实现这个过程的规范化和自动化
当然，这并不意味着你不需要掌握正手动发布的过程。
由于某种原因导致自动过程中断后，你依然需要手动去处理，所以在使用这个脚本前，请确保你了解这个脚本帮你做了什么工作，以及如何做的。
如何使用 maven-project-git-release.sh 脚本会帮你自动化以下工作
创建一个编译用的目录
目录会创建在你系统的临时目录下，在我的 Mac 系统系统中看起来像 /var/folders/fd/gqdh88px2fj66tmtcy6ffr580000gn/T
在编译用的目录中 git clone 你的仓库代码
你的仓库地址在使用脚本时通过参数指定，像这样 sh maven-project-git-release.sh git@github.com:coolbeevip/license-maven-plugin.git
编译你的代码确保正确
默认在当前仓库根目录下执行 mvn clean package，如果你需要特殊的方式，可以修改脚本中的 check_source_before_release 函数
计算版本号分支名
根据 pom 中的版本定义，自动计算下一版本号，默认采 maven 的3段式版号方式 major.minor.patch，并以此为基准滚动 minor 版本号，如果你需要特殊的方式，可以修改脚本中的 next_version 函数
输出发布计划
发布计划中会显示你要发布的仓库地址，当前版本号、维护用 X 分支、TAG 名称、下一个版本号等信息
Release Plan: ==================================================================== OS: Darwin GIT_REPO_URL: git@github.com:coolbeevip/license-maven-plugin.git RELEASE WORK DIR: /var/folders/fd/gqdh88px2fj66tmtcy6ffr580000gn/T/release-license-maven-plugin.</description></item><item><title>JProfiler with Docker Sonatype Nexus3</title><link>https://coolbeevip.github.io/posts/docker/jprofiler-with-docker/</link><pubDate>Fri, 14 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/jprofiler-with-docker/</guid><description>使用 JProfiler 监控 Docker Sonatype Nexus3
下载 JProfiler 从 https://www.ej-technologies.com/下载 JProfiler 和 Agent（注意版本必须一致）
JProfiler GUI
https://download-gcdn.ej-technologies.com/jprofiler/jprofiler_macos_12_0_2.dmg
JProfiler Agent
https://download-gcdn.ej-technologies.com/jprofiler/jprofiler_linux_12_0_2.sh
在服务器上安装 JProfiler Agent 将下载后的 jprofiler_linux_12_0_2.sh 传到服务器上，通过 sh jprofiler_linux_12_0_2.sh 命令按提示安装即可
默认安装路径为 /opt/jprofiler12/，这个路径在启动 Docker 的时候要映射到容器内部
启动 Docker Sonatype Nexus3 在官方 sonatype/nexus3 容器启动参数的基础上做如下修改
使用 -v /opt/jprofiler12:/opt/jprofiler12 将 jprofiler 路径映射到容器内部
增加 -agentpath:/opt/jprofiler12/bin/linux-x64/libjprofilerti.so=port=9899 JVM 参数，设置监听端口为 9899
增加 -p 9899:9899 容器端口映射
docker run -d \ -e NEXUS_CONTEXT=nexus \ -e INSTALL4J_ADD_VM_PARAMS=&amp;#34;-Xms10g -Xmx10g \ -agentpath:/opt/jprofiler12/bin/linux-x64/libjprofilerti.so=port=9899 \ -XX:MaxDirectMemorySize=15530M \ -XX:ActiveProcessorCount=16 \ -XX:+UseParNewGC \ -XX:ParallelGCThreads=12 \ -XX:MaxTenuringThreshold=6 \ -XX:SurvivorRatio=5 \ -XX:+UseConcMarkSweepGC \ -XX:-CMSParallelRemarkEnabled \ -XX:CMSInitiatingOccupancyFraction=65 \ -XX:+UseCMSInitiatingOccupancyOnly \ -XX:+UseCMSCompactAtFullCollection \ -XX:+CMSClassUnloadingEnabled \ -XX:+DisableExplicitGC \ -XX:+PrintGCDetails \ -Xloggc:/nexus-data/vgc/nexus-$(date +%s).</description></item><item><title>Securing Docker ports with firewalld</title><link>https://coolbeevip.github.io/posts/docker/securing-docker-ports-with-firewalld/</link><pubDate>Tue, 11 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/securing-docker-ports-with-firewalld/</guid><description>概述 为了保护 Docker 暴露的端口不受外部访问的影响，可以使用 firewalld 配置防火墙规则，只允许特定的 IP 访问。 通过让 firewalld 创建 DOCKER-USER 链，我们可以实现由 firewalld 维护的安全 Docker 端口, Docker 处理 iptables 规则以提供网络隔离，更多详细
本文基于环境
Docker-CE 19.03.12 CentOS Linux release 7.8.2003 Firewall 0.6.3 本文例子:
我们使用 Docker 安装一个 Nginx，并将 80(HTTP) 端口对外映射为 8080，443(HTTPS) 端口对外映射为 8443，并通过 Firewalld 仅允许特定的 IP 访问；提示：后续的防火墙规则中配置的端口是容器内部端口，例如 80，443
192.168.51.246 安装 Nginx Docker
配置 192.168.51.245 可以访问 Nginx Docker
其他机器无法访问 Nginx Docker
重要的事情说三遍
如果你在 Docker 运行时重启 firewalld，那么 firewalld 将删除 DOCKER-USER
不要在 Docker 运行时重启 firewalld
不要在 Docker 运行时重启 firewalld</description></item><item><title>Use Maven plugin to export license info in source files and its optional dependencies</title><link>https://coolbeevip.github.io/posts/maven/maven-export-dependencies-analyse-license/</link><pubDate>Sun, 09 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-export-dependencies-analyse-license/</guid><description>有的时候我们那需要分析多模块 Maven 项目的依赖使用情况，并希望能够分析出这些依赖的 LICENSE 信息。使用 io.github.coolbeevip:license-maven-plugin 插件 可以生成 TXT 或者 CSV 格式的分析报告
youtube
bilibili
CSV 格式的报告 NOTICE.CSV NOTICE-LICENSE.CSV TXT 格式的报告 NOTICE.TXT NOTICE-LICENSE.TXT 插件 LICENSE-MAVEN-PLUGIN format 导出格式，支持 csv、txt； license 是否分析 LICENSE 信息，默认 false； ignoreGroupIds 忽略 groupId 列表, 多个用逗号分割; timeout 分析 LICENSE 的超时时间，默认 5 秒; 导出报告 在 Maven 项目的根目录执行如下命令
导出 CSV
mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=csv 导出 TXT
mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=txt 提示： 导出的报告位置在 ./target/distribute 目录下
导出报告(忽略部分依赖) mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=csv -DignoreGroupIds=org.apache.servicecomb,com.github.seanyinx 导出报告(分析LICENSE) 此功能使用 selenium 从 Maven Central Repository 分析依赖的 License 信息</description></item><item><title>Synchronize between image repositories with Bash</title><link>https://coolbeevip.github.io/posts/docker/docker-pulling-pushing/</link><pubDate>Mon, 19 Apr 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/docker-pulling-pushing/</guid><description>从源镜像仓库批量拉取镜像，并将这些镜像推送到目标镜像仓库的批量脚本
#!/bin/bash ################################################# # 使用方式 # 从源仓库拉取镜像到本机 # sh docker-images-pulling-pushing.sh pull # # 将本机镜像推送到目的仓库 # sh docker-images-pulling-pushing.sh push # # 清理本机的镜像 # sh docker-images-pulling-pushing.sh clean ################################################# # 源仓库地址 DOCKER_REPO_FROM= # 目标仓库地址 DOCKER_REPO_TO=192.168.2.2:8888/ DOCKER_REPO_TO_USER=test DOCKER_REPO_TO_PASS=Test123456 # 镜像定义 DOCKER_IMAGES=() DOCKER_IMAGES+=(postgres:9.6) DOCKER_IMAGES+=(elasticsearch:6.6.2) DOCKER_IMAGES+=(coolbeevip/servicecomb-pack) # 从源仓库地址拉取镜像到本机仓库 function pull(){ echo &amp;#34;Pull images from $DOCKER_REPO_FROM&amp;#34; for image in ${DOCKER_IMAGES[@]}; do docker pull $DOCKER_REPO_FROM$image done } # 本机镜像推送到目的仓库 function push(){ docker login http://$DOCKER_REPO_TO -u $DOCKER_REPO_TO_USER -p $DOCKER_REPO_TO_PASS echo &amp;#34;Push $DOCKER_REPO_FROM to $DOCKER_REPO_TO&amp;#34; for image in ${DOCKER_IMAGES[@]}; do docker image tag $DOCKER_REPO_FROM$image $DOCKER_REPO_TO$image docker push $DOCKER_REPO_TO$image done } # 清理本机拉取后的镜像 function clean(){ echo &amp;#34;Remove images&amp;#34; docker rmi -f $(docker images | grep $DOCKER_REPO_FROM | awk &amp;#39;{print $3}&amp;#39;) docker rmi -f $(docker images | grep $DOCKER_REPO_TO | awk &amp;#39;{print $3}&amp;#39;) } case &amp;#34;${@: -1}&amp;#34; in pull ) pull ;; clean ) clean ;; push ) push ;; esac</description></item><item><title>About</title><link>https://coolbeevip.github.io/about/</link><pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/about/</guid><description>Hi, I&amp;rsquo;m Zhang Lei 👋
Software Engineer at Beijing, China
Apache Committer、Apache ServiceComb PMC member
My Favorite Software</description></item><item><title>Bookmarks</title><link>https://coolbeevip.github.io/bookmarks/</link><pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/bookmarks/</guid><description>Some of my favorite websites/tools with excellent design and UX that I highly recommend
Apache Software Foundation ASF 3rd Party License Policy
ASF Committer Search
ASF Account Utility
ASF Mail Search
Nearby Apache People
ASF INFRA Deploy snapshots to Nexus from Github Actions
ASF INFRA Secret Repo Tokens for use with GitHub-Actions
JetBrains All Products Packs for Apache committers
JProfiler Products for Open Source Licenses
Specification JSONPath specification
SMPP(Short Message Peer-to-Peer) Protocol Specification</description></item><item><title>MacOS Switch JDK</title><link>https://coolbeevip.github.io/posts/java/macos-switch-jdk/</link><pubDate>Thu, 25 Mar 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java/macos-switch-jdk/</guid><description>查看本机 JDK 版本 命令行输入 /usr/libexec/java_home -V 可以看到多个 JDK 版本
$ /usr/libexec/java_home -V Matching Java Virtual Machines (2): 11.0.10, x86_64:	&amp;#34;OpenJDK 11.0.10&amp;#34;	/Users/zhanglei/Library/Java/JavaVirtualMachines/adopt-openj9-11.0.10/Contents/Home 1.8.0_201, x86_64:	&amp;#34;Java SE 8&amp;#34;	/Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home /Users/zhanglei/Library/Java/JavaVirtualMachines/adopt-openj9-11.0.10/Contents/Home 查看当前使用的 JDK 版本 $ java -version java version &amp;#34;1.8.0_201&amp;#34; Java(TM) SE Runtime Environment (build 1.8.0_201-b09) Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) 切换 JDK 切换到 JDK 11.0.10 版本，并查看切换后的 JDK 版本
$ export JAVA_HOME=`/usr/libexec/java_home -v 11.0.10` $ java -version openjdk version &amp;#34;11.</description></item><item><title>Oracle Proxy Using HAProxy Docker</title><link>https://coolbeevip.github.io/posts/haproxy/haproxy_oracle_proxy_using_haproxy_docker/</link><pubDate>Tue, 01 Sep 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/haproxy/haproxy_oracle_proxy_using_haproxy_docker/</guid><description>下载 HAProxy Docker
docker pull haproxy:2.3 创建工作目录
mkdir -p /opt/haproxy-oracle/docker_volume 在 /opt/haproxy-oracle/docker_volume 目录下创建如下 haproxy.cfg 文件，请将文件尾部的 oracle 地址和端口改为你的地址和端口
global daemon log 127.0.0.1 local0 log 127.0.0.1 local1 notice maxconn 4096 tune.ssl.default-dh-param 2048 defaults log global retries 3 maxconn 2000 timeout connect 5s timeout client 50s timeout server 50s listen stats bind *:9090 balance mode http stats enable stats auth admin:admin stats uri /stats listen oracle-proxy log global bind :1521 mode tcp balance roundrobin server oracle-1 10.</description></item><item><title>Setting up Redis for Production</title><link>https://coolbeevip.github.io/posts/redis/redis-setting-up-redis-for-production/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-setting-up-redis-for-production/</guid><description>安装 官方建议的安装方法是从源代码编译安装，您可以从 redis.io 下载最新稳定版的 TAR 包
wget https://download.redis.io/releases/redis-6.2.5.tar.gz tar xvzf redis-6.2.5.tar.gz cd redis-6.2.5 make 此时，您可以通过键入 make test 来测试您的构建是否正常工作。编译后 redis-6.2.5/src 目录填充了一部分可执行文件。 最好将编译后的 Redis 执行文件都复制到适当的位置，或者使用以下命令手动复制（假设我们的安装路径是 /usr/local/redis）：
# 可执行文件 sudo mkdir -p /usr/local/redis/bin sudo cp src/redis-server /usr/local/redis/bin sudo cp src/redis-cli /usr/local/redis/bin sudo cp src/redis-sentinel /usr/local/redis/bin sudo cp src/redis-benchmark /usr/local/redis/bin sudo cp src/redis-check-aof /usr/local/redis/bin sudo cp src/redis-check-rdb /usr/local/redis/bin # 配置文件 sudo mkdir -p /usr/local/redis/conf sudo cp redis.conf /usr/local/redis/conf sudo cp sentinel.conf /usr/local/redis/conf # 数据目录 sudo mkdir -p /usr/local/redis/data sudo mkdir -p /usr/local/redis/log # 创建链接 sudo ln -s /usr/local/redis/bin/redis-server /usr/bin/redis-server sudo ln -s /usr/local/redis/bin/redis-cli /usr/bin/redis-cli 提示： 复制完毕后，您可以删除 redis-6.</description></item><item><title>Using Redis as a Cache</title><link>https://coolbeevip.github.io/posts/redis/redis-using-redis-as-a-cache/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-using-redis-as-a-cache/</guid><description>当 Redis 用作缓存时，通常可以方便地让它在您添加新数据时自动驱逐旧数据。Redis 支持 6 种驱逐策略，你可以使用 maxmemory-policy 修改驱逐策略。默认是不驱逐，也就是说如果使用的内存超过了 maxmemory 限制，将提示 OOM。
你可以在 redis.conf 通过 maxmemory 2gb 设置，也可以通过 config set maxmemory 2gb 方式动态设置，注意： 在64bit系统下，maxmemory设置为0表示不限制内存使用，在32bit系统下，maxmemory不能超过3GB
驱逐策略 noenviction: 禁止驱逐数据(默认淘汰策略) 当 redis 内存数据达到 maxmemory，在该策略下，直接返回OOM错误； volatile-lru: 驱逐已设置过期时间的内存数据集中最近最少使用的数据； volatile-ttl: 驱逐已设置过期时间的内存数据集中即将过期的数据； volatile-random: 驱逐已设置过期时间的内存数据集中任意挑选数据； allkeys-lru: 驱逐内存数据集中最近最少使用的数据； allkeys-random: 驱逐数据集中任意挑选数据； volatile-lfu 驱逐已设置过期时间的内存数据集中使用频率最少的数据；（since 4.0） allkeys-lfu 驱逐内存数据集中使用频率最少的数据；（since 4.0） 如果 KEY 未设置过期时间，那么 volatile-random、volatile-ttl 和 volatile-lru 等同于 noenviction。
驱逐程序如何运作 重要的是要了解驱逐过程的工作方式如下：
客户端运行新命令，导致添加更多数据。 Redis 检查内存使用情况，如果大于 maxmemory limit ，则根据策略驱逐键。 执行新命令，等等。 所以我们不断地越过内存限制的边界，越过它，然后通过驱逐键返回到限制之下。 如果某个命令导致使用大量内存一段时间，则内存限制可能会明显超出。</description></item><item><title>Kafka Commands</title><link>https://coolbeevip.github.io/posts/kafka/kafka-commands/</link><pubDate>Tue, 28 Jul 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kafka/kafka-commands/</guid><description>常用 Kafka 命令
Topics 查询 topic 列表
./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --list 查看 topic 描述
./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe --topic my-topic Consumer Groups 查询消费组列表
./bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list 查询指定的组各 topic 消息消费情况
./bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group my-group</description></item><item><title>MySQL Commands</title><link>https://coolbeevip.github.io/posts/mysql/mysql-commands/</link><pubDate>Mon, 11 May 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/mysql/mysql-commands/</guid><description>常用 MySQL 命令
连接数配置 查看允许的最大连接数 show variables like &amp;#39;%max_connection%&amp;#39;; 如果过去曾达到此限制，则可以使用以下方法检查 SHOW GLOBAL STATUS LIKE &amp;#39;max_use%&amp;#39;; 配置用户的最大并发连接数 GRANT USAGE ON *.* TO &amp;#39;repl&amp;#39;@&amp;#39;%&amp;#39; WITH MAX_CONNECTIONS_PER_HOUR 100 MAX_USER_CONNECTIONS 10; 查看用户的最大并发连接数 SELECT User, Host, max_connections, max_user_connections FROM mysql.user; 设置最大连接数 set global max_connections=1000; 查看当前连接数 show status like &amp;#39;Threads%&amp;#39;; Threads_cached 当前线程池中缓存有多少空闲线程 Threads_connected 当前的连接数 ( 也就是线程数 ) Threads_running 已经创建的线程总数 Threads_created 当前激活的线程数 ( Threads_connected 中的线程有些可能处于休眠状态 ) thread_cache_size 值过小会导致频繁创建线程，直接反映就是 show status 查看 Threads_created 值过大。 当 Threads_cached 越来越少 但 Threads_connected 始终不降 且 Threads_created 持续升高 这时可适当增加 thread_cache_size 的大小</description></item><item><title>Maven Projects Best Practices</title><link>https://coolbeevip.github.io/posts/maven/maven-best-practices-for-structuring-projects-and-modules/</link><pubDate>Sat, 02 May 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-best-practices-for-structuring-projects-and-modules/</guid><description>本文整理构建Maven项目和模块的最佳实践的关键事项，其中包含依赖、版本、属性、模块划分等关键因素，推荐使用 Maven 3.6.3 及以上版本。 为了便于理解，我们假设有一个 API 网关项目，这个网关项目包含服务端、客户端、通知服务端支持插件。
目标 通过多模块方式组织项目 管理项目版本、依赖，属性 规划模块依赖关系 主项目 POM 每个项目都应该在项目根目录下有一个主 POM 文件，并通过主 POM 文件管理下级子模块。在主 POM 中至少会使用一下标签
properties: 定义字符集编码、JDK 版本、插件版本; modules: 下级子模块; pluginRepositories: 插件仓库地址（非必须，主要解决国内访问慢的问题）; repositories: 定义 Maven 私服地址; distributionManagement: 定义发布用 Maven 私服地址 pluginManagement: 定义管理类插件版本 profiles: (非必须) 例如：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;build xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;com.coolbeevip.apigateway&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;apigateway-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${revision}&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;!-- 使用 revision 管理项目版本 --&amp;gt; &amp;lt;revision&amp;gt;1.0.0-SNAPSHOT&amp;lt;/revision&amp;gt; &amp;lt;!-- project --&amp;gt; &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt; &amp;lt;project.reporting.outputEncodi ng&amp;gt;UTF-8&amp;lt;/project.reporting.outputEncoding&amp;gt; &amp;lt;maven.compiler.encoding&amp;gt;UTF-8&amp;lt;/maven.compiler.encoding&amp;gt; &amp;lt;maven.compiler.source&amp;gt;8&amp;lt;/maven.compiler.source&amp;gt; &amp;lt;maven.compiler.target&amp;gt;8&amp;lt;/maven.compiler.target&amp;gt; &amp;lt;!-- plugins version --&amp;gt; &amp;lt;maven-compiler-plugin.</description></item><item><title>Git Squash Commits</title><link>https://coolbeevip.github.io/posts/git/git-command-commit-squash/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-commit-squash/</guid><description>压缩合并 Commits，将多个 commit 整理合并的方法，这样可以使提交记录更加清晰
查看提交记录，选择你要合并的范围 git log commit 6d757f70af289b5a90d00bd5e4b93d892d64a258 (HEAD -&amp;gt; SCB-1669) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Thu Dec 19 13:53:26 2019 +0800 SCB-1669 Fixed reverse compensation sort bug in FSM commit 37e0c5d99d0e6dae188cbd78f543ba69433b928f (origin/SCB-1669) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Thu Dec 19 02:00:20 2019 +0800 SCB-1669 Fixed Reverse compensation sort bug in FSM commit b4ea8717a86d1eba1956d21727d05c466ff6d8a2 (upstream/master, origin/master, origin/HEAD, master) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Tue Dec 10 16:25:48 2019 +0800 SCB-1658 Improve encapsulation on txEntityMap of SagaData 可以看到最后两次提交，都是为了修复 SCB-1669 这个问题，此时我想合并最后两次提交 6d757f70af289b5a90d00bd5e4b93d892d64a258 和 37e0c5d99d0e6dae188cbd78f543ba69433b928f</description></item><item><title>Git Stash</title><link>https://coolbeevip.github.io/posts/git/git-command-commit-stash/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-commit-stash/</guid><description>你在当前分支上开发代码，此时不想 commit，但是又想切换到其他分支完成其他的工作，此时可以用 stash
在当前分支执行 stash 将当前分支未提交的代码隐藏起来 $ git stash Saved working directory and index state WIP on SCB-1577: 2554be3d SCB-1593 Add notice for Boringssl support ciphers (base) bogon:servicecomb-pack zhanglei$ 此时你可以看到已经存储到一个id为 2554be3d 里了，这时你可以用 git status 查看已经没有要提交的内容了
git status On branch SCB-1577 nothing to commit, working tree clean (base) bogon:servicecomb-pack zhanglei$ 这时你就可以切换到其他分支开始新的工作 (base) bogon:servicecomb-pack zhanglei$ git checkout master Switched to branch &amp;#39;master&amp;#39; Your branch is up to date with &amp;#39;origin/master&amp;#39;. 返回原来的分支继续工作 git checkout SCB-1577 Switched to branch &amp;#39;SCB-1577&amp;#39; 查看以前隐藏的修改内容 git stash list stash@{0}: WIP on SCB-1577: 2554be3d SCB-1593 Add notice for Boringssl support ciphers (base) bogon:servicecomb-pack zhanglei$ 恢复隐藏内容继续工作，使用 git stash apply {id} (base) bogon:servicecomb-pack zhanglei$ git stash apply stash@{0} On branch SCB-1577 Changes not staged for commit: (use &amp;#34;git add &amp;lt;file&amp;gt;.</description></item><item><title>Synchronizing Your Forked Git Project</title><link>https://coolbeevip.github.io/posts/git/git-command-rebase-upstream/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-rebase-upstream/</guid><description>当你 fork 一个仓库后，可以时用此方法使你 fork 后的仓库 master 分支保持和上游 master 分支的同步
使用 rebase 命令同步上游 master 分支到你本地的 master 分支，并推送到你 fork 后的仓库
git fetch upstream git checkout master git rebase upstream/master git push -f origin master 或者你确定放弃你本地所有的修改，则可以简单的重置为上游版本
git fetch upstream git checkout master git reset --hard upstream/master git push -f origin master 如果你也想同步 master 分支的修改到你的功能分支
git checkout &amp;lt;分支名&amp;gt; git rebase master git push -f origin &amp;lt;分支名&amp;gt;</description></item><item><title>Linux Command - Network</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-network/</link><pubDate>Wed, 02 Oct 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-network/</guid><description>Linux 网络相关命令
可以使用 yum install iperf3 安装这个工具，或者从网站 https://iperf.fr/iperf-download.php 下载
测试 TCP 吞吐量 假设我们要测试 10.1.207.180 和 10.1.207.181 两个服务器之间的带宽
先在其中一台服务器 10.1.207.181 服上启动 iperf3 服务
[root@oss-irms-181 ~]# iperf3 -s -p 5001 ----------------------------------------------------------- Server listening on 5001 ----------------------------------------------------------- 再在另一台机器 10.1.207.180 启动客户端连接服务端 10.1.207.181 测试
[root@oss-irms-180 ~]# iperf3 -c 10.1.207.181 -P 4 -t 30 -i 2 -p 5001 Connecting to host 10.1.207.181, port 5001 [ 4] local 10.1.207.180 port 49244 connected to 10.1.207.181 port 5001 [ 6] local 10.</description></item><item><title>Git Reset HEAD</title><link>https://coolbeevip.github.io/posts/git/git-reset-head/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-reset-head/</guid><description>Git 分支非常有用，您可以根据需要创建一个新分支，合并一个分支或删除一个分支。 您可以使用许多 git 命令来管理 git 中的分支。
当您使用 git checkout 分支时，HEAD会指出最后的提交。 简单来说，您可以说 Git HEAD 是当前分支。 每当您签出一个分支或创建一个新分支时，Git HEAD 都会转移它。
HEAD 是对当前检出分支中最后一次提交的引用。
在存储库中，HEAD 始终指向当前分支的起点。 换句话说，HEAD 是指向下一个提交的父对象或下一个提交将发生的地方的指针。
更具体地说，HEAD 是一个移动指针，它可以引用或可以不引用当前分支，但是它始终引用当前提交。
什么是 HEAD^ 插入符（^）是 Commit 的父级。
什么是 HEAD~ 代字号（〜）是一行几个字符（^）的简写字符。
HEAD〜2 与 HEAD ^^ 的作用相同。
如果写数字，则使用的默认值为1，因此 HEAD〜 等价于 HEAD ^。
如何检查HEAD的状态 您可以使用以下命令查看当前 Git HEAD 指向的位置：
$ cat .git/HEAD ref: refs/heads/master 并且，你可以使用以下命令查看指向 HEAD 的 commit 的 Hash ID：
$ git rev-parse --short HEAD 6f975a5 Detached HEAD HEAD 是您目前的工作分支。 当您尝试 git checkout 分支时，HEAD 指向该分支的顶部，这样您就可以继续工作而没有任何困难。</description></item><item><title>Git Revert</title><link>https://coolbeevip.github.io/posts/git/git-command-revert/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-revert/</guid><description>撤销上一次提交
$ git revert HEAD 撤销上两次提交
ISSUE-4 解决网关服务日志中无法正确显示经过代理访问的请求端 IP 问题 $ git revert [倒数第一个提交] [倒数第二个提交]</description></item><item><title>Important JVM Options</title><link>https://coolbeevip.github.io/posts/java/java-jvm-options/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java/java-jvm-options/</guid><description>Heap Memory -XX:MetaspaceSize Metaspace 空间初始大小，如果不设置的话，默认是20.79M。这个初始大小是触发首次 Metaspace Full GC 的阈值，例如 -XX:MetaspaceSize=128M
-XX:MaxMetaspaceSize Metaspace 最大值，默认不限制大小，但是线上环境建议设置，例如 -XX:MaxMetaspaceSize=512M
GC -Xnoclassgc 表示关闭JVM对类的垃圾回收，缺省情况下，当一个类没有任何活动实例时，JVM 就会从内存中卸装该类，但是这样会使性能下降。如果关闭类垃圾回收，就可以消除由于多次装入和卸装同一个类而造成的开销
-XX:+UseParNewGC 设置年轻代为并行收集
-XX:MaxTenuringThreshold 控制新生代需要经历多少次GC​晋升到老年代中的最大阈值，默认值 15
-XX:+CMSParallelRemarkEnabled CMS收集算法步骤如下：初始标记 -&amp;gt; 并发标记 -&amp;gt; 重新标记 -&amp;gt; 标记清除。 其中 初始标记和重新标记都需要STW，即暂停用户线程。 CMSParallelRemarkEnabled参数可以让重新标记阶段进行并行重新标记，减少暂停时间
-XX:SurvivorRatio 设置 Eden、S0、S1 分配比例，默认值是 8
-XX:SurvivorRatio=5 表示 Eden 占 50%，S0、S1 平分剩余空间
-XX:+UseCompressedOops In short, don&amp;rsquo;t turn it on, use a version which has it on by default.
https://stackoverflow.com/questions/11054548/what-does-the-usecompressedoops-jvm-flag-do-and-when-should-i-use-it
-XX:+DisableExplicitGC 禁止 System.gc() 触发 GC 操作，当没有开启 DisableExplicitGC 这个参数时,你会发现JVM每个小时会执行一次Full GC,这是因为JVM在做分布式GC,为RMI服务的, 可以通过 sun.</description></item><item><title>Linux Command - Disk</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-disk/</link><pubDate>Mon, 06 May 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-disk/</guid><description>Linux 磁盘相关命令
磁盘IO dd [root@localhost ~]# dd if=/dev/zero of=./a.dat bs=8K count=1M conv=fdatasync 记录了8192+0 的读入 记录了8192+0 的写出 8589934592字节(8.6 GB)已复制，14.8606 秒，578 MB/秒 [root@localhost ~]# dd if=./a.dat of=/dev/null bs=1M count=8k iflag=direct 记录了8192+0 的读入 记录了8192+0 的写出 8589934592字节(8.6 GB)已复制，14.2462 秒，603 MB/秒 磁盘空间 df 查看磁盘各个分区的空间大小、占用、可用等信息
$ df -h Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk1s5 466Gi 10Gi 128Gi 8% 488463 4881964417 0% / devfs 192Ki 192Ki 0Bi 100% 663 0 100% /dev /dev/disk1s1 466Gi 318Gi 128Gi 72% 4557528 4877895352 0% /System/Volumes/Data /dev/disk1s4 466Gi 8.</description></item><item><title>Git Commands</title><link>https://coolbeevip.github.io/posts/git/git-commands/</link><pubDate>Sat, 06 Apr 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-commands/</guid><description>常用 Git 命令
Init 在已有目录中初始化 GIT 仓库
$ git init $ git remote add origin &amp;lt;仓库地址&amp;gt; $ git add . $ git commit -m &amp;#34;Initial commit&amp;#34; $ git push -u origin master Branch 创建分支
git checkout -b &amp;lt;分支名&amp;gt; 推送分支
git push origin &amp;lt;分支名&amp;gt; 修改分支名
git branch -m &amp;lt;旧分支名&amp;gt; &amp;lt;新分支名&amp;gt; 删除本地分支
git branch -D &amp;lt;分支名&amp;gt; 删除远程分支
git push origin --delete &amp;lt;分支名&amp;gt; 拉取远程分支
git fetch origin &amp;lt;分支名&amp;gt; 拉取远程分支并切换
git checkout -b &amp;lt;分支名&amp;gt; origin/&amp;lt;分支名&amp;gt; 当前分支会退到指定版本</description></item><item><title>Docker Commands</title><link>https://coolbeevip.github.io/posts/docker/docker-commands/</link><pubDate>Wed, 06 Feb 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/docker-commands/</guid><description>常用 Docker 命令记录
镜像 镜像列表按照大小排序 docker images --format &amp;#34;{{.ID}}\t{{.Size}}\t{{.Repository}}&amp;#34; | sort -k 2 -h 删除所有镜像 docker rmi -f $(docker images | awk &amp;#39;{print $3}&amp;#39;) 删除所有 dangling 镜像 docker rmi -f $(docker images -a | grep &amp;#34;&amp;lt;none&amp;gt;&amp;#34; | awk &amp;#39;{print $3}&amp;#39;) 导出镜像 docker save -o postgres_9.6.tar postgres:9.6 docker save postgres:9.6 | gzip &amp;gt; postgres_9.6.tar 导入镜像 docker load -i postgres_9.6.tar 容器 删除所有 Exited 容器 docker rm $(docker ps -a | grep Exited | awk &amp;#39;{print $1}&amp;#39;) 停止并删除所有容器 docker stop $(docker ps | awk &amp;#39;{print $1}&amp;#39;) docker rm -f $(docker ps -a | awk &amp;#39;{print $1}&amp;#39;) 停止 dead 容器 删除实例时提示 device or resource busy</description></item><item><title>Flyway hung on the MySQL Router + MGR</title><link>https://coolbeevip.github.io/posts/flyway/flyway-hung-on-mysql-router-mgr/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/flyway/flyway-hung-on-mysql-router-mgr/</guid><description>Flyway 连接 MySQL Router 后启动卡在 GET_LOCK 语句
现象 MySQL MGR + Router 部署高可用集群 Flyway 客户端使用 jdbc:mysql:loadbalance 连接 初始化 Schema History 表、或者执行多个 SQL 脚本时 当满足以上条件时，Flyway 会卡在初始化阶段，经过分析发现停顿在执行 GET_LOCK 语句时
原因 Flyway 默认在执行 DDL 脚本时不启用事务，在初始化时 Flyway 会先执行 GET_LOCK 锁定数据库，然后再执行 DDL 脚本。当使用 jdbc:mysql:loadbalance 连接时，会随机选择一个数据源，如果执行 GET_LOCK 和 执行 DDL 不是一个数据源，就会导致执行等待锁释放
解决办法 在启动时设置 group=true 参数，这样 Flyway 在初始化时就会启用事务，确保一个事务内的 DDL 都在一个数据源执行
ISSUE-3154
public class FlywayTestManual { String url=&amp;#34;jdbc:mysql:loadbalance://192.168.51.206:3810,192.168.51.207:3810/nc_notifier?roundRobinLoadBalance=false&amp;amp;characterEncoding=utf8&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;useSSL=false&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=GMT%2B8&amp;amp;allowMultiQueries=true&amp;amp;allowPublicKeyRetrieval=true&amp;#34;; String user=&amp;#34;user&amp;#34;; String password=&amp;#34;pass&amp;#34;; @Test public void test(){ Flyway flyway = Flyway.</description></item><item><title>Flyway Support Oracle</title><link>https://coolbeevip.github.io/posts/flyway/java-flyway-support-oracle/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/flyway/java-flyway-support-oracle/</guid><description>记录在使用 Flyway 管理 Oracle 数据库脚本时遇到的一些问题，Flyway 5.2.1 - 7.7.3 都存在此问题。
1. Flyway not support Oracle 11g 异常信息
Caused by: org.flywaydb.core.internal.license.FlywayEditionUpgradeRequiredException: Flyway Enterprise Edition or Oracle upgrade required: Oracle 11.2 is no longer supported by Flyway Community Edition, but still supported by Flyway Enterprise Edition. at org.flywaydb.core.internal.database.base.Database.ensureDatabaseNotOlderThanOtherwiseRecommendUpgradeToFlywayEdition(Database.java:173) at org.flywaydb.core.internal.database.oracle.OracleDatabase.ensureSupported(OracleDatabase.java:91) at org.flywaydb.core.Flyway.execute(Flyway.java:514) at org.flywaydb.core.Flyway.migrate(Flyway.java:159) at org.springframework.boot.autoconfigure.flyway.FlywayMigrationInitializer.afterPropertiesSet(FlywayMigrationInitializer.java:65) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1855) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1792) ... 19 common frames omitted 修改 Flyway 5.2.4 OracleDatabase.java 社区版本做了版本号限制 修改 Flyway 6.5.7 OracleDatabase.</description></item><item><title>To roll up Flyway incremental changes into 1 file</title><link>https://coolbeevip.github.io/posts/flyway/java-flyway-merge-script-step/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/flyway/java-flyway-merge-script-step/</guid><description>Flyway 通过 SQL Patch 脚本的方式管理数据库脚本版本，开发一段时间后会积攒大量脚本。当一个版本稳定后我们希望合并成一个全量脚本
1.首先对齐程序与数据库中的脚本版本号 查看程序中脚本版本清单，例如：程序中有三个版本的脚本
V1.0.0.0__init.sql V1.0.0.1__add_user_table.sql V1.0.0.2__modify_user_table.sql 查看数据库中历史版本记录表 (默认是 flyway_schema_history) 中执行过的脚本版本，例如：
versions description script success 1.0.0.0 init.sql V1.0.0.0__init.sql 1 1.0.0.1 add_user_table.sql V1.0.0.1__add_user_table.sql 1 1.0.0.2 modify_user_table V1.0.0.2__modify_user_table.sql 1 这里只摘取了关键字段，你可以看到每个版本都已经执行，并且执行都是成功的 success=1
至此：你已经对齐了程序和数据库中脚本版本号，可以开始准备合并了
2.合并程序中的SQL脚本 合并多个脚本的内容到最大版本号的文件中，例如：将 V1.0.0.0__init.sql, V1.0.0.1__add_user_table.sql, V1.0.0.2__modify_user_table.sql 合并为 V1.0.0.2__init.sql
注意： 不是简单的文件合并，而是最终执行结果的合并
3.重新打包程序 只包含合 V1.0.0.2__init.sql 脚本的程序
4.停止所有老版本的程序 包含 V1.0.0.0__init.sql,V1.0.0.1__add_user_table.sql,V1.0.0.2__modify_user_table.sql 老脚本的程序
5.删除数据库中的版本历史表 默认是 flyway_schema_history
6.重启应用程序 在程序启动时设置基线版本参数为当前版本，设置这个参数的目的是告诉 Flyway 当前已经执行过 1.0.0.2 脚本了。这之前的脚本不要再执行了。
flyway.baseline-version=1.0.0.2 注意： 如果是空库，全新安装程序，那么则不需要设置 flyway.baseline-version 参数
7.结束 查看数据库中历史版本记录表 (默认是 flyway_schema_history) 中执行过的脚本版本，例如：
versions description script success 1.</description></item><item><title>Maven Commands</title><link>https://coolbeevip.github.io/posts/maven/maven-commands/</link><pubDate>Fri, 23 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-commands/</guid><description>常用 Maven 命令
Parameters -D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试； -P 指定 Profile 配置，可以用于区分环境； -e 显示maven运行出错的信息； -o 离线执行命令,即不去远程仓库更新包； -f 强制指定使用 POM 文件，或者包含 POM 文件的目录 -pl 选项后可跟随{groupId}:{artifactId}或者所选模块的相对路径(多个模块以逗号分隔) -am 表示同时处理选定模块所依赖的模块 -amd 表示同时处理依赖选定模块的模块 -rf 表示从指定模块开始继续处理 -N 表示不递归子模块 -X 显示maven允许的debug信息； -U 强制去远程更新 snapshot的插件或依赖，默认每天只更新一次。 &amp;ndash;no-snapshot-updates 禁止更新 snapshot Dependency 显示maven依赖数
mvn dependency:tree 显示maven依赖列表
mvn dependency:list 下载依赖包的源码
mvn dependency:sources Maven Wrapper 自动安装 maven 的包装器（适合不想手动安装Maven的用户），使用插件Maven Wrapper plugin将其自动化安装指定版本的 Maven
mvn -N io.takari:maven:wrapper -Dmaven=3.6.3 这个命令会在你的项目中生成如下文件，请将这些文件与源代码一起管理
mvnw: 这是 Linux Script 可执行文件，用来代替 mvn mvnw.cmd: 这是 Windows Script 可执行文件，用来代替 mvn mvn: 隐藏的文件夹，其中包含Maven Wrapper Java库及其属性文件 首次执行 mvnw 或者 mvnw.</description></item><item><title>Estimate host capacity based on QPS</title><link>https://coolbeevip.github.io/posts/stress-testing-host-estimate-with-qps/</link><pubDate>Wed, 07 Mar 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/stress-testing-host-estimate-with-qps/</guid><description>通过单个服务器压测的 QPS 估算需要的服务器数量
已知 QPS 和期望每笔耗时，估算服务器数量 服务器数量 $$ = QPS \div (1000 \div 每笔毫秒) \div 每服务器CPU个数 $$
例如：
QPS：每秒处理3200笔 每笔毫秒：50ms 每个服务器CPU个数：16 服务器数量 $$ 3200_{qps} \div (1000_{ms} \div 50_{ms}) \div 16_{cpu} = 10_{台} $$
已知 QPS 以及服务器数量，估算每笔耗时 每笔耗时毫秒 $$ = 1000 \div ( QPS \div ( 服务器数量 \times 每服务器CPU个数 ) ) $$
例如：
QPS：每秒处理3200笔 服务器数量：10 每服务器CPU个数：16 每笔耗时毫秒 $$ 1000 \div ( 3200 \div ( 10 \times 16 ) ) = 50_{ms}$$</description></item><item><title/><link>https://coolbeevip.github.io/posts/ai/camel-database-agent-en/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/ai/camel-database-agent-en/</guid><description>Pain Points in Data Analysis and Solutions In today&amp;rsquo;s data-driven business environment, a common scenario is: business analysts urgently need certain data analysis but must wait for technical team members who know SQL to provide support. According to a McKinsey study, analysts spend an average of 30-40% of their time just on data preparation and query construction. This dependency not only delays the decision-making process but also increases the workload of the technical team.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit10/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit10/</guid><description>KET UNIT10 WORDS 中文 英文 中文 英文 海滩 beach 沙漠 desert 森林 forest 岛 islands 湖泊 lake 高山 mountain 最深的 the deepest 最长的 the longest 最高的 the highest 最多的 the most 最大的 the biggest 最热的 the hottest 活动 activity 在机场 at the airport 在欧洲 in Europe 在世界上 in the world HOMEWORK 2024/01/03
完成 Unit10 练习册。 背诵PB P73 Reading Part2 Holiday Activities.默写并校准</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit3/</guid><description>KET UNIT3 1. Grammar Countable nouns How many 用于询问可数名词的数量 a few 修饰可数名词复数，表肯定意义，有一些，不是那么多; few 表否定意义，几乎没有 quite a few表示不少, 相当多 Uncountable nouns How much 用于问不可数名词的数量 a little 修饰不可数名词，表肯定意义，有一点儿 little 表否定意义，几乎没有 Countable nouns and Uncountable nouns a lot of 很多 no 没有 2. Plurals of nouns 1. 大多数名词在末尾加s：
book-books chair-chairs cat-cats 2. 以s、x、ch、sh、o结尾的名词，在末尾加es：
bus-buses class-classes glass-glasses match-matches watch-watches dish-dishes brush-brushes box-boxes fox-foxes half-halves 但也有例外，如photo-photos 3. 以辅音字母+y结尾的名词，把y变为i，再加es：
fly-flies city-cities baby-babies 4. 以f或fe结尾的名词，大多数情况下变为v，并加es：
leaf-leaves knife-knives wife-wives family-families 5.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit4/</guid><description>KET UNIT4 1. Grammar Present Continuous 现在进行时，句子结构为 主语 + 助动词 &amp;quot;be&amp;quot; + 现在分词（动词-ing 形式）, 例如： I am studying(我正在学习) I am studying for my exam(我正在为考试而学习) She is not working today(她今天不工作) What are you doing(你正在做什么) Present Simple 一般现在时，句子结构为 主语 + 谓语动词 I eat breakfast every day(我每天吃早饭) She does not like coffee(他不喜欢咖啡) Do they play tennis on Sundays?(他们星期日打网球吗) 2. Present participle(动词现在分词) 1. 一般规律：大多数动词的现在分词形式是在动词原形（即第一形式）后加-ing：
play-playing read-reading sing-singing 2. 以不发音的字母 e 结尾的动词，去掉 e，再加-ing：
make-making write-writing dance-dancing 但有一些例外，如 be-being 3.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit5/</guid><description>KET UNIT5 1. Grammar 完成练习册 P20-21 阅读、语法部分
2. Passages 熟读学生用书 P37 短文-Joanna Middleton-a young gymnast. 课文抄写两遍(w1) 熟读学生用书P40语法部分文章- Yusra Mardini，课文抄写两遍。(w2) 学生用书P39 Listening Part4, 5个题目做精听练习。听一句重复一句，听力文本在P159左侧，抄写一遍。(w2) 3. Conversation I &amp;hellip; because &amp;hellip; or I think &amp;hellip; because &amp;hellip;
Q: Which is the most exciting sport?
A1: I think playing football is the most exciting sport because football is the most popular sport in the world. I love watching football match on TV.
Q: How often do you play/go/do it?</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit6/</guid><description>KET UNIT6 1. Grammar Somebody have/has to do sth. (某人必须做某事) You have to clean bedroom at weekend.
Somebody don’t/doesn&amp;rsquo;t have/has to do sth. (某人不必做某事) You don’t have to clean bedroom at weekend.
Do/Does somebody have to do sth. (某人必须做某事吗?) Do you have to clean bedroom at weekend?
Key grammar points:
&amp;ldquo;To&amp;rdquo; must be followed by the base form of a verb. When the subject is in the third-person singular, &amp;ldquo;has to do&amp;rdquo; should be used.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit7/</guid><description>KET UNIT7 1. Conversation Hospital is a place where you see the doctor. Church is a building where Christians go to pray. Cinema is a place where you go to see a film. Factory is a place where goods are made. Train station is a place where you catch the train. Hotel is a building for people to stay, usually for a short time, people pay for their rooms and meals.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit7_zh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit7_zh/</guid><description>KET UNIT7 1. 句子 医院是你去看医生的地方。 教堂是基督徒去祷告的建筑。 电影院是你去看电影的地方。 工厂是制造商品的地方。 火车站是你赶火车的地方。 酒店是人们寄宿的建筑，通常是短期停留，人们为他们的房间和餐饮付费。 清真寺是穆斯林去敬拜的建筑。 博物馆是保存并向公众展示艺术、文化、历史对象的地方。 邮局是你发送信件、包裹或行李的地方。 体育场是一个大型的运动场地，周围有许多座位。 2. 单词 English 中文 English 中文 医院 基督教徒 教堂 绘画 电影院 工厂 火车站 象征；符号 酒店；旅馆 清真寺 穆斯林教徒 博物馆 邮局 体育场；运动场 火车站 烟花 昂贵的 无聊的 通告；通知 特价商品；特价销售 半价 包裹 行李 环岛 交通灯 十字路口 岔路口 桥 广场</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit8/</guid><description>KET UNIT8 1. Grammar 1.1 Past Continuous (过去进行时)， 表示过去某个时间点或时间段中，正在发生的事情 We were dancing at the party at eight o’clock last night. 过去时间点或时间点段中，两件事同时发生。如： My father was reading while my mother was cooking. 过去进行时可跟一般过去时连用，指某事突然发生在另一件事的进程之中。 When she came into class, her classmates were reading. While her classmates were reading, she came into class. While后面接过去进行时, When后面接一般过去时，这两个词不在句子中同时使用。 When my father left home, I was doing homework. While I was doing homework, my father left home. 1.2 Can/Can’t (能力) Can/Can’t 作为情态动词，跟动词原形连用，表示目前所具备的能力。过去式为 Could/Couldn’t, 表示过去所具备的能力。不论主语是单数还是复数，情态动词本身没有任何变化</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit8_zh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit8_zh/</guid><description>KET UNIT8 1. Grammar 1.1 Past Continuous (过去进行时)， 我们昨晚八点在派对上跳舞。
我父亲在读书，而我母亲在做饭。
当她进入教室时，她的同学们正在读书。
当她的同学们正在读书时，她进入了教室。
当我父亲离开家时，我正在做作业。
当我正在做作业时，我父亲离开了家。
1.2 Can/Can’t (能力) Can/Can’t 作为情态动词，跟动词原形连用，表示目前所具备的能力。过去式为 Could/Couldn’t, 表示过去所具备的能力。不论主语是单数还是复数，情态动词本身没有任何变化
我两岁时会走路。 我两岁时不能说话。 你两岁时会走路吗？ 是的，我会。不，我不会。 我会游泳，但我不会弹钢琴。 你会打篮球吗？是的，我会。不，我不会。 2. Vocabulary 中文 中文 测验；知识竞赛 疯狂的 互联网 少于 多于 兴奋的（修饰人） 粉丝 广告 分数 智能手机 笔记本电脑 台式电脑 新科技 键盘 存储卡；闪存卡 选项 折扣 在互联网上发布视频 请柬 邮件 动词：给某人发短信 发信息 检查 名人；名流 社交网络媒介 上传照片 下载 节奏蓝调 长途旅行 玩线上游戏 形容词：网络上走红的 信息 数以千计；成千上万 迷路 陌生的地方 兜；口袋 冠词 代词 动词 介词 数量词 情态动词 古典音乐 爵士乐 歌剧 流行音乐 摇滚 电子乐</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit9-exam-simple-future-answer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit9-exam-simple-future-answer/</guid><description>KET UNIT9 填空 will stay will succeed is going to visit is starting is graduating is leaving are going to have are performing won&amp;rsquo;t like is going am doing won&amp;rsquo;t have will become won&amp;rsquo;t forget is beginning arrives are eating won&amp;rsquo;t appreciate will tell is visiting are going won&amp;rsquo;t tell is landing will like is ending won&amp;rsquo;t perform will be is starting will be is finishing 造句 What do you plan to do tomorrow?</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit9-exam-simple-future/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit9-exam-simple-future/</guid><description>KET UNIT9 填空 If it rains tomorrow, I _________ (stay) home. I believe they _________ (succeed) in the near future. My family _________ (visit) Japan next month. The game _________ (start) at 8pm tonight. She _________ (graduate) from college next year. My plane _________ (leave) at 6:00 a.m. tomorrow. We _________ (have) a test next week. They _________ (perform) a play in the school theater this Friday. You _________ (not like) the results of the election.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit9-exam-verb-answer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit9-exam-verb-answer/</guid><description>KET UNIT9 填空 to go to take talking to visit working of winning (另一可能的答案是to have won, 这意味着他们已经赢了) making eating playing meeting to sleep to lock studying of flying to visit talking laughing going moving to travel watching being doing running eating to start to meet not to hear to learn smoking 造句 We choose to take the train. Mary hopes to ride her bike to school. She wants to learn to skate.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit9-exam-verb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit9-exam-verb/</guid><description>KET UNIT9 选择 I’m excited _________ (go) to the concert this weekend. We decided _________ (take) a break after two hours of studying. He stopped _________ (talk) when he realized nobody was listening. She would like _________ (visit) her grandmother this afternoon. After _________ (work) all day, he was too tired to cook dinner. They were proud _________ (win) the competition. We prefer _________ (make) our own meals instead of eating out.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/ket-unit9/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/ket-unit9/</guid><description>KET UNIT9 1. 语法（形容词、介词、动词后面再衔接动词时，搭配不同的动词形式） 形容词 + 动词不定式 I’m happy to see the film 动词 + 动词不定式 We choose to go by train 动词 + 动词现在分词 We enjoy eating Italian food for dinner would like + 动词不定式 I would like to go home by bus 介词 + 动词现在分词 Thanks for coming to our party 1.1 动词+动词不定式 choose/help/hope/learn/offer/want We choose to go by train（我们选择乘火车） Mary hopes to go to school by cycling（玛丽希望骑车去学校） She wants to learn to skate（她想要学习滑冰） He has to learn to do things for himself (他必须学会自己做事) I like to read（我喜欢阅读） The kids offered to wash dishes(孩子们主动提出洗碗) 1.</description></item><item><title/><link>https://coolbeevip.github.io/posts/english/vocabulary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/english/vocabulary/</guid><description>English 中文 English 中文 subject 学科 portrait 肖像画 Art 美术课 painting 绘画 Biology 生物课 living things 生物 Chemistry 化学课 substances 物质 under different conditions 在不同条件下 English 英语课 dictionary 字典 History 历史课 Egypt-Egyptian 埃及-埃及人 Geography 地理课 nature 自然 climate 气候 Physics 物理课 energy 能量 interaction 相互作用;相互影响 Maths 数学课 Music 音乐课 instrument 乐器 uniform 制服；校服 famous 著名的 modern 现代化的；超前的 funny 有趣的；滑稽的 kind 慈祥的；友善的 strict 严格的 fashionable 流行的；时髦的 traditional 传统的 clothing 服装 explain 解释 .</description></item><item><title/><link>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-ai-commit-message-en/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-ai-commit-message-en/</guid><description>Using Git Assistant AI Feature in IntelliJ Plugin to Generate Commit Messages Git Assistant is a powerful IntelliJ IDEA plugin that allows you to use its AI capabilities by configuring your own OpenAI key. In this article, we will explain how to use the AI feature in the Git Assistant plugin to generate commit messages.
Installing the Git Assistant Plugin First, you need to install the Git Assistant plugin in IntelliJ IDEA.</description></item><item><title/><link>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-commit-insights-en/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/git-assistant-intellij-plugin/git-assistant-commit-insights-en/</guid><description>Unleashing Git Commit Insights with JetBrains Git Assistant Plugin Git Assistant is a powerful IntelliJ IDEA plugin that provides users with powerful analysis tools through the Git Assistant Insights window in the right-side tool window, introduced in version 1.4.0.
The Hour/Weekday/Month feature analyzes the distribution of team activity based on hours, weekdays, and months, optimizing work schedules and task assignments. The Timezone feature visualizes the distribution of code contributions across different time zones, making global team collaboration visible and tangible.</description></item><item><title/><link>https://coolbeevip.github.io/posts/openssf/sigstore/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/openssf/sigstore/</guid><description>sigstore
cosign 在 macOS 安装 cosign, 其他安装方式参见more
brew install cosign 查看 cosign 版本
% cosign -version WARNING: the -version flag is deprecated and will be removed in a future release. Please use the version subcommand instead. ______ ______ _______. __ _______ .__ __. / | / __ \ / || | / _____|| \ | | | ,----&amp;#39;| | | | | (----`| | | | __ | \| | | | | | | | \ \ | | | | |_ | | .</description></item><item><title>Install Gitlab Runner</title><link>https://coolbeevip.github.io/posts/gitlab/install-gitlab-runner/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/gitlab/install-gitlab-runner/</guid><description>启动 Gitlab Runner
docker run -d --name gitlab-runner-01 --restart always \ -v /data01/runner/git-runner-01/volumns/runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /bin/docker:/bin/docker \ -v /data01/runner/git-runner-01/volumns/runner/apache-maven-3.6.3:/root/.m2 \ -v /data01/runner/git-runner-01/volumns/runner/apache-maven-3.6.3/bin/mvn:/bin/mvn \ gitlab/gitlab-runner:latest 注册 Gitlab Runner 到 Gitlab
docker exec -it gitlab-runner-01 gitlab-ci-multi-runner register \ --non-interactive \ --url &amp;#34;http://mygitlab:8081/&amp;#34; \ --registration-token &amp;#34;K6PPp2LWzdHpks5RKJWy&amp;#34; \ --executor &amp;#34;docker&amp;#34; \ --docker-image alpine:latest \ --description &amp;#34;runner-01&amp;#34; \ --tag-list &amp;#34;runner-01&amp;#34; \ --run-untagged=&amp;#34;true&amp;#34; \ --locked=&amp;#34;false&amp;#34; \ --access-level=&amp;#34;not_protected&amp;#34; \ --docker-volumes /var/run/docker.sock:/var/run/docker.sock \ --docker-volumes /data01/runner/git-runner-01/volumns/runner/apache-maven-3.6.3:/root/.m2 \ --docker-volumes /data01/runner/git-runner-01/volumns/runner/apache-maven-3.</description></item><item><title>Using gitlab-ci to cache python</title><link>https://coolbeevip.github.io/posts/gitlab/using-gitlab-ci-to-cache-python/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/gitlab/using-gitlab-ci-to-cache-python/</guid><description># 缓存位置环境变量 variables: PIP_CACHE_DIR: &amp;#34;$CI_PROJECT_DIR/.cache/pip&amp;#34; # virtualenv 和 pip 缓存目录 cache: paths: - .cache/pip - venv/ # 预运行脚本 before_script: - python -V - pip install virtualenv - virtualenv venv - source venv/bin/activate stages: - build merge_job: image: python:3.9-buster stage: build only: refs: - merge_requests script: - pip install .</description></item></channel></rss>