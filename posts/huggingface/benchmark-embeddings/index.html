<!doctype html><html lang=en data-theme><head><title>Lei Zhang | Benchmark for BAAI/bge-3m on an Nvidia A800/CPU/Mac M1 </title><meta charset=utf-8><meta name=generator content="Hugo 0.123.3"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=description content="This is my knowledge base. I document things here"><link rel=stylesheet href=/css/style.min.7cf3c5090ac13256a5fa5531e5649cfe5a2ba7de88dca14ce0b6e253409a3511.css integrity="sha256-fPPFCQrBMlal+lUx5WSc/lorp96I3KFM4LbiU0CaNRE=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.f798cbda9aaa38f89eb38be6414bd082cfd71a6780375cbf67b6d2fb2b96491e.css integrity="sha256-95jL2pqqOPies4vmQUvQgs/XGmeAN1y/Z7bS+yuWSR4=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/custom.min.d03676fac5605f1e95639c8b2239ea77daf8804fe13da2208bb83b252959846c.css integrity="sha256-0DZ2+sVgXx6VY5yLIjnqd9r4gE/hPaIgi7g7JSlZhGw=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin=anonymous><link rel="shortcut icon" href=/favicons/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicons/favicon-16x16.png><link rel=canonical href=/posts/huggingface/benchmark-embeddings/><script type=text/javascript src=/js/anatole-header.min.df804b63b5bd8474ea0756ea874bc8f1e92552708cc6ea43aa0d76981dc419f9.js integrity="sha256-34BLY7W9hHTqB1bqh0vI8eklUnCMxupDqg12mB3EGfk=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="Benchmark for BAAI/bge-3m on an Nvidia A800/CPU/Mac M1"><meta name=twitter:description content='在同一个服务器上测试 CPU / GPU 性能差异
测试代码 import time import sentence_transformers import torch if __name__ == "__main__": device = "cuda" if torch.cuda.is_available() else "cpu" embedding = sentence_transformers.SentenceTransformer( model_name_or_path="/Volumes/SD/huggingface-models/bge-m3", cache_folder="/Volumes/SD/huggingface-models", device=device ) total = 10000 batch_size = 100 start_time = time.time() sentences = ["I am AnCopilot, nice to meet you!"] for i in range(total // batch_size): embedding.encode(sentences * batch_size, normalize_embeddings=True) print(f"{i + 1} / {total // batch_size}") end_time = time.time() total_time = end_time - start_time average_time = total_time / total throughput = total / total_time print(f"Device {device}") print(f"Total {total} sentences") print(f"Batch size: {batch_size}") print(f"Total time: {total_time:.'></head><body><div class="sidebar ."><div class=logo-title><div class=title><img src=/images/profile.jpg alt="profile picture"><h3 title><a href=/>I'm Lei Zhang</a></h3><div class=description><p>This is my knowledge base. I document things here</p></div></div><p><a href=https://github.com/coolbeevip><img src="https://img.shields.io/github/followers/coolbeevip?label=follow&amp;style=social" alt="GitHub coolbeevip"></a>
<img src=https://badges.pufler.dev/commits/all/coolbeevip alt="Commits Badge">
<img src=https://badges.pufler.dev/repos/coolbeevip alt="Repos Badge">
<img src=https://badges.pufler.dev/years/coolbeevip alt="Years Badge"></p></div><ul class=social-links><li><a href=https://github.com/coolbeevip/ rel=me aria-label=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li><a href=mailto:zhanglei@apache.org rel=me aria-label=e-mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul><div class=footer><div class=by_farbox>&copy; Lei Zhang 2025</div></div></div><div class=main><div class="page-top ."><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a><ul class=nav id=navMenu><li><a href=/ title>Home</a></li><li><a href=/posts title>Blog</a></li><li><a href=/bookmarks title>Bookmarks</a></li><li><a href=/about/ title>About</a></li></ul></div><div class=autopagerize_page_element><div class=content><div class="post ."><div class=post-content><div class=post-title><h3>Benchmark for BAAI/bge-3m on an Nvidia A800/CPU/Mac M1</h3></div><p>在同一个服务器上测试 CPU / GPU 性能差异</p><h2 id=测试代码>测试代码</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>import time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>import sentence_transformers
</span></span><span style=display:flex><span>import torch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    device <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;cuda&#34;</span> <span style=color:#66d9ef>if</span> torch.cuda.is_available<span style=color:#f92672>()</span> <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#34;cpu&#34;</span>
</span></span><span style=display:flex><span>    embedding <span style=color:#f92672>=</span> sentence_transformers.SentenceTransformer<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>        model_name_or_path<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/Volumes/SD/huggingface-models/bge-m3&#34;</span>,
</span></span><span style=display:flex><span>        cache_folder<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/Volumes/SD/huggingface-models&#34;</span>,
</span></span><span style=display:flex><span>        device<span style=color:#f92672>=</span>device
</span></span><span style=display:flex><span>    <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    total <span style=color:#f92672>=</span> <span style=color:#ae81ff>10000</span>
</span></span><span style=display:flex><span>    batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>    start_time <span style=color:#f92672>=</span> time.time<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>    sentences <span style=color:#f92672>=</span> <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;I am AnCopilot, nice to meet you!&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i in range<span style=color:#f92672>(</span>total // batch_size<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>        embedding.encode<span style=color:#f92672>(</span>sentences * batch_size, normalize_embeddings<span style=color:#f92672>=</span>True<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        print<span style=color:#f92672>(</span>f<span style=color:#e6db74>&#34;{i + 1} / {total // batch_size}&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    end_time <span style=color:#f92672>=</span> time.time<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>    total_time <span style=color:#f92672>=</span> end_time - start_time
</span></span><span style=display:flex><span>    average_time <span style=color:#f92672>=</span> total_time / total
</span></span><span style=display:flex><span>    throughput <span style=color:#f92672>=</span> total / total_time
</span></span><span style=display:flex><span>    print<span style=color:#f92672>(</span>f<span style=color:#e6db74>&#34;Device {device}&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    print<span style=color:#f92672>(</span>f<span style=color:#e6db74>&#34;Total {total} sentences&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    print<span style=color:#f92672>(</span>f<span style=color:#e6db74>&#34;Batch size: {batch_size}&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    print<span style=color:#f92672>(</span>f<span style=color:#e6db74>&#34;Total time: {total_time:.4f} seconds&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    print<span style=color:#f92672>(</span>f<span style=color:#e6db74>&#34;Average time per iteration: {average_time:.4f} seconds&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    print<span style=color:#f92672>(</span>f<span style=color:#e6db74>&#34;Throughput: {throughput:.2f} iterations per second&#34;</span><span style=color:#f92672>)</span>
</span></span></code></pre></div><h2 id=设备信息>设备信息</h2><p>GPU 设备信息</p><pre tabindex=0><code>+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A800-SXM4-80GB          Off | 00000000:3D:00.0 Off |                    0 |
| N/A   35C    P0              63W / 400W |  47848MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
</code></pre><p>CPU 信息</p><table><thead><tr><th>属性</th><th>值</th></tr></thead><tbody><tr><td>Architecture</td><td>x86_64</td></tr><tr><td>CPU op-mode(s)</td><td>32-bit, 64-bit</td></tr><tr><td>Byte Order</td><td>Little Endian</td></tr><tr><td>CPU(s)</td><td>128</td></tr><tr><td>On-line CPU(s) list</td><td>0-127</td></tr><tr><td>Thread(s) per core</td><td>2</td></tr><tr><td>Core(s) per socket</td><td>32</td></tr><tr><td>Socket(s)</td><td>2</td></tr><tr><td>NUMA node(s)</td><td>2</td></tr><tr><td>Vendor ID</td><td>GenuineIntel</td></tr><tr><td>CPU family</td><td>6</td></tr><tr><td>Model</td><td>106</td></tr><tr><td>Model name</td><td>Intel(R) Xeon(R) Platinum 8358P CPU @ 2.60GHz</td></tr><tr><td>Stepping</td><td>6</td></tr><tr><td>CPU MHz</td><td>800.000</td></tr><tr><td>CPU max MHz</td><td>2601.0000</td></tr><tr><td>CPU min MHz</td><td>800.0000</td></tr><tr><td>BogoMIPS</td><td>5200.00</td></tr><tr><td>Virtualization</td><td>VT-x</td></tr><tr><td>L1d cache</td><td>48K</td></tr><tr><td>L1i cache</td><td>32K</td></tr><tr><td>L2 cache</td><td>1280K</td></tr><tr><td>L3 cache</td><td>49152K</td></tr><tr><td>NUMA node0 CPU(s)</td><td>0-31, 64-95</td></tr><tr><td>NUMA node1 CPU(s)</td><td>32-63, 96-127</td></tr><tr><td>Flags</td><td>fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 invpcid_single ssbd mba rsb_ctxsw ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb intel_pt avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq md_clear pconfig spec_ctrl intel_stibp flush_l1d arch_capabilities</td></tr></tbody></table><p>内存信息</p><table><thead><tr><th>类型</th><th>总计</th><th>已用</th><th>空闲</th><th>共享</th><th>缓冲/缓存</th><th>可用</th></tr></thead><tbody><tr><td><strong>Mem</strong></td><td>2.0T</td><td>302G</td><td>37G</td><td>8.1G</td><td>1.6T</td><td>1.7T</td></tr><tr><td><strong>Swap</strong></td><td>0B</td><td>0B</td><td>0B</td><td>-</td><td>-</td><td>-</td></tr></tbody></table><h2 id=对比结果>对比结果</h2><p>以下是基准测试结果的对比表格：</p><table><thead><tr><th>Device</th><th>Batch Size</th><th>Total Sentences</th><th>Total Time (seconds)</th><th>Average Time per Iteration (seconds)</th><th>Throughput (iterations per second)</th></tr></thead><tbody><tr><td>CUDA</td><td>100</td><td>10000</td><td>13.6438</td><td>0.0014</td><td>732.93</td></tr><tr><td><strong>CUDA</strong></td><td><strong>200</strong></td><td><strong>10000</strong></td><td><strong>12.1587</strong></td><td><strong>0.0012</strong></td><td><strong>822.46</strong></td></tr><tr><td>CPU</td><td>100</td><td>10000</td><td>77.3202</td><td>0.0077</td><td>129.33</td></tr><tr><td>CPU</td><td>200</td><td>10000</td><td>72.6335</td><td>0.0073</td><td>137.68</td></tr></tbody></table><h2 id=总结>总结</h2><p>根据基准测试结果，可以得出以下分析和总结：</p><ol><li><p><strong>设备性能</strong>：</p><ul><li><strong>CUDA（GPU）设备的表现明显优于CPU设备</strong>。无论是100还是200的批量大小，CUDA设备的总时间和每次迭代的时间均显著低于CPU设备，CPU的总时间大约是CUDA的5到6倍。</li></ul></li><li><p><strong>批量大小的影响</strong>：</p><ul><li><strong>增加批量大小对CUDA设备有利</strong>：在CUDA上，从100的批量大小提升到200，虽然总时间略有减少（从13.6438秒降至12.1587秒），每次迭代的时间也减少了（从0.0014秒降至0.0012秒），同时吞吐量提升了（从732.93迭代/秒增至822.46迭代/秒）。</li><li><strong>在CPU设备上，增加批量大小同样有利</strong>：在CPU上，从批量大小100提高到200，虽然总时间也有所减少（从77.3202秒降至72.6335秒），每次迭代的时间也有小幅下降（从0.0077秒下降至0.0073秒），吞吐量由129.33迭代/秒提升至137.68迭代/秒。</li></ul></li><li><p><strong>总体吞吐量</strong>：</p><ul><li>CUDA设备的吞吐量显著高于CPU设备，200批量的CUDA吞吐量达到822.46迭代/秒，而CPU则只有137.68迭代/秒，这表明在处理大量数据时，CUDA设备能够提供更高的效率。</li></ul></li><li><p><strong>总结</strong>：</p><ul><li>在执行密集型任务（如处理大量句子）时，使用CUDA（GPU）设备会显著提高性能，减少计算时间。尽管CPU设备可通过增加批量大小来提高效率，但其性能仍无法与GPU设备相较。对于大量数据的处理，特别是需要实时反馈或低延迟的场景，选择CUDA设备将是更优的选择。</li></ul></li></ol></div><div class=post-footer><div class=info><span class=separator><a class=category href=/categories/embedding/>embedding</a><a class=category href=/categories/bge-3m/>bge-3m</a><a class=category href=/categories/benchmark/>benchmark</a></span>
<span class=separator><a class=tag href=/tags/huggingface/>huggingface</a><a class=tag href=/tags/embedding/>embedding</a></span></div></div></div></div></div></div><script type=text/javascript src=/js/medium-zoom.min.e1c6918cbaa90022a5612f0bd71c7bf3be6d036614c5729cebfe14f7b91fa4bc.js integrity="sha256-4caRjLqpACKlYS8L1xx7875tA2YUxXKc6/4U97kfpLw=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css integrity=sha384-t5CR+zwDAROtph0PXGte6ia8heboACF9R5l/DiY+WZ3P2lxNgvJkQk5n7GPvLMYw crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js integrity=sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8+w2LAIftJEULZABrF9PPFv+tVkH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js integrity=sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB+w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v crossorigin=anonymous onload=renderMathInElement(document.body)></script></body></html>