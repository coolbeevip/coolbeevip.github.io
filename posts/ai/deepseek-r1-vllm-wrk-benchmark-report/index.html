<!doctype html><html lang=en data-theme><head><title>Lei Zhang | DeepSeek-R1 vLLM性能基准测试：wrk压力测试详细报告 </title><meta charset=utf-8><meta name=generator content="Hugo 0.123.3"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=description content="This is my knowledge base. I document things here"><link rel=stylesheet href=/css/style.min.7cf3c5090ac13256a5fa5531e5649cfe5a2ba7de88dca14ce0b6e253409a3511.css integrity="sha256-fPPFCQrBMlal+lUx5WSc/lorp96I3KFM4LbiU0CaNRE=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.f798cbda9aaa38f89eb38be6414bd082cfd71a6780375cbf67b6d2fb2b96491e.css integrity="sha256-95jL2pqqOPies4vmQUvQgs/XGmeAN1y/Z7bS+yuWSR4=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/custom.min.d03676fac5605f1e95639c8b2239ea77daf8804fe13da2208bb83b252959846c.css integrity="sha256-0DZ2+sVgXx6VY5yLIjnqd9r4gE/hPaIgi7g7JSlZhGw=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin=anonymous><link rel="shortcut icon" href=/favicons/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicons/favicon-16x16.png><link rel=canonical href=/posts/ai/deepseek-r1-vllm-wrk-benchmark-report/><script type=text/javascript src=/js/anatole-header.min.df804b63b5bd8474ea0756ea874bc8f1e92552708cc6ea43aa0d76981dc419f9.js integrity="sha256-34BLY7W9hHTqB1bqh0vI8eklUnCMxupDqg12mB3EGfk=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="DeepSeek-R1 vLLM性能基准测试：wrk压力测试详细报告"><meta name=twitter:description content="配置 DeepSeek-R1-Distill-Qwen-14B NVIDIA A40 vLLM vllm/vllm-openai:v0.8.5 NVIDIA-SMI 560.35.03 Driver Version: 560.35.03 CUDA Version: 12.6 测试方法 使用 wrk 命令持续测试 60 秒
[root@myserver wrk-4.2.0]# ./wrk --timeout 30s -t10 -c20 -d60s -s post.lua http://10.1.2.100:8080/v1/chat/completions Running 1m test @ http://10.1.2.100:8080/v1/chat/completions 10 threads and 20 connections Thread Stats Avg Stdev Max +/- Stdev Latency 3.07s 38.32ms 3.20s 66.93% Req/Sec 1.45 3.05 10.00 87.92% 381 requests in 1.00m, 285.10KB read Requests/sec: 6.34 Transfer/sec: 4.74KB [root@myserver wrk-4.2.0]# ."></head><body><div class="sidebar ."><div class=logo-title><div class=title><img src=/images/profile.jpg alt="profile picture"><h3 title><a href=/>I'm Lei Zhang</a></h3><div class=description><p>This is my knowledge base. I document things here</p></div></div><p><a href=https://github.com/coolbeevip><img src="https://img.shields.io/github/followers/coolbeevip?label=follow&amp;style=social" alt="GitHub coolbeevip"></a>
<img src=https://badges.pufler.dev/commits/all/coolbeevip alt="Commits Badge">
<img src=https://badges.pufler.dev/repos/coolbeevip alt="Repos Badge">
<img src=https://badges.pufler.dev/years/coolbeevip alt="Years Badge"></p></div><ul class=social-links><li><a href=https://github.com/coolbeevip/ rel=me aria-label=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li><a href=mailto:zhanglei@apache.org rel=me aria-label=e-mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul><div class=footer><div class=by_farbox>&copy; Lei Zhang 2025</div></div></div><div class=main><div class="page-top ."><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a><ul class=nav id=navMenu><li><a href=/ title>Home</a></li><li><a href=/posts title>Blog</a></li><li><a href=/bookmarks title>Bookmarks</a></li><li><a href=/about/ title>About</a></li></ul></div><div class=autopagerize_page_element><div class=content><div class="post ."><div class=post-content><div class=post-title><h3>DeepSeek-R1 vLLM性能基准测试：wrk压力测试详细报告</h3></div><h2 id=配置>配置</h2><ul><li>DeepSeek-R1-Distill-Qwen-14B</li><li>NVIDIA A40</li><li>vLLM vllm/vllm-openai:v0.8.5</li><li>NVIDIA-SMI 560.35.03</li><li>Driver Version: 560.35.03</li><li>CUDA Version: 12.6</li></ul><h2 id=测试方法>测试方法</h2><p>使用 wrk 命令持续测试 60 秒</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#f92672>[</span>root@myserver wrk-4.2.0<span style=color:#f92672>]</span><span style=color:#75715e># ./wrk --timeout 30s -t10 -c20 -d60s -s post.lua http://10.1.2.100:8080/v1/chat/completions</span>
</span></span><span style=display:flex><span>Running 1m test @ http://10.1.2.100:8080/v1/chat/completions
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>10</span> threads and <span style=color:#ae81ff>20</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency     3.07s    38.32ms   3.20s    66.93%
</span></span><span style=display:flex><span>    Req/Sec     1.45      3.05    10.00     87.92%
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>381</span> requests in 1.00m, 285.10KB read
</span></span><span style=display:flex><span>Requests/sec:      6.34
</span></span><span style=display:flex><span>Transfer/sec:      4.74KB
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@myserver wrk-4.2.0<span style=color:#f92672>]</span><span style=color:#75715e># ./wrk --timeout 30s -t10 -c100 -d60s -s post.lua http://10.1.2.100:8080/v1/chat/completions</span>
</span></span><span style=display:flex><span>Running 1m test @ http://10.1.2.100:8080/v1/chat/completions
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>10</span> threads and <span style=color:#ae81ff>100</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency     3.62s   108.42ms   4.34s    95.19%
</span></span><span style=display:flex><span>    Req/Sec    20.14     22.29    89.00     88.81%
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>1601</span> requests in 1.00m, 1.17MB read
</span></span><span style=display:flex><span>Requests/sec:     26.64
</span></span><span style=display:flex><span>Transfer/sec:     19.97KB
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@myserver wrk-4.2.0<span style=color:#f92672>]</span><span style=color:#75715e># ./wrk --timeout 30s -t100 -c100 -d60s -s post.lua http://10.1.2.100:8080/v1/chat/completions</span>
</span></span><span style=display:flex><span>Running 1m test @ http://10.1.2.100:8080/v1/chat/completions
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>100</span> threads and <span style=color:#ae81ff>100</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency     3.62s   103.22ms   4.24s    87.65%
</span></span><span style=display:flex><span>    Req/Sec     0.00      0.00     0.00    100.00%
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>1603</span> requests in 1.00m, 1.17MB read
</span></span><span style=display:flex><span>Requests/sec:     26.67
</span></span><span style=display:flex><span>Transfer/sec:     19.99KB
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@myserver wrk-4.2.0<span style=color:#f92672>]</span><span style=color:#75715e># ./wrk --timeout 30s -t100 -c200 -d60s -s post.lua http://10.1.2.100:8080/v1/chat/completions</span>
</span></span><span style=display:flex><span>Running 1m test @ http://10.1.2.100:8080/v1/chat/completions
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>100</span> threads and <span style=color:#ae81ff>200</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency     5.27s   265.22ms   6.80s    92.77%
</span></span><span style=display:flex><span>    Req/Sec     1.33      3.25    10.00     86.58%
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>2200</span> requests in 1.00m, 1.61MB read
</span></span><span style=display:flex><span>Requests/sec:     36.60
</span></span><span style=display:flex><span>Transfer/sec:     27.43KB
</span></span></code></pre></div><h2 id=报告解读>报告解读</h2><h4 id=测试配置对比>测试配置对比</h4><table><thead><tr><th>测试</th><th>线程数</th><th>连接数</th><th>平均延迟</th><th>RPS</th><th>传输速率</th></tr></thead><tbody><tr><td>1</td><td>10</td><td>20</td><td>3.07s</td><td>6.34</td><td>4.74KB/s</td></tr><tr><td>2</td><td>10</td><td>100</td><td>3.62s</td><td>26.64</td><td>19.97KB/s</td></tr><tr><td>3</td><td>100</td><td>100</td><td>3.62s</td><td>26.67</td><td>19.99KB/s</td></tr><tr><td>4</td><td>100</td><td>200</td><td>5.27s</td><td>36.60</td><td>27.43KB/s</td></tr></tbody></table><h4 id=关键发现>关键发现</h4><p><strong>性能瓶颈分析：</strong></p><ul><li>服务器在低并发（20连接）时表现最差，RPS仅6.34</li><li>并发数从20增加到100时，性能显著提升（RPS从6.34提升到26.64）</li><li>线程数从10增加到100对性能影响很小（测试2和3几乎相同）</li><li>连接数增加到200时，延迟明显上升（从3.62s增加到5.27s）</li></ul><p><strong>延迟特征：</strong></p><ul><li>所有测试的平均延迟都超过3秒，表明这是一个高延迟的服务（可能是AI推理服务）</li><li>延迟标准差相对较小，说明响应时间比较稳定</li><li>最高延迟在6.8秒以内，99%的请求延迟分布较为集中</li></ul><p><strong>吞吐量分析：</strong></p><ul><li>最佳吞吐量出现在200连接配置下（36.60 RPS）</li><li>100连接配置达到了较好的延迟/吞吐量平衡点</li><li>传输数据量较小，每个响应平均约750字节</li></ul><h4 id=建议>建议</h4><ol><li><strong>最优配置</strong>：推荐使用100连接的配置，能够在保持合理延迟的同时获得良好的吞吐量</li><li><strong>容量规划</strong>：当前服务器在理想条件下最大支持约40 RPS</li><li><strong>监控重点</strong>：重点关注3-6秒的响应时间是否符合业务需求</li><li><strong>扩展方案</strong>：如需更高吞吐量，考虑水平扩展或优化后端处理逻辑</li></ol><p>这个性能表现符合典型的AI推理服务特征，高延迟但相对稳定的响应时间。</p></div><div class=post-footer><div class=info><span class=separator><a class=category href=/categories/vllm/>vllm</a><a class=category href=/categories/benchmark/>benchmark</a><a class=category href=/categories/wrk/>wrk</a></span>
<span class=separator><a class=tag href=/tags/vllm/>vllm</a></span></div></div></div></div></div></div><script type=text/javascript src=/js/medium-zoom.min.e1c6918cbaa90022a5612f0bd71c7bf3be6d036614c5729cebfe14f7b91fa4bc.js integrity="sha256-4caRjLqpACKlYS8L1xx7875tA2YUxXKc6/4U97kfpLw=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css integrity=sha384-t5CR+zwDAROtph0PXGte6ia8heboACF9R5l/DiY+WZ3P2lxNgvJkQk5n7GPvLMYw crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js integrity=sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8+w2LAIftJEULZABrF9PPFv+tVkH crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js integrity=sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB+w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v crossorigin=anonymous onload=renderMathInElement(document.body)></script></body></html>