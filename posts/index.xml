<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on</title><link>https://coolbeevip.github.io/posts/</link><description>Recent content in Posts on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 11 Mar 2022 13:24:14 +0800</lastBuildDate><atom:link href="https://coolbeevip.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Docker IPv6 Support</title><link>https://coolbeevip.github.io/posts/ipv6/ipv6-docker/</link><pubDate>Fri, 11 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ipv6/ipv6-docker/</guid><description>本文介绍在 IPv6 网络主机上部署 Docker
主机 IPv6 网络检查 使用 ifconfig 命令查看是否已经配置了 IPv6 网络
$ ifconfig eth1 eth1: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500 inet 10.252.248.152 netmask 255.255.255.128 broadcast 10.252.248.255 inet6 2409:8010:5ac0:400:200::2d prefixlen 128 scopeid 0x0&amp;lt;global&amp;gt; inet6 fe80::f816:3eff:fe84:bc36 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether fa:16:3e:84:bc:36 txqueuelen 1000 (Ethernet) RX packets 7150695 bytes 4751783652 (4.4 GiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5018420 bytes 4436770306 (4.</description></item><item><title>Linux Command - Memory</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-memory/</link><pubDate>Fri, 11 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-memory/</guid><description>Linux 内存相关命令
查看系统内存 # free -h total used free shared buff/cache available Mem: 251G 40G 1.4G 4.0G 209G 206G Swap: 4.0G 3.7G 312M 内存占用 TOP N # ps aux | sort -k4,4nr | head -n 5 200 139348 227 6.9 38668500 18410776 ? Ssl 3月10 1905:49 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-2.el8_3.x86_64/jre/bin/java...org.sonatype.nexus.karaf.NexusMain mysql 33407 1.2 2.2 349722012 6012524 ? Sl 2021 4596:18 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql mysql 118257 0.4 0.5 10170064 1536084 ? Ssl 2月28 66:04 /usr/share/elasticsearch/jdk/bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC root 42564 9.</description></item><item><title>Very High CPU usage Sonatype Nexus Docker</title><link>https://coolbeevip.github.io/posts/nexus/very-high-cpu-usage-sonatype-nexus-docker/</link><pubDate>Fri, 11 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/nexus/very-high-cpu-usage-sonatype-nexus-docker/</guid><description>本文记录 Sonatype Nexus 私服遇到性能劣化问题的分析过程（未解决）
环境说明 使用 sonatype/nexus3 镜像启动，通过挂载卷存储数据
Nexus 配置，可以看到关键配置 -Xms8g -Xmx8g -XX:MaxDirectMemorySize=35158M -XX:+UseConcMarkSweepGC
200 105083 105062 99 11:01 ? 2-00:51:44 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-2.el8_3.x86_64/jre/bin/java -server -Dinstall4j.jvmDir=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-2.el8_3.x86_64/jre -Dexe4j.moduleName=/opt/sonatype/nexus/bin/nexus -XX:+UnlockDiagnosticVMOptions -Dinstall4j.launcherId=245 -Dinstall4j.swt=false -Di4jv=0 -Di4jv=0 -Di4jv=0 -Di4jv=0 -Di4jv=0 -Xms8g -Xmx8g -XX:MaxDirectMemorySize=35158M -XX:ActiveProcessorCount=16 -XX:+UseParNewGC -XX:ParallelGCThreads=12 -XX:MaxTenuringThreshold=6 -XX:SurvivorRatio=5 -XX:+UseConcMarkSweepGC -XX:-CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=65 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCMSCompactAtFullCollection -XX:+CMSClassUnloadingEnabled -XX:+DisableExplicitGC -XX:+PrintGCDetails -Xloggc:/nexus-data/vgc/nexus-1646967690.vgc -XX:+UnlockDiagnosticVMOptions -XX:+LogVMOutput -XX:LogFile=../sonatype-work/nexus3/log/jvm.log -XX:-OmitStackTraceInFastThrow -Djava.net.preferIPv4Stack=true -Dkaraf.home=. -Dkaraf.base=. -Dkaraf.etc=etc/karaf -Djava.util.logging.config.file=etc/karaf/java.util.logging.properties -Dkaraf.data=../sonatype-work/nexus3 -Dkaraf.log=../sonatype-work/nexus3/log -Djava.io.tmpdir=../sonatype-work/nexus3/tmp -Dkaraf.startLocalConsole=false -Djdk.tls.ephemeralDHKeySize=2048 -Djava.endorsed.dirs=lib/endorsed -Di4j.vpt=true -classpath /opt/sonatype/nexus/.install4j/i4jruntime.jar:/opt/sonatype/nexus/lib/boot/nexus-main.jar:/opt/sonatype/nexus/lib/boot/activation-1.1.1.jar:/opt/sonatype/nexus/lib/boot/jakarta.xml.bind-api-2.3.3.jar:/opt/sonatype/nexus/lib/boot/jaxb-runtime-2.3.3.jar:/opt/sonatype/nexus/lib/boot/txw2-2.3.3.jar:/opt/sonatype/nexus/lib/boot/istack-commons-runtime-3.0.10.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.main-4.3.6.jar:/opt/sonatype/nexus/lib/boot/osgi.core-7.0.0.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.specs.activator-4.3.6.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.diagnostic.boot-4.3.6.jar:/opt/sonatype/nexus/lib/boot/org.apache.karaf.jaas.boot-4.3.6.jar com.install4j.runtime.launcher.UnixLauncher run 9d17dc87 0 0 org.</description></item><item><title>Migrate Spring Data Elasticsearch from 3.x version to 4.x</title><link>https://coolbeevip.github.io/posts/elasticsearch/migrate-spring-data-elasticsearch-from-3.x-version-to-4.x/</link><pubDate>Sun, 06 Mar 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/elasticsearch/migrate-spring-data-elasticsearch-from-3.x-version-to-4.x/</guid><description>Spring Data Elasticsearch 从 3.X 迁移到 4.X
因为需要将产品的 spring boot 2.1.6.RELEASE 升级到 2.3.12.RELEASE，升级过程中发现有一些需要迁移的部分，特此整理记录。 本文不是迁移指南，仅仅是工作中遇到的迁移问题笔记
依赖组件 组件 迁移前 迁移后 spring-data-elasticsearch 3.1.9 4.0.9 elasticsearch 6.4.3 7.6.2 GetQuery 已废弃 以下代码中 GetQuery 已经被废弃，并且 getQuery.setId 方法已经被删除
GetQuery getQuery = new GetQuery(); getQuery.setId(globalTxId); GlobalTransactionDocument globalTransaction = this.template .queryForObject(getQuery, GlobalTransactionDocument.class); 使用以下代码替换
Query query = new NativeSearchQueryBuilder().withIds(Collections.singletonList(globalTxId)).build(); SearchHit&amp;lt;GlobalTransactionDocument&amp;gt; result = this.template.searchOne(query, GlobalTransactionDocument.class); GlobalTransactionDocument globalTransaction = result.</description></item><item><title>Using OWASP Dependency Vulnerabilities Check with Maven</title><link>https://coolbeevip.github.io/posts/maven/maven-using-owasp-dependency-vulnerabilities-check/</link><pubDate>Thu, 24 Feb 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-using-owasp-dependency-vulnerabilities-check/</guid><description>使用 OWASP 依赖检查 Maven 插件 dependency-check-maven 发现依赖漏洞
增加编译插件 在 pom.xml 中增加如下配置，如果是多模块项目请增加在最外层 pom.xml 中，并且配置 &amp;lt;goal&amp;gt; 为 aggregate
&amp;lt;properties&amp;gt; &amp;lt;dependency-check-maven.version&amp;gt;6.5.3&amp;lt;/dependency-check-maven.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.owasp&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;dependency-check-maven&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${dependency-check-maven.version}&amp;lt;/version&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;name&amp;gt;notifier-dependency-check&amp;lt;/name&amp;gt; &amp;lt;format&amp;gt;HTML&amp;lt;/format&amp;gt; &amp;lt;failBuildOnCVSS&amp;gt;9&amp;lt;/failBuildOnCVSS&amp;gt; &amp;lt;failOnError&amp;gt;false&amp;lt;/failOnError&amp;gt; &amp;lt;skipProvidedScope&amp;gt;true&amp;lt;/skipProvidedScope&amp;gt; &amp;lt;skipRuntimeScope&amp;gt;true&amp;lt;/skipRuntimeScope&amp;gt; &amp;lt;skipTestScope&amp;gt;true&amp;lt;/skipTestScope&amp;gt; &amp;lt;retireJsAnalyzerEnabled&amp;gt;false&amp;lt;/retireJsAnalyzerEnabled&amp;gt; &amp;lt;skipArtifactType&amp;gt;pom&amp;lt;/skipArtifactType&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;executions&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;aggregate&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;/executions&amp;gt; &amp;lt;/plugin&amp;gt; &amp;lt;/plugins&amp;gt; &amp;lt;/build&amp;gt; failBuildOnCVSS 当发现此级别的漏洞后编译失败，评分和严重等级如下</description></item><item><title>Run Docker without Docker Desktop on macOS</title><link>https://coolbeevip.github.io/posts/kubernetes/run-docker-without-docker-desktop-on-macos/</link><pubDate>Mon, 14 Feb 2022 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kubernetes/run-docker-without-docker-desktop-on-macos/</guid><description>由于 Docker Desktop 修改了授权条款，不再对企业用户免费，所以我们需要啊寻求一种替代品。到目前为止 Minikube 已经成为 Docker Desktop 最简单的替代品。 Minikube 用于在本地环境中运行 Kubernetes 集群，但它也运行了一个可用于运行容器的 Docker 守护进程。如果你不需要使用 Kubernetes ，那么你可以通过 minikube pause 暂停 Kubernetes 相关镜像，从而解决系统资源。
在 macOS 上，Minikube 运行在很多虚拟化技术上，由于ISSUE-6296原因，本例使用 Virtualbox 方式（你需要先安装 Virtualbox）。
卸载 Docker Desktop for macOS 如果你之前安装过 Docker Desktop，那么你需要先卸载它
在 Docker Desktop 菜单中选择 Troubleshoot 并且选择 Uninstall. 删除 /Applications/Docker.app 安装 Docker CLI 因为卸载 Docker Desktop 后将自动卸载 Docker CLI，所以你需要单独安装
$ brew install docker $ brew install docker-compose 提示： 在执行 brew install docker-compose 命令的时候可能得到如下的失败信息，这是因为依赖包下载失败。你可以使用 brew install gdbm 单独下载依赖包，就避免了找不到依赖版本的错误。</description></item><item><title>Kubectl Commands</title><link>https://coolbeevip.github.io/posts/kubernetes/kubectl-commands/</link><pubDate>Sun, 19 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kubernetes/kubectl-commands/</guid><description>常用 Kubectl 命令
创建命名空间 新建一个名为 nc-namespace.yaml 的 YAML 文件
apiVersion: v1 kind: Namespace metadata: name: nc-namespace 然后运行以下命令创建命名空间
$ kubectl create -f nc-namespace.yaml namespace/nc-namespace created 创建命名空间资源配额文件 新建一个名为 nc-quota.yaml 的 YAML 文件
apiVersion: v1 kind: ResourceQuota metadata: name: nc-quota namespace: nc-namespace spec: hard: pods: &amp;#34;10&amp;#34; requests.cpu: &amp;#34;2&amp;#34; requests.memory: 2Gi limits.cpu: &amp;#34;4&amp;#34; limits.memory: 4Gi 然后运行以下命令创建资源配额
$ kubectl create -f nc-quota.yaml resourcequota/nc-quota created 创建 PV 卷和 PVC 新建一个名为 nc-pv.</description></item><item><title>Automate Install Kafka Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-kafka-cluster/</link><pubDate>Thu, 09 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-kafka-cluster/</guid><description>集群概述 此脚本中的配置基于 Kafka 2.6.3 版本 使用 Kafka 发布包中自带的 Zookeeper 组件（通常这没有问题，除非你要将 Zookeeper 安装在单独的服务器上） 在 Kafka 安装目录下独立安装 JDK，目前只支持 Java 8 和 Java 11。 安装计划 服务器规划
IP SSH 端口 SSH 用户 SSH 密码 ROOT 密码 OS 10.1.207.177 22022 kafka 123456 root123 CentOS Linux release 7.9.2009 10.1.207.178 22022 kafka 123456 root123 CentOS Linux release 7.9.2009 10.1.207.183 22022 kafka 123456 root123 CentOS Linux release 7.</description></item><item><title>Automate Install AntDB Distributed Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-antdb-distributed-cluster/</link><pubDate>Sun, 05 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-antdb-distributed-cluster/</guid><description>集群概述 包含组件
MGR 集群的管理 GTM 全局事务管理 Coordinator 协调员管理用户会话 Data Node 数据节点 安装计划 服务器规划
IP SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 antdb 123456 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 antdb 123456 root123 CentOS Linux release 7.9.2009 10.1.207.182 22022 antdb 123456 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划
IP MGR GTM Coordinator DataNode 10.</description></item><item><title>Automate Install Redis Master-Slave Sentinel with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-redis-master-slave-sentinel/</link><pubDate>Sun, 05 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-redis-master-slave-sentinel/</guid><description>集群概述 请先在目标服务器创建 redis 用户，此脚本在此用户下使用源代码编译的方式安装一主两从三哨兵的集群
安装计划 服务器规划
IP SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 redis redis123 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 redis redis123 root123 CentOS Linux release 7.9.2009 10.1.207.182 22022 redis redis123 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划
IP Redis Sentinel 10.</description></item><item><title>Slow LOG In Redis</title><link>https://coolbeevip.github.io/posts/redis/redis-slowlog/</link><pubDate>Sun, 05 Dec 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-slowlog/</guid><description>SLOWLOG 记录了 Redis 运行时间超时特定阀值的命令。这类慢查询命令被保存在 Redis 服务器的一个定长队列中，最多保存 slowlog-max-len(默认128）个慢查询命令。当慢查询命令达到128个时，新产生的慢查询被加入前，会从队列中删除最旧的慢查询命令。
配置 redis slowlog通过2个参数配置管理，默认命令耗时超过10毫秒，就会被记录到慢查询日志队列中；队列默认保存最近产生的128个慢查询命令。
slowlog-log-slower-than: 慢查询阀值，单位微秒，默认100000 (10毫秒)； 执行耗时超过这个值的查询会被记录；建议你生产环境设置为 10000（1毫秒），因为如果命令都是 1 毫秒以上，那么 Redis 吞吐率只有 1000 QPS；
slowlog-max-len: 慢查询存储的最大个数，默认128；生产设置设置大于1024，因为 slowlog 会省略过多的参数，慢查询不会占用过多的内存；
读取 返回最新的 2 条慢查询
SLOWLOG GET 2 1) 1) (integer) 9495 2) (integer) 1638760173 3) (integer) 13923 4) 1) &amp;#34;COMMAND&amp;#34; 5) &amp;#34;10.30.107.152:41830&amp;#34; 6) &amp;#34;&amp;#34; 2) 1) (integer) 9494 2) (integer) 1638759729 3) (integer) 17170 4) 1) &amp;#34;SADD&amp;#34; 2) &amp;#34;nc_oauth:uname_to_access:nc:vpengcheng&amp;#34; 3) &amp;#34;\xac\xed\x00\x05sr\x00Corg.</description></item><item><title>Automate Install MySQL InnoDB Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-mysql-innodb-cluster/</link><pubDate>Sun, 21 Nov 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-mysql-innodb-cluster/</guid><description>集群概述 MySQL InnoDB Cluster 是 MySQL 团队为了高可用性 (HA) 目的而引入的。它为 MySQL 提供了完整的高可用解决方案。我将通过 Ansible Playbook 展示三个节点的 InnoDB 集群配置。
MySQL InnoDB 集群有以下服务组成
MySQL shell Group Replication ( GR ) MySQL Router 安装计划 服务器规划
IP地址 SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 mysql 123456 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 mysql 123456 root123 CentOS Linux release 7.9.2009 10.</description></item><item><title>Automate Install Elasticsearch Cluster with Ansible Playbook</title><link>https://coolbeevip.github.io/posts/ansible/ansible-elasticsearch-cluster/</link><pubDate>Sun, 07 Nov 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/ansible/ansible-elasticsearch-cluster/</guid><description>集群概述 脚本会在此用户下安装三节点集群，因为 7.X 版本后会自带 JDK，所以我们不需要提前安装 Java 环境。
安装计划 服务器规划
IP地址 SSH 端口 SSH 用户名 SSH 密码 ROOT 密码 OS 10.1.207.180 22022 elasticsearch 123456 root123 CentOS Linux release 7.9.2009 10.1.207.181 22022 elasticsearch 123456 root123 CentOS Linux release 7.9.2009 10.1.207.182 22022 elasticsearch 123456 root123 CentOS Linux release 7.9.2009 提示： 可以参考批量自动化创建用户
集群节点规划
IP地址 Elasticsearch 10.</description></item><item><title>Linux Command - Grep</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-search/</link><pubDate>Sun, 07 Nov 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-search/</guid><description>使用正则表达式搜索文件内容 macOS
cat nc-auth_3000.log | grep -s &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39; centOS
cat nc-auth_3000.log | grep -P &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39; 使用正则表达式搜索压缩文件内容 macOS
gzip -dc nc-auth_3000.20211106.38.log.gz | grep -s &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39; centOS
gzip -dc nc-auth_3000.20211106.38.log.gz | grep -P &amp;#39;timeCost&amp;#34;:\d\d\d\d&amp;#39;</description></item><item><title>The Impact of Undertow Thread Options &amp; Database Connection Pool on Performance</title><link>https://coolbeevip.github.io/posts/java/java-undertow-threads-and-jdbc-pools/</link><pubDate>Thu, 23 Sep 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java/java-undertow-threads-and-jdbc-pools/</guid><description>Hikari 线程参数和数据库连接池参数对业务吞吐率的影响分析
场景 本例中我们使用 Undertow 作为 Web 容器，使用 Hikari 作为数据库连接池， 并通过 spring.datasource.hikari.maximum-pool-size 和 server.undertow.threads.worker 两个参数的调整，看看对于业务的性能影响有多大
为此我准备了一个简单的 DEMO，并且执行 1000 次请求，并发 100，每次请求执行一个 SLEEP(5) 的 SQL模拟单笔耗时。并在一个 2C 的服务器上测试。应用默认参数如下
spring.datasource.hikari.connection-timeout=30000 spring.datasource.hikari.minimum-idle=10 spring.datasource.hikari.maximum-pool-size=10 server.undertow.threads.worker(默认是 2C*8) 默认参数 $ ab -c 100 -n 1000 http://localhost:6060/test This is ApacheBench, Version 2.3 &amp;lt;$Revision: 1879490 $&amp;gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests Completed 200 requests Completed 300 requests Completed 400 requests Completed 500 requests Completed 600 requests Completed 700 requests Completed 800 requests Completed 900 requests Completed 1000 requests Finished 1000 requests Server Software: Server Hostname: localhost Server Port: 6060 Document Path: /test Document Length: 14 bytes Concurrency Level: 100 Time taken for tests: 510.</description></item><item><title>Find The Biggest Objects In Redis</title><link>https://coolbeevip.github.io/posts/redis/redis-find-biggest-objects-in-redis/</link><pubDate>Wed, 25 Aug 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-find-biggest-objects-in-redis/</guid><description>在 REDIS 中一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际上中如果下面两种情况，我就会认为它是 bigkeys。
字符串类型：单个 value 超过5MB 哈希、列表、集合、有序集合元素可数超过 10000 因为 REDIS 是单进程处理，所以对 BIGKEY 的访问会产生阻塞，如果你获取 100 次单体大小为 5MB 的 KEY，那么这些数据（500MB）传输到客户端就需要一定的时间，这期间其他命令都要排队等待。
查找 BIGKEY 使用 bigkeys 命令可以统计大对象（建议在从结点执行），为了方式阻塞，我们设置一个休眠参数 -i 0.1
redis-cli -h &amp;lt;ip&amp;gt; -p &amp;lt;port&amp;gt; -a &amp;lt;password&amp;gt; --bigkeys -i 0.1 结果如下：
$ redis-cli -h 192.168.51.207 -p 9015 --bigkeys Warning: Using a password with &amp;#39;-a&amp;#39; or &amp;#39;-u&amp;#39; option on the command line interface may not be safe. # Scanning the entire keyspace to find biggest keys as well as # average sizes per key type.</description></item><item><title>Multiple SSH Keys Settings For Different Git Platform[Github、Gitlab]</title><link>https://coolbeevip.github.io/posts/git/git-multiple-ssh-keys/</link><pubDate>Sun, 22 Aug 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-multiple-ssh-keys/</guid><description>我们在使用 Github、Gitlab 或者 JetBrains Space 时通常使用 SSH 密钥可以连接 Git 服务，而无需在每次访问时都提供用户名和个人访问令牌。 另外现在大量平台启用账户登录多次验证，也促进我们避免使用账号密码登录。
为了便于管理我们通常会为每个 Git 平台配置不同的 SSH KEY，然后通过 ~/.ssh/config 配置每个平台对应的 SSH KEY。
创建多个 SSH KEY 使用如下命令创建 id_github，注意提示输入文件名时请修改成 id_github
ssh-keygen -t ed25519 -C &amp;#34;coolbeevip@github.com&amp;#34; 使用同样的方法我们分别创建 id_gitlab 和 id_github，这时在的本地的 ~/.ssh 目录下会得到如下文件
id_github、id_github.pub id_gitlab、id_gitlab.pub 将 *.pub 文件内容分别导入到 Git 服务中，详细方式请参考 Github and SSH keys 、 GitLab and SSH keys 或 JetBrains Space and SSH keys
配置 SSH 编辑 ~/.ssh/config 文件为每个 Git 地址配置不同的 KEY
Host github.</description></item><item><title>Approximate Counting Morris Algorithm in Java</title><link>https://coolbeevip.github.io/posts/algorithm/algorithm-morris-approximate-counter/</link><pubDate>Sun, 22 Aug 2021 00:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/algorithm/algorithm-morris-approximate-counter/</guid><description>这是一个 Morris 计数器（近似计数算法）的 Java 实现，用很小的数据结构准确估计具有几十亿数据量的数据计数。 我们通常会定义一个 Long 类型对象，通过累加的方式实现计数。每个 Long 类型占用 8 byte (64bit) 空间，如果你有 30 亿个要记录的对象，那么你就需要 22GB 的空间存储这些计数器，这还不不包括在哈希中的对象ID。
背景 近似计数算法是允许我们使用非常少量的内存对大量事件进行计数的技术。它由 Robert Morris 于 1977 年发明。 该算法使用概率技术来增加计数器，尽管它不能保证准确性，但它确实提供了对真实值的相当好的估计，同时引入了最小但相当恒定的相对误差。 在这篇文章中，我们详细介绍了 Morris 算法及其背后的数学原理。
Morris 在贝尔实验室工作时遇到了一个问题。他应该编写一段代码来计算大量事件，而他只有一个 8 位计数器。 由于事件的数量很容易超过 256，使用普通方法计算它们是不可行的，这种限制导致他构建了这个近似计数器，它不是提供精确计数，而是提供一个近似计数。
计数和投硬币 构建近似计数器的一个简单方案是对每次事件变换进行计数。每收到一个新事件，我们抛一次硬币，如果正面朝上，我们增加计数，否则不增加。 这样计数器中的值平均下来将代表总事件的一半（因为抛硬币的获得正面并的概率是 0.5）。当我们将计数乘以 2 时，我们将得到近似实际数量的计数。
CoinFlipsCounter.java
这种基于抛硬币的计数技术是参数为 (n, p) 的二项分布，其中 n 是所见事件的总数，p 是成功概率，即在抛硬币过程中出现正面的概率。对真实事件数 n 的计数值 v 由下式给出
$$ \large 估算值v = 实际值n * 概率p = 实际值n/2 $$
这种二项式的正态分布标准偏差将帮助我们找到估算中的误差，对于正态分布平均值两侧标准差的两倍覆盖了分布的 95%；我们使用它来查找计数器值中的相对和绝对误差。
$$ \large 误差 = \sqrt{实际值n * 概率p(1-概率p)} = \sqrt{估算值v/2} $$</description></item><item><title>GraphQL Tools Schema Parser</title><link>https://coolbeevip.github.io/posts/graphql-tools-schema-paarser-slow/</link><pubDate>Sat, 29 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/graphql-tools-schema-paarser-slow/</guid><description>SYSTEM
MacBook Pro 16G
JVM
-Xmx4g -Xms4g -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -Xnoclassgc -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:ParallelGCThreads=12 -XX:MaxTenuringThreshold=15 -XX:+ExplicitGCInvokesConcurrent -XX:+CMSParallelRemarkEnabled -XX:SurvivorRatio=8 -XX:CMSInitiatingOccupancyFraction=65 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseCMSCompactAtFullCollection -XX:+CMSClassUnloadingEnabled -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 CPU Flame Graph
GrpaphQL Schema Parser
Slow Method</description></item><item><title>APISIX Study Notes (1) Build &amp; QuickStart</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-1-quickstart/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-1-quickstart/</guid><description>安装 在 macOS 基于源代码自己编译发布版本
安装 Etcd 启动 apisix-etcd.yml
version: &amp;#39;3.2&amp;#39; services: etcd-1: image: docker.io/bitnami/etcd:3.4.16 hostname: etcd container_name: apisix-etcd ports: - &amp;#39;2380:2380&amp;#39; - &amp;#39;2379:2379&amp;#39; environment: - ALLOW_NONE_AUTHENTICATION=yes - ETCD_NAME=etcd-1 - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380 - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 - ETCD_ADVERTISE_CLIENT_URLS=http://0.0.0.0:2379 volumes: - ./volume/apisix/etcd/data:/bitnami/etcd/data - ./volume/apisix/etcd/conf:/opt/bitnami/etcd/conf docker-compose -f docker-compose-apisix-etcd.yml up -d 验证 $ curl -L http://127.0.0.1:2379/health {&amp;#34;health&amp;#34;:&amp;#34;true&amp;#34;} 安装编译环境 安装 Node 10.</description></item><item><title>APISIX Study Notes (2) Plugins Traffic Split</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-2-plugins-traffic-split/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-2-plugins-traffic-split/</guid><description>场景描述 我有两个 UPSTREAM 服务:
UPSTREAM 1 $ curl -i -X GET http://192.168.51.234:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:09:29 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} UPSTREAM 2 $ curl -i -X GET http://10.19.88.60:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:08:12 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} 我希望通过 APISIX 将请求流量路由到两个不同的 UPSTREAM 服务上，参考插件 traffic-split 的样例，可以实现此功能
配置路由 &amp;amp; traffic-split 本例中并没有单独定义 UPSTREAM，而是在 traffic-split 中直接定义了 UPSTREAM 的地址</description></item><item><title>APISIX Study Notes (3) Install with Docker</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-3-install-with-docker/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-3-install-with-docker/</guid><description>使用 Docker 启动
定义卷目录 APISIX 目前好像还不支持通过环境变量配置参数，所以需要在宿主机上创建配置文件，并在启动 Docker 时通过 Volume 映射进容器
规划外部卷目录
mkdir apisix_home mkdir -p apisix_home/apisix_volume/apisix/apisix_conf mkdir -p apisix_home/apisix_volume/apisix/dashboard_conf 定义 APISIX Dashboard 配置文件 apisix_home/apisix_volume/apisix/dashboard_conf/conf.yaml
conf: listen: # 绑定 IP 地址 host: 0.0.0.0 # 监听端口 port: 9000 etcd: # etcd 用户名 # username: &amp;#34;root&amp;#34; # etcd 密码 # password: &amp;#34;123456&amp;#34; # etcd 地址，支持集群多节点定义 endpoints: - apisix-etcd:2379 log: error_log: # 日志级别 debug, info, warn, error, panic, fatal level: warn # 日志输出路径 file_path: logs/error.</description></item><item><title>APISIX Study Notes (4) Plugins Proxy Rewrite</title><link>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-4-plugins-proxy-rewrite/</link><pubDate>Fri, 21 May 2021 01:00:00 +0800</pubDate><guid>https://coolbeevip.github.io/posts/apisix/study-notes-for-apisix-4-plugins-proxy-rewrite/</guid><description>在 APISIX STUDY NOTES (2) PLUGINS TRAFFIC SPLIT 提到，我们可以通过这个插件实现上游服务的导流，但是这个插件只能通过自定义 URL参数 或者 REQUEST HEADER 的方式传递导流变量。如果我们想通过 URL PATH 的方式实现上游业务的到导流，可以使用 Proxy Rewrite 插件
场景描述 我有两个 UPSTREAM 服务:
UPSTREAM 1 $ curl -i -X GET http://192.168.51.234:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.spring-boot.actuator.v3+json Date: Sat, 22 May 2021 09:09:29 GMT {&amp;#34;status&amp;#34;:&amp;#34;UP&amp;#34;,&amp;#34;components&amp;#34;:{...}} UPSTREAM 2 $ curl -i -X GET http://10.19.88.60:5005/nc-tools/actuator/health HTTP/1.1 200 OK Connection: keep-alive Transfer-Encoding: chunked Content-Type: application/vnd.</description></item><item><title>Bash script automates the Maven project Git release process</title><link>https://coolbeevip.github.io/posts/git/git-automate-tag-release-process-with-bash/</link><pubDate>Sun, 16 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-automate-tag-release-process-with-bash/</guid><description>开源项目中我们大多采用主干开发模式管理我们的项目，他基本遵循以下规则
所有的 PR 都默认向主干合并 主干上项目的版本号是 -SNAPSHOT 当主干要发布时，我们会建立与之对应的 X 分支（此分支的目的是为了基于此分支发布补丁版本） 基于当前主干去除版本号中的 -SNAPSHOT 后建立与版本对应的 TAG 将主干上的版本号中的 minor 累加一，并在后边增加 -SNAPSHOT 后缀 此过程繁琐，切容易出错。我制作了一个脚本 maven-project-git-release.sh 用来实现这个过程的规范化和自动化
当然，这并不意味着你不需要掌握正手动发布的过程。
由于某种原因导致自动过程中断后，你依然需要手动去处理，所以在使用这个脚本前，请确保你了解这个脚本帮你做了什么工作，以及如何做的。
如何使用 maven-project-git-release.sh 脚本会帮你自动化以下工作
创建一个编译用的目录
目录会创建在你系统的临时目录下，在我的 Mac 系统系统中看起来像 /var/folders/fd/gqdh88px2fj66tmtcy6ffr580000gn/T
在编译用的目录中 git clone 你的仓库代码
你的仓库地址在使用脚本时通过参数指定，像这样 sh maven-project-git-release.sh git@github.com:coolbeevip/license-maven-plugin.git
编译你的代码确保正确
默认在当前仓库根目录下执行 mvn clean package，如果你需要特殊的方式，可以修改脚本中的 check_source_before_release 函数
计算版本号分支名
根据 pom 中的版本定义，自动计算下一版本号，默认采 maven 的3段式版号方式 major.minor.patch，并以此为基准滚动 minor 版本号，如果你需要特殊的方式，可以修改脚本中的 next_version 函数
输出发布计划</description></item><item><title>JProfiler with Docker Sonatype Nexus3</title><link>https://coolbeevip.github.io/posts/docker/jprofiler-with-docker/</link><pubDate>Fri, 14 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/jprofiler-with-docker/</guid><description>使用 JProfiler 监控 Docker Sonatype Nexus3
下载 JProfiler 从 https://www.ej-technologies.com/下载 JProfiler 和 Agent（注意版本必须一致）
JProfiler GUI
https://download-gcdn.ej-technologies.com/jprofiler/jprofiler_macos_12_0_2.dmg
JProfiler Agent
https://download-gcdn.ej-technologies.com/jprofiler/jprofiler_linux_12_0_2.sh
在服务器上安装 JProfiler Agent 将下载后的 jprofiler_linux_12_0_2.sh 传到服务器上，通过 sh jprofiler_linux_12_0_2.sh 命令按提示安装即可
默认安装路径为 /opt/jprofiler12/，这个路径在启动 Docker 的时候要映射到容器内部
启动 Docker Sonatype Nexus3 在官方 sonatype/nexus3 容器启动参数的基础上做如下修改
使用 -v /opt/jprofiler12:/opt/jprofiler12 将 jprofiler 路径映射到容器内部
增加 -agentpath:/opt/jprofiler12/bin/linux-x64/libjprofilerti.so=port=9899 JVM 参数，设置监听端口为 9899
增加 -p 9899:9899 容器端口映射
docker run -d \ -e NEXUS_CONTEXT=nexus \ -e INSTALL4J_ADD_VM_PARAMS=&amp;#34;-Xms10g -Xmx10g \ -agentpath:/opt/jprofiler12/bin/linux-x64/libjprofilerti.</description></item><item><title>Securing Docker ports with firewalld</title><link>https://coolbeevip.github.io/posts/docker/securing-docker-ports-with-firewalld/</link><pubDate>Tue, 11 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/securing-docker-ports-with-firewalld/</guid><description>概述 为了保护 Docker 暴露的端口不受外部访问的影响，可以使用 firewalld 配置防火墙规则，只允许特定的 IP 访问。 通过让 firewalld 创建 DOCKER-USER 链，我们可以实现由 firewalld 维护的安全 Docker 端口, Docker 处理 iptables 规则以提供网络隔离，更多详细
本文基于环境
Docker-CE 19.03.12 CentOS Linux release 7.8.2003 Firewall 0.6.3 本文例子:
我们使用 Docker 安装一个 Nginx，并将 80(HTTP) 端口对外映射为 8080，443(HTTPS) 端口对外映射为 8443，并通过 Firewalld 仅允许特定的 IP 访问；提示：后续的防火墙规则中配置的端口是容器内部端口，例如 80，443
192.168.51.246 安装 Nginx Docker
配置 192.168.51.245 可以访问 Nginx Docker
其他机器无法访问 Nginx Docker
重要的事情说三遍
如果你在 Docker 运行时重启 firewalld，那么 firewalld 将删除 DOCKER-USER</description></item><item><title>Use Maven plugin to export license info in source files and its optional dependencies</title><link>https://coolbeevip.github.io/posts/maven/maven-export-dependencies-analyse-license/</link><pubDate>Sun, 09 May 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-export-dependencies-analyse-license/</guid><description>有的时候我们那需要分析多模块 Maven 项目的依赖使用情况，并希望能够分析出这些依赖的 LICENSE 信息。使用 io.github.coolbeevip:license-maven-plugin 插件 可以生成 TXT 或者 CSV 格式的分析报告
youtube
bilibili
CSV 格式的报告 NOTICE.CSV NOTICE-LICENSE.CSV TXT 格式的报告 NOTICE.TXT NOTICE-LICENSE.TXT 插件 LICENSE-MAVEN-PLUGIN format 导出格式，支持 csv、txt； license 是否分析 LICENSE 信息，默认 false； ignoreGroupIds 忽略 groupId 列表, 多个用逗号分割; timeout 分析 LICENSE 的超时时间，默认 5 秒; 导出报告 在 Maven 项目的根目录执行如下命令
导出 CSV
mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=csv 导出 TXT
mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=txt 提示： 导出的报告位置在 ./target/distribute 目录下
导出报告(忽略部分依赖) mvn io.github.coolbeevip:license-maven-plugin:1.5.0:dependency-license-export -Dformat=csv -DignoreGroupIds=org.</description></item><item><title>Synchronize between image repositories with Bash</title><link>https://coolbeevip.github.io/posts/docker/docker-pulling-pushing/</link><pubDate>Mon, 19 Apr 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/docker-pulling-pushing/</guid><description>从源镜像仓库批量拉取镜像，并将这些镜像推送到目标镜像仓库的批量脚本
#!/bin/bash ################################################# # 使用方式 # 从源仓库拉取镜像到本机 # sh docker-images-pulling-pushing.sh pull # # 将本机镜像推送到目的仓库 # sh docker-images-pulling-pushing.sh push # # 清理本机的镜像 # sh docker-images-pulling-pushing.sh clean ################################################# # 源仓库地址 DOCKER_REPO_FROM= # 目标仓库地址 DOCKER_REPO_TO=192.168.2.2:8888/ DOCKER_REPO_TO_USER=test DOCKER_REPO_TO_PASS=Test123456 # 镜像定义 DOCKER_IMAGES=() DOCKER_IMAGES+=(postgres:9.6) DOCKER_IMAGES+=(elasticsearch:6.6.2) DOCKER_IMAGES+=(coolbeevip/servicecomb-pack) # 从源仓库地址拉取镜像到本机仓库 function pull(){ echo &amp;#34;Pull images from $DOCKER_REPO_FROM&amp;#34; for image in ${DOCKER_IMAGES[@]}; do docker pull $DOCKER_REPO_FROM$image done } # 本机镜像推送到目的仓库 function push(){ docker login http://$DOCKER_REPO_TO -u $DOCKER_REPO_TO_USER -p $DOCKER_REPO_TO_PASS echo &amp;#34;Push $DOCKER_REPO_FROMto $DOCKER_REPO_TO&amp;#34; for image in ${DOCKER_IMAGES[@]}; do docker image tag $DOCKER_REPO_FROM$image $DOCKER_REPO_TO$image docker push $DOCKER_REPO_TO$image done } # 清理本机拉取后的镜像 function clean(){ echo &amp;#34;Remove images&amp;#34; docker rmi -f $(docker images | grep $DOCKER_REPO_FROM | awk &amp;#39;{print $3}&amp;#39;) docker rmi -f $(docker images | grep $DOCKER_REPO_TO | awk &amp;#39;{print $3}&amp;#39;) } case &amp;#34;${@: -1}&amp;#34; in pull ) pull ;; clean ) clean ;; push ) push ;; esac</description></item><item><title>MacOS Switch JDK</title><link>https://coolbeevip.github.io/posts/java/macos-switch-jdk/</link><pubDate>Thu, 25 Mar 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java/macos-switch-jdk/</guid><description>查看本机 JDK 版本 命令行输入 /usr/libexec/java_home -V 可以看到多个 JDK 版本
$ /usr/libexec/java_home -V Matching Java Virtual Machines (2): 11.0.10, x86_64: &amp;#34;OpenJDK 11.0.10&amp;#34; /Users/zhanglei/Library/Java/JavaVirtualMachines/adopt-openj9-11.0.10/Contents/Home 1.8.0_201, x86_64: &amp;#34;Java SE 8&amp;#34; /Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home /Users/zhanglei/Library/Java/JavaVirtualMachines/adopt-openj9-11.0.10/Contents/Home 查看当前使用的 JDK 版本 $ java -version java version &amp;#34;1.8.0_201&amp;#34; Java(TM) SE Runtime Environment (build 1.8.0_201-b09) Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) 切换 JDK 切换到 JDK 11.0.10 版本，并查看切换后的 JDK 版本
$ export JAVA_HOME=`/usr/libexec/java_home -v 11.0.10` $ java -version openjdk version &amp;#34;11.</description></item><item><title>Oracle Proxy Using HAProxy Docker</title><link>https://coolbeevip.github.io/posts/haproxy/haproxy_oracle_proxy_using_haproxy_docker/</link><pubDate>Tue, 01 Sep 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/haproxy/haproxy_oracle_proxy_using_haproxy_docker/</guid><description>下载 HAProxy Docker
docker pull haproxy:2.3 创建工作目录
mkdir -p /opt/haproxy-oracle/docker_volume 在 /opt/haproxy-oracle/docker_volume 目录下创建如下 haproxy.cfg 文件，请将文件尾部的 oracle 地址和端口改为你的地址和端口
global daemon log 127.0.0.1 local0 log 127.0.0.1 local1 notice maxconn 4096 tune.ssl.default-dh-param 2048 defaults log global retries 3 maxconn 2000 timeout connect 5s timeout client 50s timeout server 50s listen stats bind *:9090 balance mode http stats enable stats auth admin:admin stats uri /stats listen oracle-proxy log global bind :1521 mode tcp balance roundrobin server oracle-1 10.</description></item><item><title>Setting up Redis for Production</title><link>https://coolbeevip.github.io/posts/redis/redis-setting-up-redis-for-production/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-setting-up-redis-for-production/</guid><description>安装 官方建议的安装方法是从源代码编译安装，您可以从 redis.io 下载最新稳定版的 TAR 包
wget https://download.redis.io/releases/redis-6.2.5.tar.gz tar xvzf redis-6.2.5.tar.gz cd redis-6.2.5 make 此时，您可以通过键入 make test 来测试您的构建是否正常工作。编译后 redis-6.2.5/src 目录填充了一部分可执行文件。 最好将编译后的 Redis 执行文件都复制到适当的位置，或者使用以下命令手动复制（假设我们的安装路径是 /usr/local/redis）：
# 可执行文件 sudo mkdir -p /usr/local/redis/bin sudo cp src/redis-server /usr/local/redis/bin sudo cp src/redis-cli /usr/local/redis/bin sudo cp src/redis-sentinel /usr/local/redis/bin sudo cp src/redis-benchmark /usr/local/redis/bin sudo cp src/redis-check-aof /usr/local/redis/bin sudo cp src/redis-check-rdb /usr/local/redis/bin # 配置文件 sudo mkdir -p /usr/local/redis/conf sudo cp redis.conf /usr/local/redis/conf sudo cp sentinel.conf /usr/local/redis/conf # 数据目录 sudo mkdir -p /usr/local/redis/data sudo mkdir -p /usr/local/redis/log # 创建链接 sudo ln -s /usr/local/redis/bin/redis-server /usr/bin/redis-server sudo ln -s /usr/local/redis/bin/redis-cli /usr/bin/redis-cli 提示： 复制完毕后，您可以删除 redis-6.</description></item><item><title>Using Redis as a Cache</title><link>https://coolbeevip.github.io/posts/redis/redis-using-redis-as-a-cache/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-using-redis-as-a-cache/</guid><description>当 Redis 用作缓存时，通常可以方便地让它在您添加新数据时自动驱逐旧数据。Redis 支持 6 种驱逐策略，你可以使用 maxmemory-policy 修改驱逐策略。默认是不驱逐，也就是说如果使用的内存超过了 maxmemory 限制，将提示 OOM。
你可以在 redis.conf 通过 maxmemory 2gb 设置，也可以通过 config set maxmemory 2gb 方式动态设置，注意： 在64bit系统下，maxmemory设置为0表示不限制内存使用，在32bit系统下，maxmemory不能超过3GB
驱逐策略 noenviction: 禁止驱逐数据(默认淘汰策略) 当 redis 内存数据达到 maxmemory，在该策略下，直接返回OOM错误； volatile-lru: 驱逐已设置过期时间的内存数据集中最近最少使用的数据； volatile-ttl: 驱逐已设置过期时间的内存数据集中即将过期的数据； volatile-random: 驱逐已设置过期时间的内存数据集中任意挑选数据； allkeys-lru: 驱逐内存数据集中最近最少使用的数据； allkeys-random: 驱逐数据集中任意挑选数据； volatile-lfu 驱逐已设置过期时间的内存数据集中使用频率最少的数据；（since 4.0） allkeys-lfu 驱逐内存数据集中使用频率最少的数据；（since 4.0） 如果 KEY 未设置过期时间，那么 volatile-random、volatile-ttl 和 volatile-lru 等同于 noenviction。
驱逐程序如何运作 重要的是要了解驱逐过程的工作方式如下：
客户端运行新命令，导致添加更多数据。 Redis 检查内存使用情况，如果大于 maxmemory limit ，则根据策略驱逐键。 执行新命令，等等。 所以我们不断地越过内存限制的边界，越过它，然后通过驱逐键返回到限制之下。 如果某个命令导致使用大量内存一段时间，则内存限制可能会明显超出。</description></item><item><title>Kafka Commands</title><link>https://coolbeevip.github.io/posts/kafka-commands/</link><pubDate>Tue, 28 Jul 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/kafka-commands/</guid><description>常用 Kafka 命令
Topics 查询 topic 列表
./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --list 查看 topic 描述
./bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe --topic my-topic Consumer Groups 查询消费组列表
./bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list 查询指定的组各 topic 消息消费情况
./bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group my-group</description></item><item><title>MySQL Commands</title><link>https://coolbeevip.github.io/posts/mysql/mysql-commands/</link><pubDate>Mon, 11 May 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/mysql/mysql-commands/</guid><description>常用 MySQL 命令
连接数配置 查看允许的最大连接数 show variables like &amp;#39;%max_connection%&amp;#39;; 如果过去曾达到此限制，则可以使用以下方法检查 SHOW GLOBAL STATUS LIKE &amp;#39;max_use%&amp;#39;; 配置用户的最大并发连接数 GRANT USAGE ON *.* TO &amp;#39;repl&amp;#39;@&amp;#39;%&amp;#39; WITH MAX_CONNECTIONS_PER_HOUR 100 MAX_USER_CONNECTIONS 10; 查看用户的最大并发连接数 SELECT User, Host, max_connections, max_user_connections FROM mysql.user; 设置最大连接数 set global max_connections=1000; 查看当前连接数 show status like &amp;#39;Threads%&amp;#39;; Threads_cached 当前线程池中缓存有多少空闲线程 Threads_connected 当前的连接数 ( 也就是线程数 ) Threads_running 已经创建的线程总数 Threads_created 当前激活的线程数 ( Threads_connected 中的线程有些可能处于休眠状态 ) thread_cache_size 值过小会导致频繁创建线程，直接反映就是 show status 查看 Threads_created 值过大。 当 Threads_cached 越来越少 但 Threads_connected 始终不降 且 Threads_created 持续升高 这时可适当增加 thread_cache_size 的大小</description></item><item><title>Maven Projects Best Practices</title><link>https://coolbeevip.github.io/posts/maven/maven-best-practices-for-structuring-projects-and-modules/</link><pubDate>Sat, 02 May 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-best-practices-for-structuring-projects-and-modules/</guid><description>本文整理构建Maven项目和模块的最佳实践的关键事项，其中包含依赖、版本、属性、模块划分等关键因素，推荐使用 Maven 3.6.3 及以上版本。 为了便于理解，我们假设有一个 API 网关项目，这个网关项目包含服务端、客户端、通知服务端支持插件。
目标 通过多模块方式组织项目 管理项目版本、依赖，属性 规划模块依赖关系 主项目 POM 每个项目都应该在项目根目录下有一个主 POM 文件，并通过主 POM 文件管理下级子模块。在主 POM 中至少会使用一下标签
properties: 定义字符集编码、JDK 版本、插件版本; modules: 下级子模块; pluginRepositories: 插件仓库地址（非必须，主要解决国内访问慢的问题）; repositories: 定义 Maven 私服地址; distributionManagement: 定义发布用 Maven 私服地址 pluginManagement: 定义管理类插件版本 例如：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;build xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;com.coolbeevip.apigateway&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;apigateway-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;!-- project --&amp;gt; &amp;lt;project.</description></item><item><title>Git Squash Commits</title><link>https://coolbeevip.github.io/posts/git/git-command-commit-squash/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-commit-squash/</guid><description>压缩合并 Commits，将多个 commit 整理合并的方法，这样可以使提交记录更加清晰
查看提交记录，选择你要合并的范围 git log commit 6d757f70af289b5a90d00bd5e4b93d892d64a258 (HEAD -&amp;gt; SCB-1669) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Thu Dec 19 13:53:26 2019 +0800 SCB-1669 Fixed reverse compensation sort bug in FSM commit 37e0c5d99d0e6dae188cbd78f543ba69433b928f (origin/SCB-1669) Author: Lei Zhang &amp;lt;zhanglei@apache.org&amp;gt; Date: Thu Dec 19 02:00:20 2019 +0800 SCB-1669 Fixed Reverse compensation sort bug in FSM commit b4ea8717a86d1eba1956d21727d05c466ff6d8a2 (upstream/master, origin/master, origin/HEAD, master) Author: Lei Zhang &amp;lt;zhanglei@apache.</description></item><item><title>Git Stash</title><link>https://coolbeevip.github.io/posts/git/git-command-commit-stash/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-commit-stash/</guid><description>你在当前分支上开发代码，此时不想 commit，但是又想切换到其他分支完成其他的工作，此时可以用 stash
在当前分支执行 stash 将当前分支未提交的代码隐藏起来 $ git stash Saved working directory and index state WIP on SCB-1577: 2554be3d SCB-1593 Add notice for Boringssl support ciphers (base) bogon:servicecomb-pack zhanglei$ 此时你可以看到已经存储到一个id为 2554be3d 里了，这时你可以用 git status 查看已经没有要提交的内容了
git status On branch SCB-1577 nothing to commit, working tree clean (base) bogon:servicecomb-pack zhanglei$ 这时你就可以切换到其他分支开始新的工作 (base) bogon:servicecomb-pack zhanglei$ git checkout master Switched to branch &amp;#39;master&amp;#39; Your branch is up to date with &amp;#39;origin/master&amp;#39;.</description></item><item><title>Synchronizing Your Forked Git Project</title><link>https://coolbeevip.github.io/posts/git/git-command-rebase-upstream/</link><pubDate>Mon, 06 Apr 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-rebase-upstream/</guid><description>当你 fork 一个仓库后，可以时用此方法使你 fork 后的仓库 master 分支保持和上游 master 分支的同步
使用 rebase 命令同步上游 master 分支到你本地的 master 分支，并推送到你 fork 后的仓库
git fetch upstream git checkout master git rebase upstream/master git push -f origin master 或者你确定放弃你本地所有的修改，则可以简单的重置为上游版本
git fetch upstream git checkout master git reset --hard upstream/master git push -f origin master 如果你也想同步 master 分支的修改到你的功能分支
git checkout &amp;lt;分支名&amp;gt; git rebase master git push -f origin &amp;lt;分支名&amp;gt;</description></item><item><title>Linux Command - Network</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-network/</link><pubDate>Wed, 02 Oct 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-network/</guid><description>Linux 网络相关命令
可以使用 yum install iperf3 安装这个工具，或者从网站 https://iperf.fr/iperf-download.php 下载
测试 TCP 吞吐量 假设我们要测试 10.1.207.180 和 10.1.207.181 两个服务器之间的带宽
先在其中一台服务器 10.1.207.181 服上启动 iperf3 服务
[root@oss-irms-181 ~]# iperf3 -s -p 5001 ----------------------------------------------------------- Server listening on 5001 ----------------------------------------------------------- 再在另一台机器 10.1.207.180 启动客户端连接服务端 10.1.207.181 测试
[root@oss-irms-180 ~]# iperf3 -c 10.1.207.181 -P 4 -t 30 -i 2 -p 5001 Connecting to host 10.1.207.181, port 5001 [ 4] local 10.1.207.180 port 49244 connected to 10.1.207.181 port 5001 [ 6] local 10.</description></item><item><title>Git Reset HEAD</title><link>https://coolbeevip.github.io/posts/git/git-reset-head/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-reset-head/</guid><description>Git 分支非常有用，您可以根据需要创建一个新分支，合并一个分支或删除一个分支。 您可以使用许多 git 命令来管理 git 中的分支。
当您使用 git checkout 分支时，HEAD会指出最后的提交。 简单来说，您可以说 Git HEAD 是当前分支。 每当您签出一个分支或创建一个新分支时，Git HEAD 都会转移它。
HEAD 是对当前检出分支中最后一次提交的引用。
在存储库中，HEAD 始终指向当前分支的起点。 换句话说，HEAD 是指向下一个提交的父对象或下一个提交将发生的地方的指针。
更具体地说，HEAD 是一个移动指针，它可以引用或可以不引用当前分支，但是它始终引用当前提交。
什么是 HEAD^ 插入符（^）是 Commit 的父级。
什么是 HEAD~ 代字号（〜）是一行几个字符（^）的简写字符。
HEAD〜2 与 HEAD ^^ 的作用相同。
如果写数字，则使用的默认值为1，因此 HEAD〜 等价于 HEAD ^。
如何检查HEAD的状态 您可以使用以下命令查看当前 Git HEAD 指向的位置：
$ cat .git/HEAD ref: refs/heads/master 并且，你可以使用以下命令查看指向 HEAD 的 commit 的 Hash ID：
$ git rev-parse --short HEAD 6f975a5 Detached HEAD HEAD 是您目前的工作分支。 当您尝试 git checkout 分支时，HEAD 指向该分支的顶部，这样您就可以继续工作而没有任何困难。</description></item><item><title>Git Revert</title><link>https://coolbeevip.github.io/posts/git/git-command-revert/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-command-revert/</guid><description>撤销上一次提交
$ git revert HEAD 撤销上两次提交
ISSUE-4 解决网关服务日志中无法正确显示经过代理访问的请求端 IP 问题 $ git revert [倒数第一个提交] [倒数第二个提交]</description></item><item><title>Important JVM Options</title><link>https://coolbeevip.github.io/posts/java/java-jvm-options/</link><pubDate>Tue, 06 Aug 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/java/java-jvm-options/</guid><description>Heap Memory -XX:MetaspaceSize Metaspace 空间初始大小，如果不设置的话，默认是20.79M。这个初始大小是触发首次 Metaspace Full GC 的阈值，例如 -XX:MetaspaceSize=128M
-XX:MaxMetaspaceSize Metaspace 最大值，默认不限制大小，但是线上环境建议设置，例如 -XX:MaxMetaspaceSize=512M
GC -Xnoclassgc 表示关闭JVM对类的垃圾回收，缺省情况下，当一个类没有任何活动实例时，JVM 就会从内存中卸装该类，但是这样会使性能下降。如果关闭类垃圾回收，就可以消除由于多次装入和卸装同一个类而造成的开销
-XX:+UseParNewGC 设置年轻代为并行收集
-XX:MaxTenuringThreshold 控制新生代需要经历多少次GC​晋升到老年代中的最大阈值，默认值 15
-XX:+CMSParallelRemarkEnabled CMS收集算法步骤如下：初始标记 -&amp;gt; 并发标记 -&amp;gt; 重新标记 -&amp;gt; 标记清除。 其中 初始标记和重新标记都需要STW，即暂停用户线程。 CMSParallelRemarkEnabled参数可以让重新标记阶段进行并行重新标记，减少暂停时间
-XX:SurvivorRatio 设置 Eden、S0、S1 分配比例，默认值是 8
-XX:SurvivorRatio=5 表示 Eden 占 50%，S0、S1 平分剩余空间
-XX:+UseCompressedOops In short, don&amp;rsquo;t turn it on, use a version which has it on by default.
https://stackoverflow.com/questions/11054548/what-does-the-usecompressedoops-jvm-flag-do-and-when-should-i-use-it
-XX:+DisableExplicitGC 禁止 System.gc() 触发 GC 操作，当没有开启 DisableExplicitGC 这个参数时,你会发现JVM每个小时会执行一次Full GC,这是因为JVM在做分布式GC,为RMI服务的, 可以通过 sun.</description></item><item><title>Linux Command - Disk</title><link>https://coolbeevip.github.io/posts/linux/linux-commands-disk/</link><pubDate>Mon, 06 May 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/linux/linux-commands-disk/</guid><description>Linux 磁盘相关命令
磁盘IO dd [root@localhost ~]# dd if=/dev/zero of=./a.dat bs=8K count=1M conv=fdatasync 记录了8192+0 的读入 记录了8192+0 的写出 8589934592字节(8.6 GB)已复制，14.8606 秒，578 MB/秒 [root@localhost ~]# dd if=./a.dat of=/dev/null bs=1M count=8k iflag=direct 记录了8192+0 的读入 记录了8192+0 的写出 8589934592字节(8.6 GB)已复制，14.2462 秒，603 MB/秒 磁盘空间 df 查看磁盘各个分区的空间大小、占用、可用等信息
$ df -h Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk1s5 466Gi 10Gi 128Gi 8% 488463 4881964417 0% / devfs 192Ki 192Ki 0Bi 100% 663 0 100% /dev /dev/disk1s1 466Gi 318Gi 128Gi 72% 4557528 4877895352 0% /System/Volumes/Data /dev/disk1s4 466Gi 8.</description></item><item><title>Git Commands</title><link>https://coolbeevip.github.io/posts/git/git-commands/</link><pubDate>Sat, 06 Apr 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/git/git-commands/</guid><description>常用 Git 命令
Init 在已有目录中初始化 GIT 仓库
$ git init $ git remote add origin &amp;lt;仓库地址&amp;gt; $ git add . $ git commit -m &amp;#34;Initial commit&amp;#34; $ git push -u origin master Branch 创建分支
git checkout -b &amp;lt;分支名&amp;gt; 推送分支
git push origin &amp;lt;分支名&amp;gt; 修改分支名
git branch -m &amp;lt;旧分支名&amp;gt; &amp;lt;新分支名&amp;gt; 删除本地分支
git branch -D &amp;lt;分支名&amp;gt; 删除远程分支
git push origin --delete &amp;lt;分支名&amp;gt; 拉取远程分支
git fetch origin &amp;lt;分支名&amp;gt; 拉取远程分支并切换
git checkout -b &amp;lt;分支名&amp;gt; origin/&amp;lt;分支名&amp;gt; 当前分支会退到指定版本</description></item><item><title>Docker Commands</title><link>https://coolbeevip.github.io/posts/docker/docker-commands/</link><pubDate>Wed, 06 Feb 2019 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/docker/docker-commands/</guid><description>常用 Docker 命令记录
镜像 删除所有镜像 docker rmi -f $(docker images | awk &amp;#39;{print $3}&amp;#39;) 删除所有 dangling 镜像 docker rmi -f $(docker images -a | grep &amp;#34;&amp;lt;none&amp;gt;&amp;#34; | awk &amp;#39;{print $3}&amp;#39;) 导出镜像 docker save -o postgres_9.6.tar postgres:9.6 导入镜像 docker load -i postgres_9.6.tar 容器 删除所有 Exited 容器 docker rm $(docker ps -a | grep Exited | awk &amp;#39;{print $1}&amp;#39;) 停止并删除所有容器 docker stop $(docker ps | awk &amp;#39;{print $1}&amp;#39;) docker rm -f $(docker ps -a | awk &amp;#39;{print $1}&amp;#39;) 停止 dead 容器 删除实例时提示 device or resource busy</description></item><item><title>Flyway hung on the MySQL Router + MGR</title><link>https://coolbeevip.github.io/posts/flyway/flyway-hung-on-mysql-router-mgr/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/flyway/flyway-hung-on-mysql-router-mgr/</guid><description>Flyway 连接 MySQL Router 后启动卡在 GET_LOCK 语句
现象 MySQL MGR + Router 部署高可用集群 Flyway 客户端使用 jdbc:mysql:loadbalance 连接 初始化 Schema History 表、或者执行多个 SQL 脚本时 当满足以上条件时，Flyway 会卡在初始化阶段，经过分析发现停顿在执行 GET_LOCK 语句时
原因 Flyway 默认在执行 DDL 脚本时不启用事务，在初始化时 Flyway 会先执行 GET_LOCK 锁定数据库，然后再执行 DDL 脚本。当使用 jdbc:mysql:loadbalance 连接时，会随机选择一个数据源，如果执行 GET_LOCK 和 执行 DDL 不是一个数据源，就会导致执行等待锁释放
解决办法 在启动时设置 group=true 参数，这样 Flyway 在初始化时就会启用事务，确保一个事务内的 DDL 都在一个数据源执行
ISSUE-3154
public class FlywayTestManual { String url=&amp;#34;jdbc:mysql:loadbalance://192.168.51.206:3810,192.168.51.207:3810/nc_notifier?roundRobinLoadBalance=false&amp;amp;characterEncoding=utf8&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;useSSL=false&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=GMT%2B8&amp;amp;allowMultiQueries=true&amp;amp;allowPublicKeyRetrieval=true&amp;#34;; String user=&amp;#34;user&amp;#34;; String password=&amp;#34;pass&amp;#34;; @Test public void test(){ Flyway flyway = Flyway.</description></item><item><title>Flyway Support Oracle</title><link>https://coolbeevip.github.io/posts/flyway/java-flyway-support-oracle/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/flyway/java-flyway-support-oracle/</guid><description>记录在使用 Flyway 管理 Oracle 数据库脚本时遇到的一些问题，Flyway 5.2.1 - 7.7.3 都存在此问题。
1. Flyway not support Oracle 11g 异常信息
Caused by: org.flywaydb.core.internal.license.FlywayEditionUpgradeRequiredException: Flyway Enterprise Edition or Oracle upgrade required: Oracle 11.2 is no longer supported by Flyway Community Edition, but still supported by Flyway Enterprise Edition. at org.flywaydb.core.internal.database.base.Database.ensureDatabaseNotOlderThanOtherwiseRecommendUpgradeToFlywayEdition(Database.java:173) at org.flywaydb.core.internal.database.oracle.OracleDatabase.ensureSupported(OracleDatabase.java:91) at org.flywaydb.core.Flyway.execute(Flyway.java:514) at org.flywaydb.core.Flyway.migrate(Flyway.java:159) at org.springframework.boot.autoconfigure.flyway.FlywayMigrationInitializer.afterPropertiesSet(FlywayMigrationInitializer.java:65) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1855) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1792) ... 19 common frames omitted 修改 Flyway 5.</description></item><item><title>To roll up Flyway incremental changes into 1 file</title><link>https://coolbeevip.github.io/posts/flyway/java-flyway-merge-script-step/</link><pubDate>Thu, 29 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/flyway/java-flyway-merge-script-step/</guid><description>Flyway 通过 SQL Patch 脚本的方式管理数据库脚本版本，开发一段时间后会积攒大量脚本。当一个版本稳定后我们希望合并成一个全量脚本
1.首先对齐程序与数据库中的脚本版本号 查看程序中脚本版本清单，例如：程序中有三个版本的脚本
V1.0.0.0__init.sql V1.0.0.1__add_user_table.sql V1.0.0.2__modify_user_table.sql 查看数据库中历史版本记录表 (默认是 flyway_schema_history) 中执行过的脚本版本，例如：
versions description script success 1.0.0.0 init.sql V1.0.0.0__init.sql 1 1.0.0.1 add_user_table.sql V1.0.0.1__add_user_table.sql 1 1.0.0.2 modify_user_table V1.0.0.2__modify_user_table.sql 1 这里只摘取了关键字段，你可以看到每个版本都已经执行，并且执行都是成功的 success=1
至此：你已经对齐了程序和数据库中脚本版本号，可以开始准备合并了
2.合并程序中的SQL脚本 合并多个脚本的内容到最大版本号的文件中，例如：将 V1.0.0.0__init.sql, V1.0.0.1__add_user_table.sql, V1.0.0.2__modify_user_table.sql 合并为 V1.0.0.2__init.sql
注意： 不是简单的文件合并，而是最终执行结果的合并
3.重新打包程序 只包含合 V1.0.0.2__init.sql 脚本的程序
4.停止所有老版本的程序 包含 V1.0.0.0__init.sql,V1.0.0.1__add_user_table.sql,V1.0.0.2__modify_user_table.sql 老脚本的程序
5.删除数据库中的版本历史表 默认是 flyway_schema_history
6.重启应用程序 在程序启动时设置基线版本参数为当前版本，设置这个参数的目的是告诉 Flyway 当前已经执行过 1.</description></item><item><title>Maven Commands</title><link>https://coolbeevip.github.io/posts/maven/maven-commands/</link><pubDate>Fri, 23 Nov 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/maven/maven-commands/</guid><description>常用 Maven 命令
Parameters -D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试； -P 指定 Profile 配置，可以用于区分环境； -e 显示maven运行出错的信息； -o 离线执行命令,即不去远程仓库更新包； -f 强制指定使用 POM 文件，或者包含 POM 文件的目录 -pl 选项后可跟随{groupId}:{artifactId}或者所选模块的相对路径(多个模块以逗号分隔) -am 表示同时处理选定模块所依赖的模块 -amd 表示同时处理依赖选定模块的模块 -rf 表示从指定模块开始继续处理 -N 表示不递归子模块 -X 显示maven允许的debug信息； -U 强制去远程更新 snapshot的插件或依赖，默认每天只更新一次。 &amp;ndash;no-snapshot-updates 禁止更新 snapshot Dependency 显示maven依赖数
mvn dependency:tree 显示maven依赖列表
mvn dependency:list 下载依赖包的源码
mvn dependency:sources Maven Wrapper 自动安装 maven 的包装器（适合不想手动安装Maven的用户），使用插件Maven Wrapper plugin将其自动化安装指定版本的 Maven
mvn -N io.takari:maven:wrapper -Dmaven=3.6.3 这个命令会在你的项目中生成如下文件，请将这些文件与源代码一起管理
mvnw: 这是 Linux Script 可执行文件，用来代替 mvn mvnw.</description></item><item><title>Estimate host capacity based on QPS</title><link>https://coolbeevip.github.io/posts/stress-testing-host-estimate-with-qps/</link><pubDate>Wed, 07 Mar 2018 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/stress-testing-host-estimate-with-qps/</guid><description>通过单个服务器压测的 QPS 估算需要的服务器数量
已知 QPS 和期望每笔耗时，估算服务器数量 服务器数量 $$ = QPS \div (1000 \div 每笔毫秒) \div 每服务器CPU个数 $$
例如：
QPS：每秒处理3200笔 每笔毫秒：50ms 每个服务器CPU个数：16 服务器数量 $$ 3200_{qps} \div (1000_{ms} \div 50_{ms}) \div 16_{cpu} = 10_{台} $$
已知 QPS 以及服务器数量，估算每笔耗时 每笔耗时毫秒 $$ = 1000 \div ( QPS \div ( 服务器数量 \times 每服务器CPU个数 ) ) $$
例如：
QPS：每秒处理3200笔 服务器数量：10 每服务器CPU个数：16 每笔耗时毫秒 $$ 1000 \div ( 3200 \div ( 10 \times 16 ) ) = 50_{ms}$$</description></item></channel></rss>