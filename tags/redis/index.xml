<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>redis on</title><link>https://coolbeevip.github.io/tags/redis/</link><description>Recent content in redis on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 25 Aug 2021 13:24:14 +0800</lastBuildDate><atom:link href="https://coolbeevip.github.io/tags/redis/index.xml" rel="self" type="application/rss+xml"/><item><title>Find The Biggest Objects In Redis</title><link>https://coolbeevip.github.io/posts/redis/redis-find-biggest-objects-in-redis/</link><pubDate>Wed, 25 Aug 2021 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-find-biggest-objects-in-redis/</guid><description>在 REDIS 中一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际上中如果下面两种情况，我就会认为它是 bigkeys。
字符串类型：单个 value 超过5MB 哈希、列表、集合、有序集合元素可数超过 10000 因为 REDIS 是单进程处理，所以对 BIGKEY 的访问会产生阻塞，如果你获取 100 次单体大小为 5MB 的 KEY，那么这些数据（500MB）传输到客户端就需要一定的时间，这期间其他命令都要排队等待。
查找 BIGKEY 使用 bigkeys 命令可以统计大对象（建议在从结点执行），为了方式阻塞，我们设置一个休眠参数 -i 0.1
redis-cli -h &amp;lt;ip&amp;gt; -p &amp;lt;port&amp;gt; -a &amp;lt;password&amp;gt; --bigkeys -i 0.1 结果如下：
$ redis-cli -h 192.168.51.207 -p 9015 --bigkeys Warning: Using a password with &amp;#39;-a&amp;#39; or &amp;#39;-u&amp;#39; option on the command line interface may not be safe. # Scanning the entire keyspace to find biggest keys as well as # average sizes per key type.</description></item><item><title>Setting up Redis for Production</title><link>https://coolbeevip.github.io/posts/redis/redis-setting-up-redis-for-production/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-setting-up-redis-for-production/</guid><description>安装 官方建议的安装方法是从源代码编译安装，您可以从 redis.io 下载最新稳定版的 TAR 包
wget https://download.redis.io/releases/redis-6.2.5.tar.gz tar xvzf redis-6.2.5.tar.gz cd redis-6.2.5 make 此时，您可以通过键入 make test 来测试您的构建是否正常工作。编译后 redis-6.2.5/src 目录填充了一部分可执行文件。 最好将编译后的 Redis 执行文件都复制到适当的位置，或者使用以下命令手动复制（假设我们的安装路径是 /usr/local/redis）：
# 可执行文件 sudo mkdir -p /usr/local/redis/bin sudo cp src/redis-server /usr/local/redis/bin sudo cp src/redis-cli /usr/local/redis/bin sudo cp src/redis-sentinel /usr/local/redis/bin sudo cp src/redis-benchmark /usr/local/redis/bin sudo cp src/redis-check-aof /usr/local/redis/bin sudo cp src/redis-check-rdb /usr/local/redis/bin # 配置文件 sudo mkdir -p /usr/local/redis/conf sudo cp redis.conf /usr/local/redis/conf sudo cp sentinel.conf /usr/local/redis/conf # 数据目录 sudo mkdir -p /usr/local/redis/data sudo mkdir -p /usr/local/redis/log # 创建链接 sudo ln -s /usr/local/redis/bin/redis-server /usr/bin/redis-server sudo ln -s /usr/local/redis/bin/redis-cli /usr/bin/redis-cli 提示： 复制完毕后，您可以删除 redis-6.</description></item><item><title>Using Redis as a Cache</title><link>https://coolbeevip.github.io/posts/redis/redis-using-redis-as-a-cache/</link><pubDate>Wed, 19 Aug 2020 13:24:14 +0800</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-using-redis-as-a-cache/</guid><description>当 Redis 用作缓存时，通常可以方便地让它在您添加新数据时自动驱逐旧数据。Redis 支持 6 种驱逐策略，你可以使用 maxmemory-policy 修改驱逐策略。默认是不驱逐，也就是说如果使用的内存超过了 maxmemory 限制，将提示 OOM。
你可以在 redis.conf 通过 maxmemory 2gb 设置，也可以通过 config set maxmemory 2gb 方式动态设置，注意： 在64bit系统下，maxmemory设置为0表示不限制内存使用，在32bit系统下，maxmemory不能超过3GB
驱逐策略 noenviction: 禁止驱逐数据(默认淘汰策略) 当 redis 内存数据达到 maxmemory，在该策略下，直接返回OOM错误； volatile-lru: 驱逐已设置过期时间的内存数据集中最近最少使用的数据； volatile-ttl: 驱逐已设置过期时间的内存数据集中即将过期的数据； volatile-random: 驱逐已设置过期时间的内存数据集中任意挑选数据； allkeys-lru: 驱逐内存数据集中最近最少使用的数据； allkeys-random: 驱逐数据集中任意挑选数据； volatile-lfu 驱逐已设置过期时间的内存数据集中使用频率最少的数据；（since 4.0） allkeys-lfu 驱逐内存数据集中使用频率最少的数据；（since 4.0） 如果 KEY 未设置过期时间，那么 volatile-random、volatile-ttl 和 volatile-lru 等同于 noenviction。
驱逐程序如何运作 重要的是要了解驱逐过程的工作方式如下：
客户端运行新命令，导致添加更多数据。 Redis 检查内存使用情况，如果大于 maxmemory limit ，则根据策略驱逐键。 执行新命令，等等。 所以我们不断地越过内存限制的边界，越过它，然后通过驱逐键返回到限制之下。 如果某个命令导致使用大量内存一段时间，则内存限制可能会明显超出。</description></item><item><title>Slow LOG In Redis</title><link>https://coolbeevip.github.io/posts/redis/redis-slowlog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://coolbeevip.github.io/posts/redis/redis-slowlog/</guid><description>SLOWLOG 记录了 Redis 运行时间超时特定阀值的命令。这类慢查询命令被保存在 Redis 服务器的一个定长队列中，最多保存 slowlog-max-len(默认128）个慢查询命令。当慢查询命令达到128个时，新产生的慢查询被加入前，会从队列中删除最旧的慢查询命令。
配置 redis slowlog通过2个参数配置管理，默认命令耗时超过10毫秒，就会被记录到慢查询日志队列中；队列默认保存最近产生的128个慢查询命令。
slowlog-log-slower-than: 慢查询阀值，单位微秒，默认100000 (10毫秒)； 执行耗时超过这个值的查询会被记录；建议你生产环境设置为 10000（1毫秒），因为如果命令都是 1 毫秒以上，那么 Redis 吞吐率只有 1000 QPS；
slowlog-max-len: 慢查询存储的最大个数，默认128；生产设置设置大于1024，因为 slowlog 会省略过多的参数，慢查询不会占用过多的内存；
读取 返回最新的 2 条慢查询
SLOWLOG GET 2 1) 1) (integer) 9495 2) (integer) 1638760173 3) (integer) 13923 4) 1) &amp;#34;COMMAND&amp;#34; 5) &amp;#34;10.30.107.152:41830&amp;#34; 6) &amp;#34;&amp;#34; 2) 1) (integer) 9494 2) (integer) 1638759729 3) (integer) 17170 4) 1) &amp;#34;SADD&amp;#34; 2) &amp;#34;nc_oauth:uname_to_access:nc:vpengcheng&amp;#34; 3) &amp;#34;\xac\xed\x00\x05sr\x00Corg.</description></item></channel></rss>